; ModuleID = 'crypto/ripemd/rmd_dgst.c'
source_filename = "crypto/ripemd/rmd_dgst.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.RIPEMD160state_st = type { i32, i32, i32, i32, i32, i32, i32, [16 x i32], i32 }

; Function Attrs: noinline nounwind uwtable
define i32 @RIPEMD160_Update(%struct.RIPEMD160state_st* noundef %c, i8* noundef %data_, i64 noundef %len) local_unnamed_addr #0 {
entry:
  %cmp = icmp eq i64 %len, 0
  br i1 %cmp, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %Nl = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 5
  %0 = load i32, i32* %Nl, align 4, !tbaa !4
  %conv = trunc i64 %len to i32
  %shl = shl i32 %conv, 3
  %add = add i32 %0, %shl
  %cmp4 = icmp ult i32 %add, %0
  %Nh = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 6
  %1 = load i32, i32* %Nh, align 4, !tbaa !9
  %inc = zext i1 %cmp4 to i32
  %2 = add i32 %1, %inc
  %shr = lshr i64 %len, 29
  %conv8 = trunc i64 %shr to i32
  %Nh9 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 6
  %add10 = add i32 %2, %conv8
  store i32 %add10, i32* %Nh9, align 4, !tbaa !9
  store i32 %add, i32* %Nl, align 4, !tbaa !4
  %num = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 8
  %3 = load i32, i32* %num, align 4, !tbaa !10
  %conv12 = zext i32 %3 to i64
  %cmp13.not = icmp eq i32 %3, 0
  br i1 %cmp13.not, label %if.end34, label %if.then15

if.then15:                                        ; preds = %if.end
  %arraydecay = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 7, i64 0
  %4 = bitcast i32* %arraydecay to i8*
  %cmp17 = icmp ugt i64 %len, 63
  %add19 = add i64 %conv12, %len
  %cmp20 = icmp ugt i64 %add19, 63
  %or.cond = select i1 %cmp17, i1 true, i1 %cmp20
  %add.ptr = getelementptr inbounds i8, i8* %4, i64 %conv12
  br i1 %or.cond, label %if.then22, label %if.else

if.then22:                                        ; preds = %if.then15
  %sub = sub nsw i64 64, %conv12
  %call = tail call i8* @memcpy(i8* noundef nonnull %add.ptr, i8* noundef %data_, i64 noundef %sub) #5
  tail call void @ripemd160_block_data_order(%struct.RIPEMD160state_st* noundef nonnull %c, i8* noundef nonnull %4, i64 noundef 1) #6
  %add.ptr24 = getelementptr inbounds i8, i8* %data_, i64 %sub
  %sub25 = sub i64 %len, %sub
  store i32 0, i32* %num, align 4, !tbaa !10
  %call27 = tail call i8* @memset(i8* noundef nonnull %4, i32 noundef 0, i64 noundef 64) #5
  br label %if.end34

if.else:                                          ; preds = %if.then15
  %call29 = tail call i8* @memcpy(i8* noundef nonnull %add.ptr, i8* noundef %data_, i64 noundef %len) #5
  %5 = load i32, i32* %num, align 4, !tbaa !10
  %add32 = add i32 %5, %conv
  store i32 %add32, i32* %num, align 4, !tbaa !10
  br label %cleanup

if.end34:                                         ; preds = %if.then22, %if.end
  %len.addr.0 = phi i64 [ %sub25, %if.then22 ], [ %len, %if.end ]
  %data.0 = phi i8* [ %add.ptr24, %if.then22 ], [ %data_, %if.end ]
  %cmp35.not = icmp ult i64 %len.addr.0, 64
  br i1 %cmp35.not, label %if.end40, label %if.then37

if.then37:                                        ; preds = %if.end34
  %div = lshr i64 %len.addr.0, 6
  tail call void @ripemd160_block_data_order(%struct.RIPEMD160state_st* noundef nonnull %c, i8* noundef %data.0, i64 noundef %div) #6
  %mul = and i64 %len.addr.0, -64
  %add.ptr38 = getelementptr inbounds i8, i8* %data.0, i64 %mul
  %sub39 = and i64 %len.addr.0, 63
  br label %if.end40

if.end40:                                         ; preds = %if.then37, %if.end34
  %len.addr.1 = phi i64 [ %sub39, %if.then37 ], [ %len.addr.0, %if.end34 ]
  %data.1 = phi i8* [ %add.ptr38, %if.then37 ], [ %data.0, %if.end34 ]
  %cmp41.not = icmp eq i64 %len.addr.1, 0
  br i1 %cmp41.not, label %cleanup, label %if.then43

if.then43:                                        ; preds = %if.end40
  %arraydecay45 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 7, i64 0
  %6 = bitcast i32* %arraydecay45 to i8*
  %conv46 = trunc i64 %len.addr.1 to i32
  store i32 %conv46, i32* %num, align 4, !tbaa !10
  %call48 = tail call i8* @memcpy(i8* noundef nonnull %6, i8* noundef %data.1, i64 noundef %len.addr.1) #5
  br label %cleanup

cleanup:                                          ; preds = %if.end40, %if.then43, %entry, %if.else
  ret i32 1
}

; Function Attrs: nounwind
declare i8* @memcpy(i8* noundef, i8* noundef, i64 noundef) local_unnamed_addr #1

; Function Attrs: nofree noinline nosync nounwind uwtable
define void @ripemd160_block_data_order(%struct.RIPEMD160state_st* nocapture noundef %ctx, i8* noundef readonly %p, i64 noundef %num) local_unnamed_addr #2 {
entry:
  %tobool.not4905 = icmp eq i64 %num, 0
  br i1 %tobool.not4905, label %for.end, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %entry
  %A1 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %ctx, i64 0, i32 0
  %B2 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %ctx, i64 0, i32 1
  %C3 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %ctx, i64 0, i32 2
  %D4 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %ctx, i64 0, i32 3
  %E5 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %ctx, i64 0, i32 4
  %.pre = load i32, i32* %A1, align 4, !tbaa !11
  %.pre4908 = load i32, i32* %B2, align 4, !tbaa !12
  %.pre4909 = load i32, i32* %C3, align 4, !tbaa !13
  %.pre4910 = load i32, i32* %D4, align 4, !tbaa !14
  %.pre4911 = load i32, i32* %E5, align 4, !tbaa !15
  br label %for.body

for.body:                                         ; preds = %for.body.lr.ph, %for.body
  %0 = phi i32 [ %.pre4911, %for.body.lr.ph ], [ %add3075, %for.body ]
  %1 = phi i32 [ %.pre4910, %for.body.lr.ph ], [ %add3071, %for.body ]
  %2 = phi i32 [ %.pre4909, %for.body.lr.ph ], [ %add3067, %for.body ]
  %3 = phi i32 [ %.pre4908, %for.body.lr.ph ], [ %add3063, %for.body ]
  %4 = phi i32 [ %.pre, %for.body.lr.ph ], [ %add3060, %for.body ]
  %num.addr.04907 = phi i64 [ %num, %for.body.lr.ph ], [ %dec, %for.body ]
  %data.04906 = phi i8* [ %p, %for.body.lr.ph ], [ %incdec.ptr510, %for.body ]
  %dec = add i64 %num.addr.04907, -1
  %incdec.ptr = getelementptr inbounds i8, i8* %data.04906, i64 1
  %5 = load i8, i8* %data.04906, align 1, !tbaa !16
  %incdec.ptr7 = getelementptr inbounds i8, i8* %data.04906, i64 2
  %6 = load i8, i8* %incdec.ptr, align 1, !tbaa !16
  %conv8 = zext i8 %6 to i32
  %shl = shl nuw nsw i32 %conv8, 8
  %conv9 = zext i8 %5 to i32
  %or = or i32 %shl, %conv9
  %incdec.ptr11 = getelementptr inbounds i8, i8* %data.04906, i64 3
  %7 = load i8, i8* %incdec.ptr7, align 1, !tbaa !16
  %conv12 = zext i8 %7 to i32
  %shl13 = shl nuw nsw i32 %conv12, 16
  %or15 = or i32 %or, %shl13
  %incdec.ptr17 = getelementptr inbounds i8, i8* %data.04906, i64 4
  %8 = load i8, i8* %incdec.ptr11, align 1, !tbaa !16
  %conv18 = zext i8 %8 to i32
  %shl19 = shl nuw i32 %conv18, 24
  %or21 = or i32 %or15, %shl19
  %incdec.ptr23 = getelementptr inbounds i8, i8* %data.04906, i64 5
  %9 = load i8, i8* %incdec.ptr17, align 1, !tbaa !16
  %incdec.ptr26 = getelementptr inbounds i8, i8* %data.04906, i64 6
  %10 = load i8, i8* %incdec.ptr23, align 1, !tbaa !16
  %conv27 = zext i8 %10 to i32
  %shl28 = shl nuw nsw i32 %conv27, 8
  %conv29 = zext i8 %9 to i32
  %or30 = or i32 %shl28, %conv29
  %incdec.ptr32 = getelementptr inbounds i8, i8* %data.04906, i64 7
  %11 = load i8, i8* %incdec.ptr26, align 1, !tbaa !16
  %conv33 = zext i8 %11 to i32
  %shl34 = shl nuw nsw i32 %conv33, 16
  %or36 = or i32 %or30, %shl34
  %incdec.ptr38 = getelementptr inbounds i8, i8* %data.04906, i64 8
  %12 = load i8, i8* %incdec.ptr32, align 1, !tbaa !16
  %conv39 = zext i8 %12 to i32
  %shl40 = shl nuw i32 %conv39, 24
  %or42 = or i32 %or36, %shl40
  %xor = xor i32 %2, %3
  %xor44 = xor i32 %xor, %1
  %add = add i32 %xor44, %4
  %add45 = add i32 %add, %or21
  %or47 = tail call i32 @llvm.fshl.i32(i32 %add45, i32 %add45, i32 11)
  %add48 = add i32 %or47, %0
  %or52 = tail call i32 @llvm.fshl.i32(i32 %2, i32 %2, i32 10)
  %incdec.ptr53 = getelementptr inbounds i8, i8* %data.04906, i64 9
  %13 = load i8, i8* %incdec.ptr38, align 1, !tbaa !16
  %incdec.ptr56 = getelementptr inbounds i8, i8* %data.04906, i64 10
  %14 = load i8, i8* %incdec.ptr53, align 1, !tbaa !16
  %conv57 = zext i8 %14 to i32
  %shl58 = shl nuw nsw i32 %conv57, 8
  %conv59 = zext i8 %13 to i32
  %or60 = or i32 %shl58, %conv59
  %incdec.ptr62 = getelementptr inbounds i8, i8* %data.04906, i64 11
  %15 = load i8, i8* %incdec.ptr56, align 1, !tbaa !16
  %conv63 = zext i8 %15 to i32
  %shl64 = shl nuw nsw i32 %conv63, 16
  %or66 = or i32 %or60, %shl64
  %incdec.ptr68 = getelementptr inbounds i8, i8* %data.04906, i64 12
  %16 = load i8, i8* %incdec.ptr62, align 1, !tbaa !16
  %conv69 = zext i8 %16 to i32
  %shl70 = shl nuw i32 %conv69, 24
  %or72 = or i32 %or66, %shl70
  %xor74 = xor i32 %or52, %3
  %xor75 = xor i32 %xor74, %add48
  %add76 = add i32 %or42, %0
  %add77 = add i32 %add76, %xor75
  %or81 = tail call i32 @llvm.fshl.i32(i32 %add77, i32 %add77, i32 14)
  %add82 = add i32 %or81, %1
  %or86 = tail call i32 @llvm.fshl.i32(i32 %3, i32 %3, i32 10)
  %incdec.ptr87 = getelementptr inbounds i8, i8* %data.04906, i64 13
  %17 = load i8, i8* %incdec.ptr68, align 1, !tbaa !16
  %incdec.ptr90 = getelementptr inbounds i8, i8* %data.04906, i64 14
  %18 = load i8, i8* %incdec.ptr87, align 1, !tbaa !16
  %conv91 = zext i8 %18 to i32
  %shl92 = shl nuw nsw i32 %conv91, 8
  %conv93 = zext i8 %17 to i32
  %or94 = or i32 %shl92, %conv93
  %incdec.ptr96 = getelementptr inbounds i8, i8* %data.04906, i64 15
  %19 = load i8, i8* %incdec.ptr90, align 1, !tbaa !16
  %conv97 = zext i8 %19 to i32
  %shl98 = shl nuw nsw i32 %conv97, 16
  %or100 = or i32 %or94, %shl98
  %incdec.ptr102 = getelementptr inbounds i8, i8* %data.04906, i64 16
  %20 = load i8, i8* %incdec.ptr96, align 1, !tbaa !16
  %conv103 = zext i8 %20 to i32
  %shl104 = shl nuw i32 %conv103, 24
  %or106 = or i32 %or100, %shl104
  %xor108 = xor i32 %add48, %or86
  %xor109 = xor i32 %xor108, %add82
  %add110 = add i32 %or72, %1
  %add111 = add i32 %add110, %xor109
  %or115 = tail call i32 @llvm.fshl.i32(i32 %add111, i32 %add111, i32 15)
  %add116 = add i32 %or115, %or52
  %or120 = tail call i32 @llvm.fshl.i32(i32 %add48, i32 %add48, i32 10)
  %incdec.ptr121 = getelementptr inbounds i8, i8* %data.04906, i64 17
  %21 = load i8, i8* %incdec.ptr102, align 1, !tbaa !16
  %incdec.ptr124 = getelementptr inbounds i8, i8* %data.04906, i64 18
  %22 = load i8, i8* %incdec.ptr121, align 1, !tbaa !16
  %conv125 = zext i8 %22 to i32
  %shl126 = shl nuw nsw i32 %conv125, 8
  %conv127 = zext i8 %21 to i32
  %or128 = or i32 %shl126, %conv127
  %incdec.ptr130 = getelementptr inbounds i8, i8* %data.04906, i64 19
  %23 = load i8, i8* %incdec.ptr124, align 1, !tbaa !16
  %conv131 = zext i8 %23 to i32
  %shl132 = shl nuw nsw i32 %conv131, 16
  %or134 = or i32 %or128, %shl132
  %incdec.ptr136 = getelementptr inbounds i8, i8* %data.04906, i64 20
  %24 = load i8, i8* %incdec.ptr130, align 1, !tbaa !16
  %conv137 = zext i8 %24 to i32
  %shl138 = shl nuw i32 %conv137, 24
  %or140 = or i32 %or134, %shl138
  %xor142 = xor i32 %add82, %or120
  %xor143 = xor i32 %xor142, %add116
  %add144 = add i32 %or106, %or52
  %add145 = add i32 %add144, %xor143
  %or149 = tail call i32 @llvm.fshl.i32(i32 %add145, i32 %add145, i32 12)
  %add150 = add i32 %or149, %or86
  %or154 = tail call i32 @llvm.fshl.i32(i32 %add82, i32 %add82, i32 10)
  %incdec.ptr155 = getelementptr inbounds i8, i8* %data.04906, i64 21
  %25 = load i8, i8* %incdec.ptr136, align 1, !tbaa !16
  %incdec.ptr158 = getelementptr inbounds i8, i8* %data.04906, i64 22
  %26 = load i8, i8* %incdec.ptr155, align 1, !tbaa !16
  %conv159 = zext i8 %26 to i32
  %shl160 = shl nuw nsw i32 %conv159, 8
  %conv161 = zext i8 %25 to i32
  %or162 = or i32 %shl160, %conv161
  %incdec.ptr164 = getelementptr inbounds i8, i8* %data.04906, i64 23
  %27 = load i8, i8* %incdec.ptr158, align 1, !tbaa !16
  %conv165 = zext i8 %27 to i32
  %shl166 = shl nuw nsw i32 %conv165, 16
  %or168 = or i32 %or162, %shl166
  %incdec.ptr170 = getelementptr inbounds i8, i8* %data.04906, i64 24
  %28 = load i8, i8* %incdec.ptr164, align 1, !tbaa !16
  %conv171 = zext i8 %28 to i32
  %shl172 = shl nuw i32 %conv171, 24
  %or174 = or i32 %or168, %shl172
  %xor176 = xor i32 %add116, %or154
  %xor177 = xor i32 %xor176, %add150
  %add178 = add i32 %or140, %or86
  %add179 = add i32 %add178, %xor177
  %or183 = tail call i32 @llvm.fshl.i32(i32 %add179, i32 %add179, i32 5)
  %add184 = add i32 %or183, %or120
  %or188 = tail call i32 @llvm.fshl.i32(i32 %add116, i32 %add116, i32 10)
  %incdec.ptr189 = getelementptr inbounds i8, i8* %data.04906, i64 25
  %29 = load i8, i8* %incdec.ptr170, align 1, !tbaa !16
  %incdec.ptr192 = getelementptr inbounds i8, i8* %data.04906, i64 26
  %30 = load i8, i8* %incdec.ptr189, align 1, !tbaa !16
  %conv193 = zext i8 %30 to i32
  %shl194 = shl nuw nsw i32 %conv193, 8
  %conv195 = zext i8 %29 to i32
  %or196 = or i32 %shl194, %conv195
  %incdec.ptr198 = getelementptr inbounds i8, i8* %data.04906, i64 27
  %31 = load i8, i8* %incdec.ptr192, align 1, !tbaa !16
  %conv199 = zext i8 %31 to i32
  %shl200 = shl nuw nsw i32 %conv199, 16
  %or202 = or i32 %or196, %shl200
  %incdec.ptr204 = getelementptr inbounds i8, i8* %data.04906, i64 28
  %32 = load i8, i8* %incdec.ptr198, align 1, !tbaa !16
  %conv205 = zext i8 %32 to i32
  %shl206 = shl nuw i32 %conv205, 24
  %or208 = or i32 %or202, %shl206
  %xor210 = xor i32 %add150, %or188
  %xor211 = xor i32 %xor210, %add184
  %add212 = add i32 %or174, %or120
  %add213 = add i32 %add212, %xor211
  %or217 = tail call i32 @llvm.fshl.i32(i32 %add213, i32 %add213, i32 8)
  %add218 = add i32 %or217, %or154
  %or222 = tail call i32 @llvm.fshl.i32(i32 %add150, i32 %add150, i32 10)
  %incdec.ptr223 = getelementptr inbounds i8, i8* %data.04906, i64 29
  %33 = load i8, i8* %incdec.ptr204, align 1, !tbaa !16
  %incdec.ptr226 = getelementptr inbounds i8, i8* %data.04906, i64 30
  %34 = load i8, i8* %incdec.ptr223, align 1, !tbaa !16
  %conv227 = zext i8 %34 to i32
  %shl228 = shl nuw nsw i32 %conv227, 8
  %conv229 = zext i8 %33 to i32
  %or230 = or i32 %shl228, %conv229
  %incdec.ptr232 = getelementptr inbounds i8, i8* %data.04906, i64 31
  %35 = load i8, i8* %incdec.ptr226, align 1, !tbaa !16
  %conv233 = zext i8 %35 to i32
  %shl234 = shl nuw nsw i32 %conv233, 16
  %or236 = or i32 %or230, %shl234
  %incdec.ptr238 = getelementptr inbounds i8, i8* %data.04906, i64 32
  %36 = load i8, i8* %incdec.ptr232, align 1, !tbaa !16
  %conv239 = zext i8 %36 to i32
  %shl240 = shl nuw i32 %conv239, 24
  %or242 = or i32 %or236, %shl240
  %xor244 = xor i32 %add184, %or222
  %xor245 = xor i32 %xor244, %add218
  %add246 = add i32 %or208, %or154
  %add247 = add i32 %add246, %xor245
  %or251 = tail call i32 @llvm.fshl.i32(i32 %add247, i32 %add247, i32 7)
  %add252 = add i32 %or251, %or188
  %or256 = tail call i32 @llvm.fshl.i32(i32 %add184, i32 %add184, i32 10)
  %incdec.ptr257 = getelementptr inbounds i8, i8* %data.04906, i64 33
  %37 = load i8, i8* %incdec.ptr238, align 1, !tbaa !16
  %incdec.ptr260 = getelementptr inbounds i8, i8* %data.04906, i64 34
  %38 = load i8, i8* %incdec.ptr257, align 1, !tbaa !16
  %conv261 = zext i8 %38 to i32
  %shl262 = shl nuw nsw i32 %conv261, 8
  %conv263 = zext i8 %37 to i32
  %or264 = or i32 %shl262, %conv263
  %incdec.ptr266 = getelementptr inbounds i8, i8* %data.04906, i64 35
  %39 = load i8, i8* %incdec.ptr260, align 1, !tbaa !16
  %conv267 = zext i8 %39 to i32
  %shl268 = shl nuw nsw i32 %conv267, 16
  %or270 = or i32 %or264, %shl268
  %incdec.ptr272 = getelementptr inbounds i8, i8* %data.04906, i64 36
  %40 = load i8, i8* %incdec.ptr266, align 1, !tbaa !16
  %conv273 = zext i8 %40 to i32
  %shl274 = shl nuw i32 %conv273, 24
  %or276 = or i32 %or270, %shl274
  %xor278 = xor i32 %add218, %or256
  %xor279 = xor i32 %xor278, %add252
  %add280 = add i32 %or242, %or188
  %add281 = add i32 %add280, %xor279
  %or285 = tail call i32 @llvm.fshl.i32(i32 %add281, i32 %add281, i32 9)
  %add286 = add i32 %or285, %or222
  %or290 = tail call i32 @llvm.fshl.i32(i32 %add218, i32 %add218, i32 10)
  %incdec.ptr291 = getelementptr inbounds i8, i8* %data.04906, i64 37
  %41 = load i8, i8* %incdec.ptr272, align 1, !tbaa !16
  %incdec.ptr294 = getelementptr inbounds i8, i8* %data.04906, i64 38
  %42 = load i8, i8* %incdec.ptr291, align 1, !tbaa !16
  %conv295 = zext i8 %42 to i32
  %shl296 = shl nuw nsw i32 %conv295, 8
  %conv297 = zext i8 %41 to i32
  %or298 = or i32 %shl296, %conv297
  %incdec.ptr300 = getelementptr inbounds i8, i8* %data.04906, i64 39
  %43 = load i8, i8* %incdec.ptr294, align 1, !tbaa !16
  %conv301 = zext i8 %43 to i32
  %shl302 = shl nuw nsw i32 %conv301, 16
  %or304 = or i32 %or298, %shl302
  %incdec.ptr306 = getelementptr inbounds i8, i8* %data.04906, i64 40
  %44 = load i8, i8* %incdec.ptr300, align 1, !tbaa !16
  %conv307 = zext i8 %44 to i32
  %shl308 = shl nuw i32 %conv307, 24
  %or310 = or i32 %or304, %shl308
  %xor312 = xor i32 %add252, %or290
  %xor313 = xor i32 %xor312, %add286
  %add314 = add i32 %or276, %or222
  %add315 = add i32 %add314, %xor313
  %or319 = tail call i32 @llvm.fshl.i32(i32 %add315, i32 %add315, i32 11)
  %add320 = add i32 %or319, %or256
  %or324 = tail call i32 @llvm.fshl.i32(i32 %add252, i32 %add252, i32 10)
  %incdec.ptr325 = getelementptr inbounds i8, i8* %data.04906, i64 41
  %45 = load i8, i8* %incdec.ptr306, align 1, !tbaa !16
  %incdec.ptr328 = getelementptr inbounds i8, i8* %data.04906, i64 42
  %46 = load i8, i8* %incdec.ptr325, align 1, !tbaa !16
  %conv329 = zext i8 %46 to i32
  %shl330 = shl nuw nsw i32 %conv329, 8
  %conv331 = zext i8 %45 to i32
  %or332 = or i32 %shl330, %conv331
  %incdec.ptr334 = getelementptr inbounds i8, i8* %data.04906, i64 43
  %47 = load i8, i8* %incdec.ptr328, align 1, !tbaa !16
  %conv335 = zext i8 %47 to i32
  %shl336 = shl nuw nsw i32 %conv335, 16
  %or338 = or i32 %or332, %shl336
  %incdec.ptr340 = getelementptr inbounds i8, i8* %data.04906, i64 44
  %48 = load i8, i8* %incdec.ptr334, align 1, !tbaa !16
  %conv341 = zext i8 %48 to i32
  %shl342 = shl nuw i32 %conv341, 24
  %or344 = or i32 %or338, %shl342
  %xor346 = xor i32 %add286, %or324
  %xor347 = xor i32 %xor346, %add320
  %add348 = add i32 %or310, %or256
  %add349 = add i32 %add348, %xor347
  %or353 = tail call i32 @llvm.fshl.i32(i32 %add349, i32 %add349, i32 13)
  %add354 = add i32 %or353, %or290
  %or358 = tail call i32 @llvm.fshl.i32(i32 %add286, i32 %add286, i32 10)
  %incdec.ptr359 = getelementptr inbounds i8, i8* %data.04906, i64 45
  %49 = load i8, i8* %incdec.ptr340, align 1, !tbaa !16
  %incdec.ptr362 = getelementptr inbounds i8, i8* %data.04906, i64 46
  %50 = load i8, i8* %incdec.ptr359, align 1, !tbaa !16
  %conv363 = zext i8 %50 to i32
  %shl364 = shl nuw nsw i32 %conv363, 8
  %conv365 = zext i8 %49 to i32
  %or366 = or i32 %shl364, %conv365
  %incdec.ptr368 = getelementptr inbounds i8, i8* %data.04906, i64 47
  %51 = load i8, i8* %incdec.ptr362, align 1, !tbaa !16
  %conv369 = zext i8 %51 to i32
  %shl370 = shl nuw nsw i32 %conv369, 16
  %or372 = or i32 %or366, %shl370
  %incdec.ptr374 = getelementptr inbounds i8, i8* %data.04906, i64 48
  %52 = load i8, i8* %incdec.ptr368, align 1, !tbaa !16
  %conv375 = zext i8 %52 to i32
  %shl376 = shl nuw i32 %conv375, 24
  %or378 = or i32 %or372, %shl376
  %xor380 = xor i32 %add320, %or358
  %xor381 = xor i32 %xor380, %add354
  %add382 = add i32 %or344, %or290
  %add383 = add i32 %add382, %xor381
  %or387 = tail call i32 @llvm.fshl.i32(i32 %add383, i32 %add383, i32 14)
  %add388 = add i32 %or387, %or324
  %or392 = tail call i32 @llvm.fshl.i32(i32 %add320, i32 %add320, i32 10)
  %incdec.ptr393 = getelementptr inbounds i8, i8* %data.04906, i64 49
  %53 = load i8, i8* %incdec.ptr374, align 1, !tbaa !16
  %incdec.ptr396 = getelementptr inbounds i8, i8* %data.04906, i64 50
  %54 = load i8, i8* %incdec.ptr393, align 1, !tbaa !16
  %conv397 = zext i8 %54 to i32
  %shl398 = shl nuw nsw i32 %conv397, 8
  %conv399 = zext i8 %53 to i32
  %or400 = or i32 %shl398, %conv399
  %incdec.ptr402 = getelementptr inbounds i8, i8* %data.04906, i64 51
  %55 = load i8, i8* %incdec.ptr396, align 1, !tbaa !16
  %conv403 = zext i8 %55 to i32
  %shl404 = shl nuw nsw i32 %conv403, 16
  %or406 = or i32 %or400, %shl404
  %incdec.ptr408 = getelementptr inbounds i8, i8* %data.04906, i64 52
  %56 = load i8, i8* %incdec.ptr402, align 1, !tbaa !16
  %conv409 = zext i8 %56 to i32
  %shl410 = shl nuw i32 %conv409, 24
  %or412 = or i32 %or406, %shl410
  %xor414 = xor i32 %add354, %or392
  %xor415 = xor i32 %xor414, %add388
  %add416 = add i32 %or378, %or324
  %add417 = add i32 %add416, %xor415
  %or421 = tail call i32 @llvm.fshl.i32(i32 %add417, i32 %add417, i32 15)
  %add422 = add i32 %or421, %or358
  %or426 = tail call i32 @llvm.fshl.i32(i32 %add354, i32 %add354, i32 10)
  %incdec.ptr427 = getelementptr inbounds i8, i8* %data.04906, i64 53
  %57 = load i8, i8* %incdec.ptr408, align 1, !tbaa !16
  %incdec.ptr430 = getelementptr inbounds i8, i8* %data.04906, i64 54
  %58 = load i8, i8* %incdec.ptr427, align 1, !tbaa !16
  %conv431 = zext i8 %58 to i32
  %shl432 = shl nuw nsw i32 %conv431, 8
  %conv433 = zext i8 %57 to i32
  %or434 = or i32 %shl432, %conv433
  %incdec.ptr436 = getelementptr inbounds i8, i8* %data.04906, i64 55
  %59 = load i8, i8* %incdec.ptr430, align 1, !tbaa !16
  %conv437 = zext i8 %59 to i32
  %shl438 = shl nuw nsw i32 %conv437, 16
  %or440 = or i32 %or434, %shl438
  %incdec.ptr442 = getelementptr inbounds i8, i8* %data.04906, i64 56
  %60 = load i8, i8* %incdec.ptr436, align 1, !tbaa !16
  %conv443 = zext i8 %60 to i32
  %shl444 = shl nuw i32 %conv443, 24
  %or446 = or i32 %or440, %shl444
  %xor448 = xor i32 %add388, %or426
  %xor449 = xor i32 %xor448, %add422
  %add450 = add i32 %or412, %or358
  %add451 = add i32 %add450, %xor449
  %or455 = tail call i32 @llvm.fshl.i32(i32 %add451, i32 %add451, i32 6)
  %add456 = add i32 %or455, %or392
  %or460 = tail call i32 @llvm.fshl.i32(i32 %add388, i32 %add388, i32 10)
  %incdec.ptr461 = getelementptr inbounds i8, i8* %data.04906, i64 57
  %61 = load i8, i8* %incdec.ptr442, align 1, !tbaa !16
  %incdec.ptr464 = getelementptr inbounds i8, i8* %data.04906, i64 58
  %62 = load i8, i8* %incdec.ptr461, align 1, !tbaa !16
  %conv465 = zext i8 %62 to i32
  %shl466 = shl nuw nsw i32 %conv465, 8
  %conv467 = zext i8 %61 to i32
  %or468 = or i32 %shl466, %conv467
  %incdec.ptr470 = getelementptr inbounds i8, i8* %data.04906, i64 59
  %63 = load i8, i8* %incdec.ptr464, align 1, !tbaa !16
  %conv471 = zext i8 %63 to i32
  %shl472 = shl nuw nsw i32 %conv471, 16
  %or474 = or i32 %or468, %shl472
  %incdec.ptr476 = getelementptr inbounds i8, i8* %data.04906, i64 60
  %64 = load i8, i8* %incdec.ptr470, align 1, !tbaa !16
  %conv477 = zext i8 %64 to i32
  %shl478 = shl nuw i32 %conv477, 24
  %or480 = or i32 %or474, %shl478
  %xor482 = xor i32 %add422, %or460
  %xor483 = xor i32 %xor482, %add456
  %add484 = add i32 %or392, %or446
  %add485 = add i32 %add484, %xor483
  %or489 = tail call i32 @llvm.fshl.i32(i32 %add485, i32 %add485, i32 7)
  %add490 = add i32 %or489, %or426
  %or494 = tail call i32 @llvm.fshl.i32(i32 %add422, i32 %add422, i32 10)
  %incdec.ptr495 = getelementptr inbounds i8, i8* %data.04906, i64 61
  %65 = load i8, i8* %incdec.ptr476, align 1, !tbaa !16
  %incdec.ptr498 = getelementptr inbounds i8, i8* %data.04906, i64 62
  %66 = load i8, i8* %incdec.ptr495, align 1, !tbaa !16
  %conv499 = zext i8 %66 to i32
  %shl500 = shl nuw nsw i32 %conv499, 8
  %conv501 = zext i8 %65 to i32
  %or502 = or i32 %shl500, %conv501
  %incdec.ptr504 = getelementptr inbounds i8, i8* %data.04906, i64 63
  %67 = load i8, i8* %incdec.ptr498, align 1, !tbaa !16
  %conv505 = zext i8 %67 to i32
  %shl506 = shl nuw nsw i32 %conv505, 16
  %or508 = or i32 %or502, %shl506
  %incdec.ptr510 = getelementptr inbounds i8, i8* %data.04906, i64 64
  %68 = load i8, i8* %incdec.ptr504, align 1, !tbaa !16
  %conv511 = zext i8 %68 to i32
  %shl512 = shl nuw i32 %conv511, 24
  %or514 = or i32 %or508, %shl512
  %xor516 = xor i32 %add456, %or494
  %xor517 = xor i32 %xor516, %add490
  %add518 = add i32 %or426, %or480
  %add519 = add i32 %add518, %xor517
  %or523 = tail call i32 @llvm.fshl.i32(i32 %add519, i32 %add519, i32 9)
  %add524 = add i32 %or523, %or460
  %or528 = tail call i32 @llvm.fshl.i32(i32 %add456, i32 %add456, i32 10)
  %xor529 = xor i32 %add490, %or528
  %xor530 = xor i32 %xor529, %add524
  %add531 = add i32 %or460, %or514
  %add532 = add i32 %add531, %xor530
  %or536 = tail call i32 @llvm.fshl.i32(i32 %add532, i32 %add532, i32 8)
  %add537 = add i32 %or536, %or494
  %or541 = tail call i32 @llvm.fshl.i32(i32 %add490, i32 %add490, i32 10)
  %xor542 = xor i32 %add524, %or541
  %and543 = and i32 %add537, %xor542
  %xor544 = xor i32 %and543, %or541
  %add545 = add i32 %or242, 1518500249
  %add547 = add i32 %add545, %or494
  %add549 = add i32 %add547, %xor544
  %or554 = tail call i32 @llvm.fshl.i32(i32 %add549, i32 %add549, i32 7)
  %add555 = add i32 %or554, %or528
  %or559 = tail call i32 @llvm.fshl.i32(i32 %add524, i32 %add524, i32 10)
  %xor560 = xor i32 %add537, %or559
  %and561 = and i32 %add555, %xor560
  %xor562 = xor i32 %and561, %or559
  %add563 = add i32 %or140, 1518500249
  %add565 = add i32 %add563, %or528
  %add567 = add i32 %add565, %xor562
  %or572 = tail call i32 @llvm.fshl.i32(i32 %add567, i32 %add567, i32 6)
  %add573 = add i32 %or572, %or541
  %or577 = tail call i32 @llvm.fshl.i32(i32 %add537, i32 %add537, i32 10)
  %xor578 = xor i32 %add555, %or577
  %and579 = and i32 %add573, %xor578
  %xor580 = xor i32 %and579, %or577
  %add581 = add i32 %or446, 1518500249
  %add583 = add i32 %add581, %or541
  %add585 = add i32 %add583, %xor580
  %or590 = tail call i32 @llvm.fshl.i32(i32 %add585, i32 %add585, i32 8)
  %add591 = add i32 %or590, %or559
  %or595 = tail call i32 @llvm.fshl.i32(i32 %add555, i32 %add555, i32 10)
  %xor596 = xor i32 %add573, %or595
  %and597 = and i32 %add591, %xor596
  %xor598 = xor i32 %and597, %or595
  %add599 = add i32 %or42, 1518500249
  %add601 = add i32 %add599, %or559
  %add603 = add i32 %add601, %xor598
  %or608 = tail call i32 @llvm.fshl.i32(i32 %add603, i32 %add603, i32 13)
  %add609 = add i32 %or608, %or577
  %or613 = tail call i32 @llvm.fshl.i32(i32 %add573, i32 %add573, i32 10)
  %xor614 = xor i32 %add591, %or613
  %and615 = and i32 %add609, %xor614
  %xor616 = xor i32 %and615, %or613
  %add617 = add i32 %or344, 1518500249
  %add619 = add i32 %add617, %or577
  %add621 = add i32 %add619, %xor616
  %or626 = tail call i32 @llvm.fshl.i32(i32 %add621, i32 %add621, i32 11)
  %add627 = add i32 %or626, %or595
  %or631 = tail call i32 @llvm.fshl.i32(i32 %add591, i32 %add591, i32 10)
  %xor632 = xor i32 %add609, %or631
  %and633 = and i32 %add627, %xor632
  %xor634 = xor i32 %and633, %or631
  %add635 = add i32 %or208, 1518500249
  %add637 = add i32 %add635, %or595
  %add639 = add i32 %add637, %xor634
  %or644 = tail call i32 @llvm.fshl.i32(i32 %add639, i32 %add639, i32 9)
  %add645 = add i32 %or644, %or613
  %or649 = tail call i32 @llvm.fshl.i32(i32 %add609, i32 %add609, i32 10)
  %xor650 = xor i32 %add627, %or649
  %and651 = and i32 %add645, %xor650
  %xor652 = xor i32 %and651, %or649
  %add653 = add i32 %or514, 1518500249
  %add655 = add i32 %add653, %or613
  %add657 = add i32 %add655, %xor652
  %or662 = tail call i32 @llvm.fshl.i32(i32 %add657, i32 %add657, i32 7)
  %add663 = add i32 %or662, %or631
  %or667 = tail call i32 @llvm.fshl.i32(i32 %add627, i32 %add627, i32 10)
  %xor668 = xor i32 %add645, %or667
  %and669 = and i32 %add663, %xor668
  %xor670 = xor i32 %and669, %or667
  %add671 = add i32 %or106, 1518500249
  %add673 = add i32 %add671, %or631
  %add675 = add i32 %add673, %xor670
  %or680 = tail call i32 @llvm.fshl.i32(i32 %add675, i32 %add675, i32 15)
  %add681 = add i32 %or680, %or649
  %or685 = tail call i32 @llvm.fshl.i32(i32 %add645, i32 %add645, i32 10)
  %xor686 = xor i32 %add663, %or685
  %and687 = and i32 %add681, %xor686
  %xor688 = xor i32 %and687, %or685
  %add689 = add i32 %or412, 1518500249
  %add691 = add i32 %add689, %or649
  %add693 = add i32 %add691, %xor688
  %or698 = tail call i32 @llvm.fshl.i32(i32 %add693, i32 %add693, i32 7)
  %add699 = add i32 %or698, %or667
  %or703 = tail call i32 @llvm.fshl.i32(i32 %add663, i32 %add663, i32 10)
  %xor704 = xor i32 %add681, %or703
  %and705 = and i32 %add699, %xor704
  %xor706 = xor i32 %and705, %or703
  %add707 = add i32 %or21, 1518500249
  %add709 = add i32 %add707, %or667
  %add711 = add i32 %add709, %xor706
  %or716 = tail call i32 @llvm.fshl.i32(i32 %add711, i32 %add711, i32 12)
  %add717 = add i32 %or716, %or685
  %or721 = tail call i32 @llvm.fshl.i32(i32 %add681, i32 %add681, i32 10)
  %xor722 = xor i32 %add699, %or721
  %and723 = and i32 %add717, %xor722
  %xor724 = xor i32 %and723, %or721
  %add725 = add i32 %or310, 1518500249
  %add727 = add i32 %add725, %or685
  %add729 = add i32 %add727, %xor724
  %or734 = tail call i32 @llvm.fshl.i32(i32 %add729, i32 %add729, i32 15)
  %add735 = add i32 %or734, %or703
  %or739 = tail call i32 @llvm.fshl.i32(i32 %add699, i32 %add699, i32 10)
  %xor740 = xor i32 %add717, %or739
  %and741 = and i32 %add735, %xor740
  %xor742 = xor i32 %and741, %or739
  %add743 = add i32 %or174, 1518500249
  %add745 = add i32 %add743, %or703
  %add747 = add i32 %add745, %xor742
  %or752 = tail call i32 @llvm.fshl.i32(i32 %add747, i32 %add747, i32 9)
  %add753 = add i32 %or752, %or721
  %or757 = tail call i32 @llvm.fshl.i32(i32 %add717, i32 %add717, i32 10)
  %xor758 = xor i32 %add735, %or757
  %and759 = and i32 %add753, %xor758
  %xor760 = xor i32 %and759, %or757
  %add761 = add i32 %or72, 1518500249
  %add763 = add i32 %add761, %or721
  %add765 = add i32 %add763, %xor760
  %or770 = tail call i32 @llvm.fshl.i32(i32 %add765, i32 %add765, i32 11)
  %add771 = add i32 %or770, %or739
  %or775 = tail call i32 @llvm.fshl.i32(i32 %add735, i32 %add735, i32 10)
  %xor776 = xor i32 %add753, %or775
  %and777 = and i32 %add771, %xor776
  %xor778 = xor i32 %and777, %or775
  %add779 = add i32 %or480, 1518500249
  %add781 = add i32 %add779, %or739
  %add783 = add i32 %add781, %xor778
  %or788 = tail call i32 @llvm.fshl.i32(i32 %add783, i32 %add783, i32 7)
  %add789 = add i32 %or788, %or757
  %or793 = tail call i32 @llvm.fshl.i32(i32 %add753, i32 %add753, i32 10)
  %xor794 = xor i32 %add771, %or793
  %and795 = and i32 %add789, %xor794
  %xor796 = xor i32 %and795, %or793
  %add797 = add i32 %or378, 1518500249
  %add799 = add i32 %add797, %or757
  %add801 = add i32 %add799, %xor796
  %or806 = tail call i32 @llvm.fshl.i32(i32 %add801, i32 %add801, i32 13)
  %add807 = add i32 %or806, %or775
  %or811 = tail call i32 @llvm.fshl.i32(i32 %add771, i32 %add771, i32 10)
  %xor812 = xor i32 %add789, %or811
  %and813 = and i32 %add807, %xor812
  %xor814 = xor i32 %and813, %or811
  %add815 = add i32 %or276, 1518500249
  %add817 = add i32 %add815, %or775
  %add819 = add i32 %add817, %xor814
  %or824 = tail call i32 @llvm.fshl.i32(i32 %add819, i32 %add819, i32 12)
  %add825 = add i32 %or824, %or793
  %or829 = tail call i32 @llvm.fshl.i32(i32 %add789, i32 %add789, i32 10)
  %neg = xor i32 %add807, -1
  %or830 = or i32 %add825, %neg
  %xor831 = xor i32 %or830, %or829
  %add832 = add i32 %or106, 1859775393
  %add834 = add i32 %add832, %or793
  %add836 = add i32 %add834, %xor831
  %or841 = tail call i32 @llvm.fshl.i32(i32 %add836, i32 %add836, i32 11)
  %add842 = add i32 %or841, %or811
  %or846 = tail call i32 @llvm.fshl.i32(i32 %add807, i32 %add807, i32 10)
  %neg847 = xor i32 %add825, -1
  %or848 = or i32 %add842, %neg847
  %xor849 = xor i32 %or848, %or846
  %add850 = add i32 %or344, 1859775393
  %add852 = add i32 %add850, %or811
  %add854 = add i32 %add852, %xor849
  %or859 = tail call i32 @llvm.fshl.i32(i32 %add854, i32 %add854, i32 13)
  %add860 = add i32 %or859, %or829
  %or864 = tail call i32 @llvm.fshl.i32(i32 %add825, i32 %add825, i32 10)
  %neg865 = xor i32 %add842, -1
  %or866 = or i32 %add860, %neg865
  %xor867 = xor i32 %or866, %or864
  %add868 = add i32 %or480, 1859775393
  %add870 = add i32 %add868, %or829
  %add872 = add i32 %add870, %xor867
  %or877 = tail call i32 @llvm.fshl.i32(i32 %add872, i32 %add872, i32 6)
  %add878 = add i32 %or877, %or846
  %or882 = tail call i32 @llvm.fshl.i32(i32 %add842, i32 %add842, i32 10)
  %neg883 = xor i32 %add860, -1
  %or884 = or i32 %add878, %neg883
  %xor885 = xor i32 %or884, %or882
  %add886 = add i32 %or140, 1859775393
  %add888 = add i32 %add886, %or846
  %add890 = add i32 %add888, %xor885
  %or895 = tail call i32 @llvm.fshl.i32(i32 %add890, i32 %add890, i32 7)
  %add896 = add i32 %or895, %or864
  %or900 = tail call i32 @llvm.fshl.i32(i32 %add860, i32 %add860, i32 10)
  %neg901 = xor i32 %add878, -1
  %or902 = or i32 %add896, %neg901
  %xor903 = xor i32 %or902, %or900
  %add904 = add i32 %or310, 1859775393
  %add906 = add i32 %add904, %or864
  %add908 = add i32 %add906, %xor903
  %or913 = tail call i32 @llvm.fshl.i32(i32 %add908, i32 %add908, i32 14)
  %add914 = add i32 %or913, %or882
  %or918 = tail call i32 @llvm.fshl.i32(i32 %add878, i32 %add878, i32 10)
  %neg919 = xor i32 %add896, -1
  %or920 = or i32 %add914, %neg919
  %xor921 = xor i32 %or920, %or918
  %add922 = add i32 %or514, 1859775393
  %add924 = add i32 %add922, %or882
  %add926 = add i32 %add924, %xor921
  %or931 = tail call i32 @llvm.fshl.i32(i32 %add926, i32 %add926, i32 9)
  %add932 = add i32 %or931, %or900
  %or936 = tail call i32 @llvm.fshl.i32(i32 %add896, i32 %add896, i32 10)
  %neg937 = xor i32 %add914, -1
  %or938 = or i32 %add932, %neg937
  %xor939 = xor i32 %or938, %or936
  %add940 = add i32 %or276, 1859775393
  %add942 = add i32 %add940, %or900
  %add944 = add i32 %add942, %xor939
  %or949 = tail call i32 @llvm.fshl.i32(i32 %add944, i32 %add944, i32 13)
  %add950 = add i32 %or949, %or918
  %or954 = tail call i32 @llvm.fshl.i32(i32 %add914, i32 %add914, i32 10)
  %neg955 = xor i32 %add932, -1
  %or956 = or i32 %add950, %neg955
  %xor957 = xor i32 %or956, %or954
  %add958 = add i32 %or42, 1859775393
  %add960 = add i32 %add958, %or918
  %add962 = add i32 %add960, %xor957
  %or967 = tail call i32 @llvm.fshl.i32(i32 %add962, i32 %add962, i32 15)
  %add968 = add i32 %or967, %or936
  %or972 = tail call i32 @llvm.fshl.i32(i32 %add932, i32 %add932, i32 10)
  %neg973 = xor i32 %add950, -1
  %or974 = or i32 %add968, %neg973
  %xor975 = xor i32 %or974, %or972
  %add976 = add i32 %or72, 1859775393
  %add978 = add i32 %add976, %or936
  %add980 = add i32 %add978, %xor975
  %or985 = tail call i32 @llvm.fshl.i32(i32 %add980, i32 %add980, i32 14)
  %add986 = add i32 %or985, %or954
  %or990 = tail call i32 @llvm.fshl.i32(i32 %add950, i32 %add950, i32 10)
  %neg991 = xor i32 %add968, -1
  %or992 = or i32 %add986, %neg991
  %xor993 = xor i32 %or992, %or990
  %add994 = add i32 %or242, 1859775393
  %add996 = add i32 %add994, %or954
  %add998 = add i32 %add996, %xor993
  %or1003 = tail call i32 @llvm.fshl.i32(i32 %add998, i32 %add998, i32 8)
  %add1004 = add i32 %or1003, %or972
  %or1008 = tail call i32 @llvm.fshl.i32(i32 %add968, i32 %add968, i32 10)
  %neg1009 = xor i32 %add986, -1
  %or1010 = or i32 %add1004, %neg1009
  %xor1011 = xor i32 %or1010, %or1008
  %add1012 = add i32 %or21, 1859775393
  %add1014 = add i32 %add1012, %or972
  %add1016 = add i32 %add1014, %xor1011
  %or1021 = tail call i32 @llvm.fshl.i32(i32 %add1016, i32 %add1016, i32 13)
  %add1022 = add i32 %or1021, %or990
  %or1026 = tail call i32 @llvm.fshl.i32(i32 %add986, i32 %add986, i32 10)
  %neg1027 = xor i32 %add1004, -1
  %or1028 = or i32 %add1022, %neg1027
  %xor1029 = xor i32 %or1028, %or1026
  %add1030 = add i32 %or208, 1859775393
  %add1032 = add i32 %add1030, %or990
  %add1034 = add i32 %add1032, %xor1029
  %or1039 = tail call i32 @llvm.fshl.i32(i32 %add1034, i32 %add1034, i32 6)
  %add1040 = add i32 %or1039, %or1008
  %or1044 = tail call i32 @llvm.fshl.i32(i32 %add1004, i32 %add1004, i32 10)
  %neg1045 = xor i32 %add1022, -1
  %or1046 = or i32 %add1040, %neg1045
  %xor1047 = xor i32 %or1046, %or1044
  %add1048 = add i32 %or446, 1859775393
  %add1050 = add i32 %add1048, %or1008
  %add1052 = add i32 %add1050, %xor1047
  %or1057 = tail call i32 @llvm.fshl.i32(i32 %add1052, i32 %add1052, i32 5)
  %add1058 = add i32 %or1057, %or1026
  %or1062 = tail call i32 @llvm.fshl.i32(i32 %add1022, i32 %add1022, i32 10)
  %neg1063 = xor i32 %add1040, -1
  %or1064 = or i32 %add1058, %neg1063
  %xor1065 = xor i32 %or1064, %or1062
  %add1066 = add i32 %or378, 1859775393
  %add1068 = add i32 %add1066, %or1026
  %add1070 = add i32 %add1068, %xor1065
  %or1075 = tail call i32 @llvm.fshl.i32(i32 %add1070, i32 %add1070, i32 12)
  %add1076 = add i32 %or1075, %or1044
  %or1080 = tail call i32 @llvm.fshl.i32(i32 %add1040, i32 %add1040, i32 10)
  %neg1081 = xor i32 %add1058, -1
  %or1082 = or i32 %add1076, %neg1081
  %xor1083 = xor i32 %or1082, %or1080
  %add1084 = add i32 %or174, 1859775393
  %add1086 = add i32 %add1084, %or1044
  %add1088 = add i32 %add1086, %xor1083
  %or1093 = tail call i32 @llvm.fshl.i32(i32 %add1088, i32 %add1088, i32 7)
  %add1094 = add i32 %or1093, %or1062
  %or1098 = tail call i32 @llvm.fshl.i32(i32 %add1058, i32 %add1058, i32 10)
  %neg1099 = xor i32 %add1076, -1
  %or1100 = or i32 %add1094, %neg1099
  %xor1101 = xor i32 %or1100, %or1098
  %add1102 = add i32 %or412, 1859775393
  %add1104 = add i32 %add1102, %or1062
  %add1106 = add i32 %add1104, %xor1101
  %or1111 = tail call i32 @llvm.fshl.i32(i32 %add1106, i32 %add1106, i32 5)
  %add1112 = add i32 %or1111, %or1080
  %or1116 = tail call i32 @llvm.fshl.i32(i32 %add1076, i32 %add1076, i32 10)
  %xor1117 = xor i32 %add1112, %add1094
  %and1118 = and i32 %xor1117, %or1116
  %xor1119 = xor i32 %and1118, %add1094
  %add1120 = add i32 %or42, -1894007588
  %add1122 = add i32 %add1120, %or1080
  %add1124 = add i32 %add1122, %xor1119
  %or1129 = tail call i32 @llvm.fshl.i32(i32 %add1124, i32 %add1124, i32 11)
  %add1130 = add i32 %or1129, %or1098
  %or1134 = tail call i32 @llvm.fshl.i32(i32 %add1094, i32 %add1094, i32 10)
  %xor1135 = xor i32 %add1130, %add1112
  %and1136 = and i32 %xor1135, %or1134
  %xor1137 = xor i32 %and1136, %add1112
  %add1138 = add i32 %or310, -1894007588
  %add1140 = add i32 %add1138, %or1098
  %add1142 = add i32 %add1140, %xor1137
  %or1147 = tail call i32 @llvm.fshl.i32(i32 %add1142, i32 %add1142, i32 12)
  %add1148 = add i32 %or1147, %or1116
  %or1152 = tail call i32 @llvm.fshl.i32(i32 %add1112, i32 %add1112, i32 10)
  %xor1153 = xor i32 %add1148, %add1130
  %and1154 = and i32 %xor1153, %or1152
  %xor1155 = xor i32 %and1154, %add1130
  %add1156 = add i32 %or378, -1894007588
  %add1158 = add i32 %add1156, %or1116
  %add1160 = add i32 %add1158, %xor1155
  %or1165 = tail call i32 @llvm.fshl.i32(i32 %add1160, i32 %add1160, i32 14)
  %add1166 = add i32 %or1165, %or1134
  %or1170 = tail call i32 @llvm.fshl.i32(i32 %add1130, i32 %add1130, i32 10)
  %xor1171 = xor i32 %add1166, %add1148
  %and1172 = and i32 %xor1171, %or1170
  %xor1173 = xor i32 %and1172, %add1148
  %add1174 = add i32 %or344, -1894007588
  %add1176 = add i32 %add1174, %or1134
  %add1178 = add i32 %add1176, %xor1173
  %or1183 = tail call i32 @llvm.fshl.i32(i32 %add1178, i32 %add1178, i32 15)
  %add1184 = add i32 %or1183, %or1152
  %or1188 = tail call i32 @llvm.fshl.i32(i32 %add1148, i32 %add1148, i32 10)
  %xor1189 = xor i32 %add1184, %add1166
  %and1190 = and i32 %xor1189, %or1188
  %xor1191 = xor i32 %and1190, %add1166
  %add1192 = add i32 %or21, -1894007588
  %add1194 = add i32 %add1192, %or1152
  %add1196 = add i32 %add1194, %xor1191
  %or1201 = tail call i32 @llvm.fshl.i32(i32 %add1196, i32 %add1196, i32 14)
  %add1202 = add i32 %or1201, %or1170
  %or1206 = tail call i32 @llvm.fshl.i32(i32 %add1166, i32 %add1166, i32 10)
  %xor1207 = xor i32 %add1202, %add1184
  %and1208 = and i32 %xor1207, %or1206
  %xor1209 = xor i32 %and1208, %add1184
  %add1210 = add i32 %or276, -1894007588
  %add1212 = add i32 %add1210, %or1170
  %add1214 = add i32 %add1212, %xor1209
  %or1219 = tail call i32 @llvm.fshl.i32(i32 %add1214, i32 %add1214, i32 15)
  %add1220 = add i32 %or1219, %or1188
  %or1224 = tail call i32 @llvm.fshl.i32(i32 %add1184, i32 %add1184, i32 10)
  %xor1225 = xor i32 %add1220, %add1202
  %and1226 = and i32 %xor1225, %or1224
  %xor1227 = xor i32 %and1226, %add1202
  %add1228 = add i32 %or412, -1894007588
  %add1230 = add i32 %add1228, %or1188
  %add1232 = add i32 %add1230, %xor1227
  %or1237 = tail call i32 @llvm.fshl.i32(i32 %add1232, i32 %add1232, i32 9)
  %add1238 = add i32 %or1237, %or1206
  %or1242 = tail call i32 @llvm.fshl.i32(i32 %add1202, i32 %add1202, i32 10)
  %xor1243 = xor i32 %add1238, %add1220
  %and1244 = and i32 %xor1243, %or1242
  %xor1245 = xor i32 %and1244, %add1220
  %add1246 = add i32 %or140, -1894007588
  %add1248 = add i32 %add1246, %or1206
  %add1250 = add i32 %add1248, %xor1245
  %or1255 = tail call i32 @llvm.fshl.i32(i32 %add1250, i32 %add1250, i32 8)
  %add1256 = add i32 %or1255, %or1224
  %or1260 = tail call i32 @llvm.fshl.i32(i32 %add1220, i32 %add1220, i32 10)
  %xor1261 = xor i32 %add1256, %add1238
  %and1262 = and i32 %xor1261, %or1260
  %xor1263 = xor i32 %and1262, %add1238
  %add1264 = add i32 %or446, -1894007588
  %add1266 = add i32 %add1264, %or1224
  %add1268 = add i32 %add1266, %xor1263
  %or1273 = tail call i32 @llvm.fshl.i32(i32 %add1268, i32 %add1268, i32 9)
  %add1274 = add i32 %or1273, %or1242
  %or1278 = tail call i32 @llvm.fshl.i32(i32 %add1238, i32 %add1238, i32 10)
  %xor1279 = xor i32 %add1274, %add1256
  %and1280 = and i32 %xor1279, %or1278
  %xor1281 = xor i32 %and1280, %add1256
  %add1282 = add i32 %or106, -1894007588
  %add1284 = add i32 %add1282, %or1242
  %add1286 = add i32 %add1284, %xor1281
  %or1291 = tail call i32 @llvm.fshl.i32(i32 %add1286, i32 %add1286, i32 14)
  %add1292 = add i32 %or1291, %or1260
  %or1296 = tail call i32 @llvm.fshl.i32(i32 %add1256, i32 %add1256, i32 10)
  %xor1297 = xor i32 %add1292, %add1274
  %and1298 = and i32 %xor1297, %or1296
  %xor1299 = xor i32 %and1298, %add1274
  %add1300 = add i32 %or242, -1894007588
  %add1302 = add i32 %add1300, %or1260
  %add1304 = add i32 %add1302, %xor1299
  %or1309 = tail call i32 @llvm.fshl.i32(i32 %add1304, i32 %add1304, i32 5)
  %add1310 = add i32 %or1309, %or1278
  %or1314 = tail call i32 @llvm.fshl.i32(i32 %add1274, i32 %add1274, i32 10)
  %xor1315 = xor i32 %add1310, %add1292
  %and1316 = and i32 %xor1315, %or1314
  %xor1317 = xor i32 %and1316, %add1292
  %add1318 = add i32 %or514, -1894007588
  %add1320 = add i32 %add1318, %or1278
  %add1322 = add i32 %add1320, %xor1317
  %or1327 = tail call i32 @llvm.fshl.i32(i32 %add1322, i32 %add1322, i32 6)
  %add1328 = add i32 %or1327, %or1296
  %or1332 = tail call i32 @llvm.fshl.i32(i32 %add1292, i32 %add1292, i32 10)
  %xor1333 = xor i32 %add1328, %add1310
  %and1334 = and i32 %xor1333, %or1332
  %xor1335 = xor i32 %and1334, %add1310
  %add1336 = add i32 %or480, -1894007588
  %add1338 = add i32 %add1336, %or1296
  %add1340 = add i32 %add1338, %xor1335
  %or1345 = tail call i32 @llvm.fshl.i32(i32 %add1340, i32 %add1340, i32 8)
  %add1346 = add i32 %or1345, %or1314
  %or1350 = tail call i32 @llvm.fshl.i32(i32 %add1310, i32 %add1310, i32 10)
  %xor1351 = xor i32 %add1346, %add1328
  %and1352 = and i32 %xor1351, %or1350
  %xor1353 = xor i32 %and1352, %add1328
  %add1354 = add i32 %or174, -1894007588
  %add1356 = add i32 %add1354, %or1314
  %add1358 = add i32 %add1356, %xor1353
  %or1363 = tail call i32 @llvm.fshl.i32(i32 %add1358, i32 %add1358, i32 6)
  %add1364 = add i32 %or1363, %or1332
  %or1368 = tail call i32 @llvm.fshl.i32(i32 %add1328, i32 %add1328, i32 10)
  %xor1369 = xor i32 %add1364, %add1346
  %and1370 = and i32 %xor1369, %or1368
  %xor1371 = xor i32 %and1370, %add1346
  %add1372 = add i32 %or208, -1894007588
  %add1374 = add i32 %add1372, %or1332
  %add1376 = add i32 %add1374, %xor1371
  %or1381 = tail call i32 @llvm.fshl.i32(i32 %add1376, i32 %add1376, i32 5)
  %add1382 = add i32 %or1381, %or1350
  %or1386 = tail call i32 @llvm.fshl.i32(i32 %add1346, i32 %add1346, i32 10)
  %xor1387 = xor i32 %add1382, %add1364
  %and1388 = and i32 %xor1387, %or1386
  %xor1389 = xor i32 %and1388, %add1364
  %add1390 = add i32 %or72, -1894007588
  %add1392 = add i32 %add1390, %or1350
  %add1394 = add i32 %add1392, %xor1389
  %or1399 = tail call i32 @llvm.fshl.i32(i32 %add1394, i32 %add1394, i32 12)
  %add1400 = add i32 %or1399, %or1368
  %or1404 = tail call i32 @llvm.fshl.i32(i32 %add1364, i32 %add1364, i32 10)
  %neg1405 = xor i32 %or1404, -1
  %or1406 = or i32 %add1382, %neg1405
  %xor1407 = xor i32 %add1400, %or1406
  %add1408 = add i32 %or140, -1454113458
  %add1410 = add i32 %add1408, %or1368
  %add1412 = add i32 %add1410, %xor1407
  %or1417 = tail call i32 @llvm.fshl.i32(i32 %add1412, i32 %add1412, i32 9)
  %add1418 = add i32 %or1417, %or1386
  %or1422 = tail call i32 @llvm.fshl.i32(i32 %add1382, i32 %add1382, i32 10)
  %neg1423 = xor i32 %or1422, -1
  %or1424 = or i32 %add1400, %neg1423
  %xor1425 = xor i32 %add1418, %or1424
  %add1426 = add i32 %or21, -1454113458
  %add1428 = add i32 %add1426, %or1386
  %add1430 = add i32 %add1428, %xor1425
  %or1435 = tail call i32 @llvm.fshl.i32(i32 %add1430, i32 %add1430, i32 15)
  %add1436 = add i32 %or1435, %or1404
  %or1440 = tail call i32 @llvm.fshl.i32(i32 %add1400, i32 %add1400, i32 10)
  %neg1441 = xor i32 %or1440, -1
  %or1442 = or i32 %add1418, %neg1441
  %xor1443 = xor i32 %add1436, %or1442
  %add1444 = add i32 %or174, -1454113458
  %add1446 = add i32 %add1444, %or1404
  %add1448 = add i32 %add1446, %xor1443
  %or1453 = tail call i32 @llvm.fshl.i32(i32 %add1448, i32 %add1448, i32 5)
  %add1454 = add i32 %or1453, %or1422
  %or1458 = tail call i32 @llvm.fshl.i32(i32 %add1418, i32 %add1418, i32 10)
  %neg1459 = xor i32 %or1458, -1
  %or1460 = or i32 %add1436, %neg1459
  %xor1461 = xor i32 %add1454, %or1460
  %add1462 = add i32 %or310, -1454113458
  %add1464 = add i32 %add1462, %or1422
  %add1466 = add i32 %add1464, %xor1461
  %or1471 = tail call i32 @llvm.fshl.i32(i32 %add1466, i32 %add1466, i32 11)
  %add1472 = add i32 %or1471, %or1440
  %or1476 = tail call i32 @llvm.fshl.i32(i32 %add1436, i32 %add1436, i32 10)
  %neg1477 = xor i32 %or1476, -1
  %or1478 = or i32 %add1454, %neg1477
  %xor1479 = xor i32 %add1472, %or1478
  %add1480 = add i32 %or242, -1454113458
  %add1482 = add i32 %add1480, %or1440
  %add1484 = add i32 %add1482, %xor1479
  %or1489 = tail call i32 @llvm.fshl.i32(i32 %add1484, i32 %add1484, i32 6)
  %add1490 = add i32 %or1489, %or1458
  %or1494 = tail call i32 @llvm.fshl.i32(i32 %add1454, i32 %add1454, i32 10)
  %neg1495 = xor i32 %or1494, -1
  %or1496 = or i32 %add1472, %neg1495
  %xor1497 = xor i32 %add1490, %or1496
  %add1498 = add i32 %or412, -1454113458
  %add1500 = add i32 %add1498, %or1458
  %add1502 = add i32 %add1500, %xor1497
  %or1507 = tail call i32 @llvm.fshl.i32(i32 %add1502, i32 %add1502, i32 8)
  %add1508 = add i32 %or1507, %or1476
  %or1512 = tail call i32 @llvm.fshl.i32(i32 %add1472, i32 %add1472, i32 10)
  %neg1513 = xor i32 %or1512, -1
  %or1514 = or i32 %add1490, %neg1513
  %xor1515 = xor i32 %add1508, %or1514
  %add1516 = add i32 %or72, -1454113458
  %add1518 = add i32 %add1516, %or1476
  %add1520 = add i32 %add1518, %xor1515
  %or1525 = tail call i32 @llvm.fshl.i32(i32 %add1520, i32 %add1520, i32 13)
  %add1526 = add i32 %or1525, %or1494
  %or1530 = tail call i32 @llvm.fshl.i32(i32 %add1490, i32 %add1490, i32 10)
  %neg1531 = xor i32 %or1530, -1
  %or1532 = or i32 %add1508, %neg1531
  %xor1533 = xor i32 %add1526, %or1532
  %add1534 = add i32 %or344, -1454113458
  %add1536 = add i32 %add1534, %or1494
  %add1538 = add i32 %add1536, %xor1533
  %or1543 = tail call i32 @llvm.fshl.i32(i32 %add1538, i32 %add1538, i32 12)
  %add1544 = add i32 %or1543, %or1512
  %or1548 = tail call i32 @llvm.fshl.i32(i32 %add1508, i32 %add1508, i32 10)
  %neg1549 = xor i32 %or1548, -1
  %or1550 = or i32 %add1526, %neg1549
  %xor1551 = xor i32 %add1544, %or1550
  %add1552 = add i32 %or480, -1454113458
  %add1554 = add i32 %add1552, %or1512
  %add1556 = add i32 %add1554, %xor1551
  %or1561 = tail call i32 @llvm.fshl.i32(i32 %add1556, i32 %add1556, i32 5)
  %add1562 = add i32 %or1561, %or1530
  %or1566 = tail call i32 @llvm.fshl.i32(i32 %add1526, i32 %add1526, i32 10)
  %neg1567 = xor i32 %or1566, -1
  %or1568 = or i32 %add1544, %neg1567
  %xor1569 = xor i32 %add1562, %or1568
  %add1570 = add i32 %or42, -1454113458
  %add1572 = add i32 %add1570, %or1530
  %add1574 = add i32 %add1572, %xor1569
  %or1579 = tail call i32 @llvm.fshl.i32(i32 %add1574, i32 %add1574, i32 12)
  %add1580 = add i32 %or1579, %or1548
  %or1584 = tail call i32 @llvm.fshl.i32(i32 %add1544, i32 %add1544, i32 10)
  %neg1585 = xor i32 %or1584, -1
  %or1586 = or i32 %add1562, %neg1585
  %xor1587 = xor i32 %add1580, %or1586
  %add1588 = add i32 %or106, -1454113458
  %add1590 = add i32 %add1588, %or1548
  %add1592 = add i32 %add1590, %xor1587
  %or1597 = tail call i32 @llvm.fshl.i32(i32 %add1592, i32 %add1592, i32 13)
  %add1598 = add i32 %or1597, %or1566
  %or1602 = tail call i32 @llvm.fshl.i32(i32 %add1562, i32 %add1562, i32 10)
  %neg1603 = xor i32 %or1602, -1
  %or1604 = or i32 %add1580, %neg1603
  %xor1605 = xor i32 %add1598, %or1604
  %add1606 = add i32 %or276, -1454113458
  %add1608 = add i32 %add1606, %or1566
  %add1610 = add i32 %add1608, %xor1605
  %or1615 = tail call i32 @llvm.fshl.i32(i32 %add1610, i32 %add1610, i32 14)
  %add1616 = add i32 %or1615, %or1584
  %or1620 = tail call i32 @llvm.fshl.i32(i32 %add1580, i32 %add1580, i32 10)
  %neg1621 = xor i32 %or1620, -1
  %or1622 = or i32 %add1598, %neg1621
  %xor1623 = xor i32 %add1616, %or1622
  %add1624 = add i32 %or378, -1454113458
  %add1626 = add i32 %add1624, %or1584
  %add1628 = add i32 %add1626, %xor1623
  %or1633 = tail call i32 @llvm.fshl.i32(i32 %add1628, i32 %add1628, i32 11)
  %add1634 = add i32 %or1633, %or1602
  %or1638 = tail call i32 @llvm.fshl.i32(i32 %add1598, i32 %add1598, i32 10)
  %neg1639 = xor i32 %or1638, -1
  %or1640 = or i32 %add1616, %neg1639
  %xor1641 = xor i32 %add1634, %or1640
  %add1642 = add i32 %or208, -1454113458
  %add1644 = add i32 %add1642, %or1602
  %add1646 = add i32 %add1644, %xor1641
  %or1651 = tail call i32 @llvm.fshl.i32(i32 %add1646, i32 %add1646, i32 8)
  %add1652 = add i32 %or1651, %or1620
  %or1656 = tail call i32 @llvm.fshl.i32(i32 %add1616, i32 %add1616, i32 10)
  %neg1657 = xor i32 %or1656, -1
  %or1658 = or i32 %add1634, %neg1657
  %xor1659 = xor i32 %add1652, %or1658
  %add1660 = add i32 %or514, -1454113458
  %add1662 = add i32 %add1660, %or1620
  %add1664 = add i32 %add1662, %xor1659
  %or1669 = tail call i32 @llvm.fshl.i32(i32 %add1664, i32 %add1664, i32 5)
  %add1670 = add i32 %or1669, %or1638
  %or1674 = tail call i32 @llvm.fshl.i32(i32 %add1634, i32 %add1634, i32 10)
  %neg1675 = xor i32 %or1674, -1
  %or1676 = or i32 %add1652, %neg1675
  %xor1677 = xor i32 %add1670, %or1676
  %add1678 = add i32 %or446, -1454113458
  %add1680 = add i32 %add1678, %or1638
  %add1682 = add i32 %add1680, %xor1677
  %or1687 = tail call i32 @llvm.fshl.i32(i32 %add1682, i32 %add1682, i32 6)
  %or1692 = tail call i32 @llvm.fshl.i32(i32 %add1652, i32 %add1652, i32 10)
  %neg1698 = xor i32 %1, -1
  %or1699 = or i32 %2, %neg1698
  %xor1700 = xor i32 %or1699, %3
  %add1701 = add i32 %4, 1352829926
  %add1703 = add i32 %add1701, %xor1700
  %add1705 = add i32 %add1703, %or174
  %or1710 = tail call i32 @llvm.fshl.i32(i32 %add1705, i32 %add1705, i32 8)
  %add1711 = add i32 %or1710, %0
  %neg1716 = xor i32 %or52, -1
  %or1717 = or i32 %3, %neg1716
  %xor1718 = xor i32 %add1711, %or1717
  %add1719 = add i32 %0, 1352829926
  %add1721 = add i32 %add1719, %xor1718
  %add1723 = add i32 %add1721, %or480
  %or1728 = tail call i32 @llvm.fshl.i32(i32 %add1723, i32 %add1723, i32 9)
  %add1729 = add i32 %or1728, %1
  %neg1734 = xor i32 %or86, -1
  %or1735 = or i32 %add1711, %neg1734
  %xor1736 = xor i32 %add1729, %or1735
  %add1737 = add i32 %1, 1352829926
  %add1739 = add i32 %add1737, %or242
  %add1741 = add i32 %add1739, %xor1736
  %or1746 = tail call i32 @llvm.fshl.i32(i32 %add1741, i32 %add1741, i32 9)
  %add1747 = add i32 %or1746, %or52
  %or1751 = tail call i32 @llvm.fshl.i32(i32 %add1711, i32 %add1711, i32 10)
  %neg1752 = xor i32 %or1751, -1
  %or1753 = or i32 %add1729, %neg1752
  %xor1754 = xor i32 %add1747, %or1753
  %add1755 = add i32 %or52, 1352829926
  %add1757 = add i32 %add1755, %or21
  %add1759 = add i32 %add1757, %xor1754
  %or1764 = tail call i32 @llvm.fshl.i32(i32 %add1759, i32 %add1759, i32 11)
  %add1765 = add i32 %or1764, %or86
  %or1769 = tail call i32 @llvm.fshl.i32(i32 %add1729, i32 %add1729, i32 10)
  %neg1770 = xor i32 %or1769, -1
  %or1771 = or i32 %add1747, %neg1770
  %xor1772 = xor i32 %add1765, %or1771
  %add1773 = add i32 %or86, 1352829926
  %add1775 = add i32 %add1773, %or310
  %add1777 = add i32 %add1775, %xor1772
  %or1782 = tail call i32 @llvm.fshl.i32(i32 %add1777, i32 %add1777, i32 13)
  %add1783 = add i32 %or1782, %or1751
  %or1787 = tail call i32 @llvm.fshl.i32(i32 %add1747, i32 %add1747, i32 10)
  %neg1788 = xor i32 %or1787, -1
  %or1789 = or i32 %add1765, %neg1788
  %xor1790 = xor i32 %add1783, %or1789
  %add1791 = add i32 %or72, 1352829926
  %add1793 = add i32 %add1791, %or1751
  %add1795 = add i32 %add1793, %xor1790
  %or1800 = tail call i32 @llvm.fshl.i32(i32 %add1795, i32 %add1795, i32 15)
  %add1801 = add i32 %or1800, %or1769
  %or1805 = tail call i32 @llvm.fshl.i32(i32 %add1765, i32 %add1765, i32 10)
  %neg1806 = xor i32 %or1805, -1
  %or1807 = or i32 %add1783, %neg1806
  %xor1808 = xor i32 %add1801, %or1807
  %add1809 = add i32 %or378, 1352829926
  %add1811 = add i32 %add1809, %or1769
  %add1813 = add i32 %add1811, %xor1808
  %or1818 = tail call i32 @llvm.fshl.i32(i32 %add1813, i32 %add1813, i32 15)
  %add1819 = add i32 %or1818, %or1787
  %or1823 = tail call i32 @llvm.fshl.i32(i32 %add1783, i32 %add1783, i32 10)
  %neg1824 = xor i32 %or1823, -1
  %or1825 = or i32 %add1801, %neg1824
  %xor1826 = xor i32 %add1819, %or1825
  %add1827 = add i32 %or140, 1352829926
  %add1829 = add i32 %add1827, %or1787
  %add1831 = add i32 %add1829, %xor1826
  %or1836 = tail call i32 @llvm.fshl.i32(i32 %add1831, i32 %add1831, i32 5)
  %add1837 = add i32 %or1836, %or1805
  %or1841 = tail call i32 @llvm.fshl.i32(i32 %add1801, i32 %add1801, i32 10)
  %neg1842 = xor i32 %or1841, -1
  %or1843 = or i32 %add1819, %neg1842
  %xor1844 = xor i32 %add1837, %or1843
  %add1845 = add i32 %or446, 1352829926
  %add1847 = add i32 %add1845, %or1805
  %add1849 = add i32 %add1847, %xor1844
  %or1854 = tail call i32 @llvm.fshl.i32(i32 %add1849, i32 %add1849, i32 7)
  %add1855 = add i32 %or1854, %or1823
  %or1859 = tail call i32 @llvm.fshl.i32(i32 %add1819, i32 %add1819, i32 10)
  %neg1860 = xor i32 %or1859, -1
  %or1861 = or i32 %add1837, %neg1860
  %xor1862 = xor i32 %add1855, %or1861
  %add1863 = add i32 %or208, 1352829926
  %add1865 = add i32 %add1863, %or1823
  %add1867 = add i32 %add1865, %xor1862
  %or1872 = tail call i32 @llvm.fshl.i32(i32 %add1867, i32 %add1867, i32 7)
  %add1873 = add i32 %or1872, %or1841
  %or1877 = tail call i32 @llvm.fshl.i32(i32 %add1837, i32 %add1837, i32 10)
  %neg1878 = xor i32 %or1877, -1
  %or1879 = or i32 %add1855, %neg1878
  %xor1880 = xor i32 %add1873, %or1879
  %add1881 = add i32 %or514, 1352829926
  %add1883 = add i32 %add1881, %or1841
  %add1885 = add i32 %add1883, %xor1880
  %or1890 = tail call i32 @llvm.fshl.i32(i32 %add1885, i32 %add1885, i32 8)
  %add1891 = add i32 %or1890, %or1859
  %or1895 = tail call i32 @llvm.fshl.i32(i32 %add1855, i32 %add1855, i32 10)
  %neg1896 = xor i32 %or1895, -1
  %or1897 = or i32 %add1873, %neg1896
  %xor1898 = xor i32 %add1891, %or1897
  %add1899 = add i32 %or276, 1352829926
  %add1901 = add i32 %add1899, %or1859
  %add1903 = add i32 %add1901, %xor1898
  %or1908 = tail call i32 @llvm.fshl.i32(i32 %add1903, i32 %add1903, i32 11)
  %add1909 = add i32 %or1908, %or1877
  %or1913 = tail call i32 @llvm.fshl.i32(i32 %add1873, i32 %add1873, i32 10)
  %neg1914 = xor i32 %or1913, -1
  %or1915 = or i32 %add1891, %neg1914
  %xor1916 = xor i32 %add1909, %or1915
  %add1917 = add i32 %or42, 1352829926
  %add1919 = add i32 %add1917, %or1877
  %add1921 = add i32 %add1919, %xor1916
  %or1926 = tail call i32 @llvm.fshl.i32(i32 %add1921, i32 %add1921, i32 14)
  %add1927 = add i32 %or1926, %or1895
  %or1931 = tail call i32 @llvm.fshl.i32(i32 %add1891, i32 %add1891, i32 10)
  %neg1932 = xor i32 %or1931, -1
  %or1933 = or i32 %add1909, %neg1932
  %xor1934 = xor i32 %add1927, %or1933
  %add1935 = add i32 %or344, 1352829926
  %add1937 = add i32 %add1935, %or1895
  %add1939 = add i32 %add1937, %xor1934
  %or1944 = tail call i32 @llvm.fshl.i32(i32 %add1939, i32 %add1939, i32 14)
  %add1945 = add i32 %or1944, %or1913
  %or1949 = tail call i32 @llvm.fshl.i32(i32 %add1909, i32 %add1909, i32 10)
  %neg1950 = xor i32 %or1949, -1
  %or1951 = or i32 %add1927, %neg1950
  %xor1952 = xor i32 %add1945, %or1951
  %add1953 = add i32 %or106, 1352829926
  %add1955 = add i32 %add1953, %or1913
  %add1957 = add i32 %add1955, %xor1952
  %or1962 = tail call i32 @llvm.fshl.i32(i32 %add1957, i32 %add1957, i32 12)
  %add1963 = add i32 %or1962, %or1931
  %or1967 = tail call i32 @llvm.fshl.i32(i32 %add1927, i32 %add1927, i32 10)
  %neg1968 = xor i32 %or1967, -1
  %or1969 = or i32 %add1945, %neg1968
  %xor1970 = xor i32 %add1963, %or1969
  %add1971 = add i32 %or412, 1352829926
  %add1973 = add i32 %add1971, %or1931
  %add1975 = add i32 %add1973, %xor1970
  %or1980 = tail call i32 @llvm.fshl.i32(i32 %add1975, i32 %add1975, i32 6)
  %add1981 = add i32 %or1980, %or1949
  %or1985 = tail call i32 @llvm.fshl.i32(i32 %add1945, i32 %add1945, i32 10)
  %xor1986 = xor i32 %add1981, %add1963
  %and1987 = and i32 %xor1986, %or1985
  %xor1988 = xor i32 %and1987, %add1963
  %add1989 = add i32 %or208, 1548603684
  %add1991 = add i32 %add1989, %or1949
  %add1993 = add i32 %add1991, %xor1988
  %or1998 = tail call i32 @llvm.fshl.i32(i32 %add1993, i32 %add1993, i32 9)
  %add1999 = add i32 %or1998, %or1967
  %or2003 = tail call i32 @llvm.fshl.i32(i32 %add1963, i32 %add1963, i32 10)
  %xor2004 = xor i32 %add1999, %add1981
  %and2005 = and i32 %xor2004, %or2003
  %xor2006 = xor i32 %and2005, %add1981
  %add2007 = add i32 %or378, 1548603684
  %add2009 = add i32 %add2007, %or1967
  %add2011 = add i32 %add2009, %xor2006
  %or2016 = tail call i32 @llvm.fshl.i32(i32 %add2011, i32 %add2011, i32 13)
  %add2017 = add i32 %or2016, %or1985
  %or2021 = tail call i32 @llvm.fshl.i32(i32 %add1981, i32 %add1981, i32 10)
  %xor2022 = xor i32 %add2017, %add1999
  %and2023 = and i32 %xor2022, %or2021
  %xor2024 = xor i32 %and2023, %add1999
  %add2025 = add i32 %or106, 1548603684
  %add2027 = add i32 %add2025, %or1985
  %add2029 = add i32 %add2027, %xor2024
  %or2034 = tail call i32 @llvm.fshl.i32(i32 %add2029, i32 %add2029, i32 15)
  %add2035 = add i32 %or2034, %or2003
  %or2039 = tail call i32 @llvm.fshl.i32(i32 %add1999, i32 %add1999, i32 10)
  %xor2040 = xor i32 %add2035, %add2017
  %and2041 = and i32 %xor2040, %or2039
  %xor2042 = xor i32 %and2041, %add2017
  %add2043 = add i32 %or242, 1548603684
  %add2045 = add i32 %add2043, %or2003
  %add2047 = add i32 %add2045, %xor2042
  %or2052 = tail call i32 @llvm.fshl.i32(i32 %add2047, i32 %add2047, i32 7)
  %add2053 = add i32 %or2052, %or2021
  %or2057 = tail call i32 @llvm.fshl.i32(i32 %add2017, i32 %add2017, i32 10)
  %xor2058 = xor i32 %add2053, %add2035
  %and2059 = and i32 %xor2058, %or2057
  %xor2060 = xor i32 %and2059, %add2035
  %add2061 = add i32 %or21, 1548603684
  %add2063 = add i32 %add2061, %or2021
  %add2065 = add i32 %add2063, %xor2060
  %or2070 = tail call i32 @llvm.fshl.i32(i32 %add2065, i32 %add2065, i32 12)
  %add2071 = add i32 %or2070, %or2039
  %or2075 = tail call i32 @llvm.fshl.i32(i32 %add2035, i32 %add2035, i32 10)
  %xor2076 = xor i32 %add2071, %add2053
  %and2077 = and i32 %xor2076, %or2075
  %xor2078 = xor i32 %and2077, %add2053
  %add2079 = add i32 %or446, 1548603684
  %add2081 = add i32 %add2079, %or2039
  %add2083 = add i32 %add2081, %xor2078
  %or2088 = tail call i32 @llvm.fshl.i32(i32 %add2083, i32 %add2083, i32 8)
  %add2089 = add i32 %or2088, %or2057
  %or2093 = tail call i32 @llvm.fshl.i32(i32 %add2053, i32 %add2053, i32 10)
  %xor2094 = xor i32 %add2089, %add2071
  %and2095 = and i32 %xor2094, %or2093
  %xor2096 = xor i32 %and2095, %add2071
  %add2097 = add i32 %or174, 1548603684
  %add2099 = add i32 %add2097, %or2057
  %add2101 = add i32 %add2099, %xor2096
  %or2106 = tail call i32 @llvm.fshl.i32(i32 %add2101, i32 %add2101, i32 9)
  %add2107 = add i32 %or2106, %or2075
  %or2111 = tail call i32 @llvm.fshl.i32(i32 %add2071, i32 %add2071, i32 10)
  %xor2112 = xor i32 %add2107, %add2089
  %and2113 = and i32 %xor2112, %or2111
  %xor2114 = xor i32 %and2113, %add2089
  %add2115 = add i32 %or344, 1548603684
  %add2117 = add i32 %add2115, %or2075
  %add2119 = add i32 %add2117, %xor2114
  %or2124 = tail call i32 @llvm.fshl.i32(i32 %add2119, i32 %add2119, i32 11)
  %add2125 = add i32 %or2124, %or2093
  %or2129 = tail call i32 @llvm.fshl.i32(i32 %add2089, i32 %add2089, i32 10)
  %xor2130 = xor i32 %add2125, %add2107
  %and2131 = and i32 %xor2130, %or2129
  %xor2132 = xor i32 %and2131, %add2107
  %add2133 = add i32 %or480, 1548603684
  %add2135 = add i32 %add2133, %or2093
  %add2137 = add i32 %add2135, %xor2132
  %or2142 = tail call i32 @llvm.fshl.i32(i32 %add2137, i32 %add2137, i32 7)
  %add2143 = add i32 %or2142, %or2111
  %or2147 = tail call i32 @llvm.fshl.i32(i32 %add2107, i32 %add2107, i32 10)
  %xor2148 = xor i32 %add2143, %add2125
  %and2149 = and i32 %xor2148, %or2147
  %xor2150 = xor i32 %and2149, %add2125
  %add2151 = add i32 %or514, 1548603684
  %add2153 = add i32 %add2151, %or2111
  %add2155 = add i32 %add2153, %xor2150
  %or2160 = tail call i32 @llvm.fshl.i32(i32 %add2155, i32 %add2155, i32 7)
  %add2161 = add i32 %or2160, %or2129
  %or2165 = tail call i32 @llvm.fshl.i32(i32 %add2125, i32 %add2125, i32 10)
  %xor2166 = xor i32 %add2161, %add2143
  %and2167 = and i32 %xor2166, %or2165
  %xor2168 = xor i32 %and2167, %add2143
  %add2169 = add i32 %or276, 1548603684
  %add2171 = add i32 %add2169, %or2129
  %add2173 = add i32 %add2171, %xor2168
  %or2178 = tail call i32 @llvm.fshl.i32(i32 %add2173, i32 %add2173, i32 12)
  %add2179 = add i32 %or2178, %or2147
  %or2183 = tail call i32 @llvm.fshl.i32(i32 %add2143, i32 %add2143, i32 10)
  %xor2184 = xor i32 %add2179, %add2161
  %and2185 = and i32 %xor2184, %or2183
  %xor2186 = xor i32 %and2185, %add2161
  %add2187 = add i32 %or412, 1548603684
  %add2189 = add i32 %add2187, %or2147
  %add2191 = add i32 %add2189, %xor2186
  %or2196 = tail call i32 @llvm.fshl.i32(i32 %add2191, i32 %add2191, i32 7)
  %add2197 = add i32 %or2196, %or2165
  %or2201 = tail call i32 @llvm.fshl.i32(i32 %add2161, i32 %add2161, i32 10)
  %xor2202 = xor i32 %add2197, %add2179
  %and2203 = and i32 %xor2202, %or2201
  %xor2204 = xor i32 %and2203, %add2179
  %add2205 = add i32 %or140, 1548603684
  %add2207 = add i32 %add2205, %or2165
  %add2209 = add i32 %add2207, %xor2204
  %or2214 = tail call i32 @llvm.fshl.i32(i32 %add2209, i32 %add2209, i32 6)
  %add2215 = add i32 %or2214, %or2183
  %or2219 = tail call i32 @llvm.fshl.i32(i32 %add2179, i32 %add2179, i32 10)
  %xor2220 = xor i32 %add2215, %add2197
  %and2221 = and i32 %xor2220, %or2219
  %xor2222 = xor i32 %and2221, %add2197
  %add2223 = add i32 %or310, 1548603684
  %add2225 = add i32 %add2223, %or2183
  %add2227 = add i32 %add2225, %xor2222
  %or2232 = tail call i32 @llvm.fshl.i32(i32 %add2227, i32 %add2227, i32 15)
  %add2233 = add i32 %or2232, %or2201
  %or2237 = tail call i32 @llvm.fshl.i32(i32 %add2197, i32 %add2197, i32 10)
  %xor2238 = xor i32 %add2233, %add2215
  %and2239 = and i32 %xor2238, %or2237
  %xor2240 = xor i32 %and2239, %add2215
  %add2241 = add i32 %or42, 1548603684
  %add2243 = add i32 %add2241, %or2201
  %add2245 = add i32 %add2243, %xor2240
  %or2250 = tail call i32 @llvm.fshl.i32(i32 %add2245, i32 %add2245, i32 13)
  %add2251 = add i32 %or2250, %or2219
  %or2255 = tail call i32 @llvm.fshl.i32(i32 %add2215, i32 %add2215, i32 10)
  %xor2256 = xor i32 %add2251, %add2233
  %and2257 = and i32 %xor2256, %or2255
  %xor2258 = xor i32 %and2257, %add2233
  %add2259 = add i32 %or72, 1548603684
  %add2261 = add i32 %add2259, %or2219
  %add2263 = add i32 %add2261, %xor2258
  %or2268 = tail call i32 @llvm.fshl.i32(i32 %add2263, i32 %add2263, i32 11)
  %add2269 = add i32 %or2268, %or2237
  %or2273 = tail call i32 @llvm.fshl.i32(i32 %add2233, i32 %add2233, i32 10)
  %neg2274 = xor i32 %add2251, -1
  %or2275 = or i32 %add2269, %neg2274
  %xor2276 = xor i32 %or2275, %or2273
  %add2277 = add i32 %or514, 1836072691
  %add2279 = add i32 %add2277, %or2237
  %add2281 = add i32 %add2279, %xor2276
  %or2286 = tail call i32 @llvm.fshl.i32(i32 %add2281, i32 %add2281, i32 9)
  %add2287 = add i32 %or2286, %or2255
  %or2291 = tail call i32 @llvm.fshl.i32(i32 %add2251, i32 %add2251, i32 10)
  %neg2292 = xor i32 %add2269, -1
  %or2293 = or i32 %add2287, %neg2292
  %xor2294 = xor i32 %or2293, %or2291
  %add2295 = add i32 %or174, 1836072691
  %add2297 = add i32 %add2295, %or2255
  %add2299 = add i32 %add2297, %xor2294
  %or2304 = tail call i32 @llvm.fshl.i32(i32 %add2299, i32 %add2299, i32 7)
  %add2305 = add i32 %or2304, %or2273
  %or2309 = tail call i32 @llvm.fshl.i32(i32 %add2269, i32 %add2269, i32 10)
  %neg2310 = xor i32 %add2287, -1
  %or2311 = or i32 %add2305, %neg2310
  %xor2312 = xor i32 %or2311, %or2309
  %add2313 = add i32 %or42, 1836072691
  %add2315 = add i32 %add2313, %or2273
  %add2317 = add i32 %add2315, %xor2312
  %or2322 = tail call i32 @llvm.fshl.i32(i32 %add2317, i32 %add2317, i32 15)
  %add2323 = add i32 %or2322, %or2291
  %or2327 = tail call i32 @llvm.fshl.i32(i32 %add2287, i32 %add2287, i32 10)
  %neg2328 = xor i32 %add2305, -1
  %or2329 = or i32 %add2323, %neg2328
  %xor2330 = xor i32 %or2329, %or2327
  %add2331 = add i32 %or106, 1836072691
  %add2333 = add i32 %add2331, %or2291
  %add2335 = add i32 %add2333, %xor2330
  %or2340 = tail call i32 @llvm.fshl.i32(i32 %add2335, i32 %add2335, i32 11)
  %add2341 = add i32 %or2340, %or2309
  %or2345 = tail call i32 @llvm.fshl.i32(i32 %add2305, i32 %add2305, i32 10)
  %neg2346 = xor i32 %add2323, -1
  %or2347 = or i32 %add2341, %neg2346
  %xor2348 = xor i32 %or2347, %or2345
  %add2349 = add i32 %or242, 1836072691
  %add2351 = add i32 %add2349, %or2309
  %add2353 = add i32 %add2351, %xor2348
  %or2358 = tail call i32 @llvm.fshl.i32(i32 %add2353, i32 %add2353, i32 8)
  %add2359 = add i32 %or2358, %or2327
  %or2363 = tail call i32 @llvm.fshl.i32(i32 %add2323, i32 %add2323, i32 10)
  %neg2364 = xor i32 %add2341, -1
  %or2365 = or i32 %add2359, %neg2364
  %xor2366 = xor i32 %or2365, %or2363
  %add2367 = add i32 %or480, 1836072691
  %add2369 = add i32 %add2367, %or2327
  %add2371 = add i32 %add2369, %xor2366
  %or2376 = tail call i32 @llvm.fshl.i32(i32 %add2371, i32 %add2371, i32 6)
  %add2377 = add i32 %or2376, %or2345
  %or2381 = tail call i32 @llvm.fshl.i32(i32 %add2341, i32 %add2341, i32 10)
  %neg2382 = xor i32 %add2359, -1
  %or2383 = or i32 %add2377, %neg2382
  %xor2384 = xor i32 %or2383, %or2381
  %add2385 = add i32 %or208, 1836072691
  %add2387 = add i32 %add2385, %or2345
  %add2389 = add i32 %add2387, %xor2384
  %or2394 = tail call i32 @llvm.fshl.i32(i32 %add2389, i32 %add2389, i32 6)
  %add2395 = add i32 %or2394, %or2363
  %or2399 = tail call i32 @llvm.fshl.i32(i32 %add2359, i32 %add2359, i32 10)
  %neg2400 = xor i32 %add2377, -1
  %or2401 = or i32 %add2395, %neg2400
  %xor2402 = xor i32 %or2401, %or2399
  %add2403 = add i32 %or310, 1836072691
  %add2405 = add i32 %add2403, %or2363
  %add2407 = add i32 %add2405, %xor2402
  %or2412 = tail call i32 @llvm.fshl.i32(i32 %add2407, i32 %add2407, i32 14)
  %add2413 = add i32 %or2412, %or2381
  %or2417 = tail call i32 @llvm.fshl.i32(i32 %add2377, i32 %add2377, i32 10)
  %neg2418 = xor i32 %add2395, -1
  %or2419 = or i32 %add2413, %neg2418
  %xor2420 = xor i32 %or2419, %or2417
  %add2421 = add i32 %or378, 1836072691
  %add2423 = add i32 %add2421, %or2381
  %add2425 = add i32 %add2423, %xor2420
  %or2430 = tail call i32 @llvm.fshl.i32(i32 %add2425, i32 %add2425, i32 12)
  %add2431 = add i32 %or2430, %or2399
  %or2435 = tail call i32 @llvm.fshl.i32(i32 %add2395, i32 %add2395, i32 10)
  %neg2436 = xor i32 %add2413, -1
  %or2437 = or i32 %add2431, %neg2436
  %xor2438 = xor i32 %or2437, %or2435
  %add2439 = add i32 %or276, 1836072691
  %add2441 = add i32 %add2439, %or2399
  %add2443 = add i32 %add2441, %xor2438
  %or2448 = tail call i32 @llvm.fshl.i32(i32 %add2443, i32 %add2443, i32 13)
  %add2449 = add i32 %or2448, %or2417
  %or2453 = tail call i32 @llvm.fshl.i32(i32 %add2413, i32 %add2413, i32 10)
  %neg2454 = xor i32 %add2431, -1
  %or2455 = or i32 %add2449, %neg2454
  %xor2456 = xor i32 %or2455, %or2453
  %add2457 = add i32 %or412, 1836072691
  %add2459 = add i32 %add2457, %or2417
  %add2461 = add i32 %add2459, %xor2456
  %or2466 = tail call i32 @llvm.fshl.i32(i32 %add2461, i32 %add2461, i32 5)
  %add2467 = add i32 %or2466, %or2435
  %or2471 = tail call i32 @llvm.fshl.i32(i32 %add2431, i32 %add2431, i32 10)
  %neg2472 = xor i32 %add2449, -1
  %or2473 = or i32 %add2467, %neg2472
  %xor2474 = xor i32 %or2473, %or2471
  %add2475 = add i32 %or72, 1836072691
  %add2477 = add i32 %add2475, %or2435
  %add2479 = add i32 %add2477, %xor2474
  %or2484 = tail call i32 @llvm.fshl.i32(i32 %add2479, i32 %add2479, i32 14)
  %add2485 = add i32 %or2484, %or2453
  %or2489 = tail call i32 @llvm.fshl.i32(i32 %add2449, i32 %add2449, i32 10)
  %neg2490 = xor i32 %add2467, -1
  %or2491 = or i32 %add2485, %neg2490
  %xor2492 = xor i32 %or2491, %or2489
  %add2493 = add i32 %or344, 1836072691
  %add2495 = add i32 %add2493, %or2453
  %add2497 = add i32 %add2495, %xor2492
  %or2502 = tail call i32 @llvm.fshl.i32(i32 %add2497, i32 %add2497, i32 13)
  %add2503 = add i32 %or2502, %or2471
  %or2507 = tail call i32 @llvm.fshl.i32(i32 %add2467, i32 %add2467, i32 10)
  %neg2508 = xor i32 %add2485, -1
  %or2509 = or i32 %add2503, %neg2508
  %xor2510 = xor i32 %or2509, %or2507
  %add2511 = add i32 %or21, 1836072691
  %add2513 = add i32 %add2511, %or2471
  %add2515 = add i32 %add2513, %xor2510
  %or2520 = tail call i32 @llvm.fshl.i32(i32 %add2515, i32 %add2515, i32 13)
  %add2521 = add i32 %or2520, %or2489
  %or2525 = tail call i32 @llvm.fshl.i32(i32 %add2485, i32 %add2485, i32 10)
  %neg2526 = xor i32 %add2503, -1
  %or2527 = or i32 %add2521, %neg2526
  %xor2528 = xor i32 %or2527, %or2525
  %add2529 = add i32 %or140, 1836072691
  %add2531 = add i32 %add2529, %or2489
  %add2533 = add i32 %add2531, %xor2528
  %or2538 = tail call i32 @llvm.fshl.i32(i32 %add2533, i32 %add2533, i32 7)
  %add2539 = add i32 %or2538, %or2507
  %or2543 = tail call i32 @llvm.fshl.i32(i32 %add2503, i32 %add2503, i32 10)
  %neg2544 = xor i32 %add2521, -1
  %or2545 = or i32 %add2539, %neg2544
  %xor2546 = xor i32 %or2545, %or2543
  %add2547 = add i32 %or446, 1836072691
  %add2549 = add i32 %add2547, %or2507
  %add2551 = add i32 %add2549, %xor2546
  %or2556 = tail call i32 @llvm.fshl.i32(i32 %add2551, i32 %add2551, i32 5)
  %add2557 = add i32 %or2556, %or2525
  %or2561 = tail call i32 @llvm.fshl.i32(i32 %add2521, i32 %add2521, i32 10)
  %xor2562 = xor i32 %add2539, %or2561
  %and2563 = and i32 %add2557, %xor2562
  %xor2564 = xor i32 %and2563, %or2561
  %add2565 = add i32 %or276, 2053994217
  %add2567 = add i32 %add2565, %or2525
  %add2569 = add i32 %add2567, %xor2564
  %or2574 = tail call i32 @llvm.fshl.i32(i32 %add2569, i32 %add2569, i32 15)
  %add2575 = add i32 %or2574, %or2543
  %or2579 = tail call i32 @llvm.fshl.i32(i32 %add2539, i32 %add2539, i32 10)
  %xor2580 = xor i32 %add2557, %or2579
  %and2581 = and i32 %add2575, %xor2580
  %xor2582 = xor i32 %and2581, %or2579
  %add2583 = add i32 %or208, 2053994217
  %add2585 = add i32 %add2583, %or2543
  %add2587 = add i32 %add2585, %xor2582
  %or2592 = tail call i32 @llvm.fshl.i32(i32 %add2587, i32 %add2587, i32 5)
  %add2593 = add i32 %or2592, %or2561
  %or2597 = tail call i32 @llvm.fshl.i32(i32 %add2557, i32 %add2557, i32 10)
  %xor2598 = xor i32 %add2575, %or2597
  %and2599 = and i32 %add2593, %xor2598
  %xor2600 = xor i32 %and2599, %or2597
  %add2601 = add i32 %or140, 2053994217
  %add2603 = add i32 %add2601, %or2561
  %add2605 = add i32 %add2603, %xor2600
  %or2610 = tail call i32 @llvm.fshl.i32(i32 %add2605, i32 %add2605, i32 8)
  %add2611 = add i32 %or2610, %or2579
  %or2615 = tail call i32 @llvm.fshl.i32(i32 %add2575, i32 %add2575, i32 10)
  %xor2616 = xor i32 %add2593, %or2615
  %and2617 = and i32 %add2611, %xor2616
  %xor2618 = xor i32 %and2617, %or2615
  %add2619 = add i32 %or42, 2053994217
  %add2621 = add i32 %add2619, %or2579
  %add2623 = add i32 %add2621, %xor2618
  %or2628 = tail call i32 @llvm.fshl.i32(i32 %add2623, i32 %add2623, i32 11)
  %add2629 = add i32 %or2628, %or2597
  %or2633 = tail call i32 @llvm.fshl.i32(i32 %add2593, i32 %add2593, i32 10)
  %xor2634 = xor i32 %add2611, %or2633
  %and2635 = and i32 %add2629, %xor2634
  %xor2636 = xor i32 %and2635, %or2633
  %add2637 = add i32 %or106, 2053994217
  %add2639 = add i32 %add2637, %or2597
  %add2641 = add i32 %add2639, %xor2636
  %or2646 = tail call i32 @llvm.fshl.i32(i32 %add2641, i32 %add2641, i32 14)
  %add2647 = add i32 %or2646, %or2615
  %or2651 = tail call i32 @llvm.fshl.i32(i32 %add2611, i32 %add2611, i32 10)
  %xor2652 = xor i32 %add2629, %or2651
  %and2653 = and i32 %add2647, %xor2652
  %xor2654 = xor i32 %and2653, %or2651
  %add2655 = add i32 %or378, 2053994217
  %add2657 = add i32 %add2655, %or2615
  %add2659 = add i32 %add2657, %xor2654
  %or2664 = tail call i32 @llvm.fshl.i32(i32 %add2659, i32 %add2659, i32 14)
  %add2665 = add i32 %or2664, %or2633
  %or2669 = tail call i32 @llvm.fshl.i32(i32 %add2629, i32 %add2629, i32 10)
  %xor2670 = xor i32 %add2647, %or2669
  %and2671 = and i32 %add2665, %xor2670
  %xor2672 = xor i32 %and2671, %or2669
  %add2673 = add i32 %or514, 2053994217
  %add2675 = add i32 %add2673, %or2633
  %add2677 = add i32 %add2675, %xor2672
  %or2682 = tail call i32 @llvm.fshl.i32(i32 %add2677, i32 %add2677, i32 6)
  %add2683 = add i32 %or2682, %or2651
  %or2687 = tail call i32 @llvm.fshl.i32(i32 %add2647, i32 %add2647, i32 10)
  %xor2688 = xor i32 %add2665, %or2687
  %and2689 = and i32 %add2683, %xor2688
  %xor2690 = xor i32 %and2689, %or2687
  %add2691 = add i32 %or21, 2053994217
  %add2693 = add i32 %add2691, %or2651
  %add2695 = add i32 %add2693, %xor2690
  %or2700 = tail call i32 @llvm.fshl.i32(i32 %add2695, i32 %add2695, i32 14)
  %add2701 = add i32 %or2700, %or2669
  %or2705 = tail call i32 @llvm.fshl.i32(i32 %add2665, i32 %add2665, i32 10)
  %xor2706 = xor i32 %add2683, %or2705
  %and2707 = and i32 %add2701, %xor2706
  %xor2708 = xor i32 %and2707, %or2705
  %add2709 = add i32 %or174, 2053994217
  %add2711 = add i32 %add2709, %or2669
  %add2713 = add i32 %add2711, %xor2708
  %or2718 = tail call i32 @llvm.fshl.i32(i32 %add2713, i32 %add2713, i32 6)
  %add2719 = add i32 %or2718, %or2687
  %or2723 = tail call i32 @llvm.fshl.i32(i32 %add2683, i32 %add2683, i32 10)
  %xor2724 = xor i32 %add2701, %or2723
  %and2725 = and i32 %add2719, %xor2724
  %xor2726 = xor i32 %and2725, %or2723
  %add2727 = add i32 %or412, 2053994217
  %add2729 = add i32 %add2727, %or2687
  %add2731 = add i32 %add2729, %xor2726
  %or2736 = tail call i32 @llvm.fshl.i32(i32 %add2731, i32 %add2731, i32 9)
  %add2737 = add i32 %or2736, %or2705
  %or2741 = tail call i32 @llvm.fshl.i32(i32 %add2701, i32 %add2701, i32 10)
  %xor2742 = xor i32 %add2719, %or2741
  %and2743 = and i32 %add2737, %xor2742
  %xor2744 = xor i32 %and2743, %or2741
  %add2745 = add i32 %or72, 2053994217
  %add2747 = add i32 %add2745, %or2705
  %add2749 = add i32 %add2747, %xor2744
  %or2754 = tail call i32 @llvm.fshl.i32(i32 %add2749, i32 %add2749, i32 12)
  %add2755 = add i32 %or2754, %or2723
  %or2759 = tail call i32 @llvm.fshl.i32(i32 %add2719, i32 %add2719, i32 10)
  %xor2760 = xor i32 %add2737, %or2759
  %and2761 = and i32 %add2755, %xor2760
  %xor2762 = xor i32 %and2761, %or2759
  %add2763 = add i32 %or446, 2053994217
  %add2765 = add i32 %add2763, %or2723
  %add2767 = add i32 %add2765, %xor2762
  %or2772 = tail call i32 @llvm.fshl.i32(i32 %add2767, i32 %add2767, i32 9)
  %add2773 = add i32 %or2772, %or2741
  %or2777 = tail call i32 @llvm.fshl.i32(i32 %add2737, i32 %add2737, i32 10)
  %xor2778 = xor i32 %add2755, %or2777
  %and2779 = and i32 %add2773, %xor2778
  %xor2780 = xor i32 %and2779, %or2777
  %add2781 = add i32 %or310, 2053994217
  %add2783 = add i32 %add2781, %or2741
  %add2785 = add i32 %add2783, %xor2780
  %or2790 = tail call i32 @llvm.fshl.i32(i32 %add2785, i32 %add2785, i32 12)
  %add2791 = add i32 %or2790, %or2759
  %or2795 = tail call i32 @llvm.fshl.i32(i32 %add2755, i32 %add2755, i32 10)
  %xor2796 = xor i32 %add2773, %or2795
  %and2797 = and i32 %add2791, %xor2796
  %xor2798 = xor i32 %and2797, %or2795
  %add2799 = add i32 %or242, 2053994217
  %add2801 = add i32 %add2799, %or2759
  %add2803 = add i32 %add2801, %xor2798
  %or2808 = tail call i32 @llvm.fshl.i32(i32 %add2803, i32 %add2803, i32 5)
  %add2809 = add i32 %or2808, %or2777
  %or2813 = tail call i32 @llvm.fshl.i32(i32 %add2773, i32 %add2773, i32 10)
  %xor2814 = xor i32 %add2791, %or2813
  %and2815 = and i32 %add2809, %xor2814
  %xor2816 = xor i32 %and2815, %or2813
  %add2817 = add i32 %or344, 2053994217
  %add2819 = add i32 %add2817, %or2777
  %add2821 = add i32 %add2819, %xor2816
  %or2826 = tail call i32 @llvm.fshl.i32(i32 %add2821, i32 %add2821, i32 15)
  %add2827 = add i32 %or2826, %or2795
  %or2831 = tail call i32 @llvm.fshl.i32(i32 %add2791, i32 %add2791, i32 10)
  %xor2832 = xor i32 %add2809, %or2831
  %and2833 = and i32 %add2827, %xor2832
  %xor2834 = xor i32 %and2833, %or2831
  %add2835 = add i32 %or480, 2053994217
  %add2837 = add i32 %add2835, %or2795
  %add2839 = add i32 %add2837, %xor2834
  %or2844 = tail call i32 @llvm.fshl.i32(i32 %add2839, i32 %add2839, i32 8)
  %add2845 = add i32 %or2844, %or2813
  %or2849 = tail call i32 @llvm.fshl.i32(i32 %add2809, i32 %add2809, i32 10)
  %xor2850 = xor i32 %add2827, %or2849
  %xor2851 = xor i32 %xor2850, %add2845
  %add2852 = add i32 %or2813, %or412
  %add2853 = add i32 %add2852, %xor2851
  %or2857 = tail call i32 @llvm.fshl.i32(i32 %add2853, i32 %add2853, i32 8)
  %add2858 = add i32 %or2857, %or2831
  %or2862 = tail call i32 @llvm.fshl.i32(i32 %add2827, i32 %add2827, i32 10)
  %xor2863 = xor i32 %add2845, %or2862
  %xor2864 = xor i32 %xor2863, %add2858
  %add2865 = add i32 %or2831, %or514
  %add2866 = add i32 %add2865, %xor2864
  %or2870 = tail call i32 @llvm.fshl.i32(i32 %add2866, i32 %add2866, i32 5)
  %add2871 = add i32 %or2870, %or2849
  %or2875 = tail call i32 @llvm.fshl.i32(i32 %add2845, i32 %add2845, i32 10)
  %xor2876 = xor i32 %add2858, %or2875
  %xor2877 = xor i32 %xor2876, %add2871
  %add2878 = add i32 %or2849, %or344
  %add2879 = add i32 %add2878, %xor2877
  %or2883 = tail call i32 @llvm.fshl.i32(i32 %add2879, i32 %add2879, i32 12)
  %add2884 = add i32 %or2883, %or2862
  %or2888 = tail call i32 @llvm.fshl.i32(i32 %add2858, i32 %add2858, i32 10)
  %xor2889 = xor i32 %add2871, %or2888
  %xor2890 = xor i32 %xor2889, %add2884
  %add2891 = add i32 %or2862, %or140
  %add2892 = add i32 %add2891, %xor2890
  %or2896 = tail call i32 @llvm.fshl.i32(i32 %add2892, i32 %add2892, i32 9)
  %add2897 = add i32 %or2896, %or2875
  %or2901 = tail call i32 @llvm.fshl.i32(i32 %add2871, i32 %add2871, i32 10)
  %xor2902 = xor i32 %add2884, %or2901
  %xor2903 = xor i32 %xor2902, %add2897
  %add2904 = add i32 %or2875, %or42
  %add2905 = add i32 %add2904, %xor2903
  %or2909 = tail call i32 @llvm.fshl.i32(i32 %add2905, i32 %add2905, i32 12)
  %add2910 = add i32 %or2909, %or2888
  %or2914 = tail call i32 @llvm.fshl.i32(i32 %add2884, i32 %add2884, i32 10)
  %xor2915 = xor i32 %add2897, %or2914
  %xor2916 = xor i32 %xor2915, %add2910
  %add2917 = add i32 %or2888, %or174
  %add2918 = add i32 %add2917, %xor2916
  %or2922 = tail call i32 @llvm.fshl.i32(i32 %add2918, i32 %add2918, i32 5)
  %add2923 = add i32 %or2922, %or2901
  %or2927 = tail call i32 @llvm.fshl.i32(i32 %add2897, i32 %add2897, i32 10)
  %xor2928 = xor i32 %add2910, %or2927
  %xor2929 = xor i32 %xor2928, %add2923
  %add2930 = add i32 %or2901, %or276
  %add2931 = add i32 %add2930, %xor2929
  %or2935 = tail call i32 @llvm.fshl.i32(i32 %add2931, i32 %add2931, i32 14)
  %add2936 = add i32 %or2935, %or2914
  %or2940 = tail call i32 @llvm.fshl.i32(i32 %add2910, i32 %add2910, i32 10)
  %xor2941 = xor i32 %add2923, %or2940
  %xor2942 = xor i32 %xor2941, %add2936
  %add2943 = add i32 %or2914, %or242
  %add2944 = add i32 %add2943, %xor2942
  %or2948 = tail call i32 @llvm.fshl.i32(i32 %add2944, i32 %add2944, i32 6)
  %add2949 = add i32 %or2948, %or2927
  %or2953 = tail call i32 @llvm.fshl.i32(i32 %add2923, i32 %add2923, i32 10)
  %xor2954 = xor i32 %add2936, %or2953
  %xor2955 = xor i32 %xor2954, %add2949
  %add2956 = add i32 %or2927, %or208
  %add2957 = add i32 %add2956, %xor2955
  %or2961 = tail call i32 @llvm.fshl.i32(i32 %add2957, i32 %add2957, i32 8)
  %add2962 = add i32 %or2961, %or2940
  %or2966 = tail call i32 @llvm.fshl.i32(i32 %add2936, i32 %add2936, i32 10)
  %xor2967 = xor i32 %add2949, %or2966
  %xor2968 = xor i32 %xor2967, %add2962
  %add2969 = add i32 %or2940, %or72
  %add2970 = add i32 %add2969, %xor2968
  %or2974 = tail call i32 @llvm.fshl.i32(i32 %add2970, i32 %add2970, i32 13)
  %add2975 = add i32 %or2974, %or2953
  %or2979 = tail call i32 @llvm.fshl.i32(i32 %add2949, i32 %add2949, i32 10)
  %xor2980 = xor i32 %add2962, %or2979
  %xor2981 = xor i32 %xor2980, %add2975
  %add2982 = add i32 %or2953, %or446
  %add2983 = add i32 %add2982, %xor2981
  %or2987 = tail call i32 @llvm.fshl.i32(i32 %add2983, i32 %add2983, i32 6)
  %add2988 = add i32 %or2987, %or2966
  %or2992 = tail call i32 @llvm.fshl.i32(i32 %add2962, i32 %add2962, i32 10)
  %xor2993 = xor i32 %add2975, %or2992
  %xor2994 = xor i32 %xor2993, %add2988
  %add2995 = add i32 %or2966, %or480
  %add2996 = add i32 %add2995, %xor2994
  %or3000 = tail call i32 @llvm.fshl.i32(i32 %add2996, i32 %add2996, i32 5)
  %add3001 = add i32 %or3000, %or2979
  %or3005 = tail call i32 @llvm.fshl.i32(i32 %add2975, i32 %add2975, i32 10)
  %xor3006 = xor i32 %add2988, %or3005
  %xor3007 = xor i32 %xor3006, %add3001
  %add3008 = add i32 %or2979, %or21
  %add3009 = add i32 %add3008, %xor3007
  %or3013 = tail call i32 @llvm.fshl.i32(i32 %add3009, i32 %add3009, i32 15)
  %add3014 = add i32 %or3013, %or2992
  %or3018 = tail call i32 @llvm.fshl.i32(i32 %add2988, i32 %add2988, i32 10)
  %xor3019 = xor i32 %add3001, %or3018
  %xor3020 = xor i32 %xor3019, %add3014
  %add3021 = add i32 %or2992, %or106
  %add3022 = add i32 %add3021, %xor3020
  %or3026 = tail call i32 @llvm.fshl.i32(i32 %add3022, i32 %add3022, i32 13)
  %add3027 = add i32 %or3026, %or3005
  %or3031 = tail call i32 @llvm.fshl.i32(i32 %add3001, i32 %add3001, i32 10)
  %xor3032 = xor i32 %add3014, %or3031
  %xor3033 = xor i32 %xor3032, %add3027
  %add3034 = add i32 %or3005, %or310
  %add3035 = add i32 %add3034, %xor3033
  %or3039 = tail call i32 @llvm.fshl.i32(i32 %add3035, i32 %add3035, i32 11)
  %add3040 = add i32 %or3039, %or3018
  %or3044 = tail call i32 @llvm.fshl.i32(i32 %add3014, i32 %add3014, i32 10)
  %xor3045 = xor i32 %add3027, %or3044
  %xor3046 = xor i32 %xor3045, %add3040
  %add3047 = add i32 %or3018, %or378
  %add3048 = add i32 %add3047, %xor3046
  %or3052 = tail call i32 @llvm.fshl.i32(i32 %add3048, i32 %add3048, i32 11)
  %or3057 = tail call i32 @llvm.fshl.i32(i32 %add3027, i32 %add3027, i32 10)
  %add3059 = add i32 %add1670, %3
  %add3060 = add i32 %add3059, %or3057
  %add3062 = add i32 %or1692, %2
  %add3063 = add i32 %add3062, %or3044
  store i32 %add3063, i32* %B2, align 4, !tbaa !12
  %add3066 = add i32 %or1674, %1
  %add3067 = add i32 %add3066, %or3031
  store i32 %add3067, i32* %C3, align 4, !tbaa !13
  %add3053 = add i32 %or1656, %0
  %add3070 = add i32 %add3053, %or3031
  %add3071 = add i32 %add3070, %or3052
  store i32 %add3071, i32* %D4, align 4, !tbaa !14
  %add1688 = add i32 %or1656, %4
  %add3074 = add i32 %add1688, %or1687
  %add3075 = add i32 %add3074, %add3040
  store i32 %add3075, i32* %E5, align 4, !tbaa !15
  store i32 %add3060, i32* %A1, align 4, !tbaa !11
  %tobool.not = icmp eq i64 %dec, 0
  br i1 %tobool.not, label %for.end, label %for.body, !llvm.loop !17

for.end:                                          ; preds = %for.body, %entry
  ret void
}

; Function Attrs: nounwind
declare i8* @memset(i8* noundef, i32 noundef, i64 noundef) local_unnamed_addr #1

; Function Attrs: nofree noinline nosync nounwind uwtable
define void @RIPEMD160_Transform(%struct.RIPEMD160state_st* nocapture noundef %c, i8* noundef %data) local_unnamed_addr #2 {
entry:
  tail call void @ripemd160_block_data_order(%struct.RIPEMD160state_st* noundef %c, i8* noundef %data, i64 noundef 1) #6
  ret void
}

; Function Attrs: noinline nounwind uwtable
define i32 @RIPEMD160_Final(i8* nocapture noundef writeonly %md, %struct.RIPEMD160state_st* noundef %c) local_unnamed_addr #0 {
entry:
  %arraydecay = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 7, i64 0
  %0 = bitcast i32* %arraydecay to i8*
  %num = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 8
  %1 = load i32, i32* %num, align 4, !tbaa !10
  %conv = zext i32 %1 to i64
  %arrayidx = getelementptr inbounds i8, i8* %0, i64 %conv
  store i8 -128, i8* %arrayidx, align 1, !tbaa !16
  %inc = add nuw nsw i64 %conv, 1
  %cmp = icmp ugt i32 %1, 55
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %add.ptr = getelementptr inbounds i8, i8* %0, i64 %inc
  %sub = sub nsw i64 63, %conv
  %call = tail call i8* @memset(i8* noundef nonnull %add.ptr, i32 noundef 0, i64 noundef %sub) #5
  tail call void @ripemd160_block_data_order(%struct.RIPEMD160state_st* noundef nonnull %c, i8* noundef nonnull %0, i64 noundef 1) #6
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %n.0 = phi i64 [ 0, %if.then ], [ %inc, %entry ]
  %add.ptr2 = getelementptr inbounds i8, i8* %0, i64 %n.0
  %sub3 = sub nsw i64 56, %n.0
  %call4 = tail call i8* @memset(i8* noundef nonnull %add.ptr2, i32 noundef 0, i64 noundef %sub3) #5
  %add.ptr5209 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 7, i64 14
  %add.ptr5 = bitcast i32* %add.ptr5209 to i8*
  %Nl = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 5
  %2 = load i32, i32* %Nl, align 4, !tbaa !4
  %conv6 = trunc i32 %2 to i8
  %incdec.ptr = getelementptr inbounds i8, i8* %add.ptr5, i64 1
  store i8 %conv6, i8* %add.ptr5, align 1, !tbaa !16
  %shr = lshr i32 %2, 8
  %conv9 = trunc i32 %shr to i8
  %incdec.ptr10 = getelementptr inbounds i8, i8* %add.ptr5, i64 2
  store i8 %conv9, i8* %incdec.ptr, align 1, !tbaa !16
  %shr12 = lshr i32 %2, 16
  %conv14 = trunc i32 %shr12 to i8
  %incdec.ptr15 = getelementptr inbounds i8, i8* %add.ptr5, i64 3
  store i8 %conv14, i8* %incdec.ptr10, align 1, !tbaa !16
  %shr17 = lshr i32 %2, 24
  %conv19 = trunc i32 %shr17 to i8
  %incdec.ptr20210 = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 7, i64 15
  %incdec.ptr20 = bitcast i32* %incdec.ptr20210 to i8*
  store i8 %conv19, i8* %incdec.ptr15, align 1, !tbaa !16
  %Nh = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 6
  %3 = load i32, i32* %Nh, align 4, !tbaa !9
  %conv23 = trunc i32 %3 to i8
  %incdec.ptr24 = getelementptr inbounds i8, i8* %incdec.ptr20, i64 1
  store i8 %conv23, i8* %incdec.ptr20, align 1, !tbaa !16
  %shr26 = lshr i32 %3, 8
  %conv28 = trunc i32 %shr26 to i8
  %incdec.ptr29 = getelementptr inbounds i8, i8* %incdec.ptr20, i64 2
  store i8 %conv28, i8* %incdec.ptr24, align 1, !tbaa !16
  %shr31 = lshr i32 %3, 16
  %conv33 = trunc i32 %shr31 to i8
  %incdec.ptr34 = getelementptr inbounds i8, i8* %incdec.ptr20, i64 3
  store i8 %conv33, i8* %incdec.ptr29, align 1, !tbaa !16
  %shr36 = lshr i32 %3, 24
  %conv38 = trunc i32 %shr36 to i8
  store i8 %conv38, i8* %incdec.ptr34, align 1, !tbaa !16
  tail call void @ripemd160_block_data_order(%struct.RIPEMD160state_st* noundef nonnull %c, i8* noundef nonnull %0, i64 noundef 1) #6
  store i32 0, i32* %num, align 4, !tbaa !10
  tail call void @OPENSSL_cleanse(i8* noundef nonnull %0, i64 noundef 64) #5
  %A = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 0
  %4 = load i32, i32* %A, align 4, !tbaa !11
  %conv43 = zext i32 %4 to i64
  %conv45 = trunc i32 %4 to i8
  %incdec.ptr46 = getelementptr inbounds i8, i8* %md, i64 1
  store i8 %conv45, i8* %md, align 1, !tbaa !16
  %shr47 = lshr i64 %conv43, 8
  %conv49 = trunc i64 %shr47 to i8
  %incdec.ptr50 = getelementptr inbounds i8, i8* %md, i64 2
  store i8 %conv49, i8* %incdec.ptr46, align 1, !tbaa !16
  %shr51 = lshr i64 %conv43, 16
  %conv53 = trunc i64 %shr51 to i8
  %incdec.ptr54 = getelementptr inbounds i8, i8* %md, i64 3
  store i8 %conv53, i8* %incdec.ptr50, align 1, !tbaa !16
  %shr55 = lshr i64 %conv43, 24
  %conv57 = trunc i64 %shr55 to i8
  %incdec.ptr58 = getelementptr inbounds i8, i8* %md, i64 4
  store i8 %conv57, i8* %incdec.ptr54, align 1, !tbaa !16
  %B = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 1
  %5 = load i32, i32* %B, align 4, !tbaa !12
  %conv59 = zext i32 %5 to i64
  %conv61 = trunc i32 %5 to i8
  %incdec.ptr62 = getelementptr inbounds i8, i8* %md, i64 5
  store i8 %conv61, i8* %incdec.ptr58, align 1, !tbaa !16
  %shr63 = lshr i64 %conv59, 8
  %conv65 = trunc i64 %shr63 to i8
  %incdec.ptr66 = getelementptr inbounds i8, i8* %md, i64 6
  store i8 %conv65, i8* %incdec.ptr62, align 1, !tbaa !16
  %shr67 = lshr i64 %conv59, 16
  %conv69 = trunc i64 %shr67 to i8
  %incdec.ptr70 = getelementptr inbounds i8, i8* %md, i64 7
  store i8 %conv69, i8* %incdec.ptr66, align 1, !tbaa !16
  %shr71 = lshr i64 %conv59, 24
  %conv73 = trunc i64 %shr71 to i8
  %incdec.ptr74 = getelementptr inbounds i8, i8* %md, i64 8
  store i8 %conv73, i8* %incdec.ptr70, align 1, !tbaa !16
  %C = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 2
  %6 = load i32, i32* %C, align 4, !tbaa !13
  %conv75 = zext i32 %6 to i64
  %conv77 = trunc i32 %6 to i8
  %incdec.ptr78 = getelementptr inbounds i8, i8* %md, i64 9
  store i8 %conv77, i8* %incdec.ptr74, align 1, !tbaa !16
  %shr79 = lshr i64 %conv75, 8
  %conv81 = trunc i64 %shr79 to i8
  %incdec.ptr82 = getelementptr inbounds i8, i8* %md, i64 10
  store i8 %conv81, i8* %incdec.ptr78, align 1, !tbaa !16
  %shr83 = lshr i64 %conv75, 16
  %conv85 = trunc i64 %shr83 to i8
  %incdec.ptr86 = getelementptr inbounds i8, i8* %md, i64 11
  store i8 %conv85, i8* %incdec.ptr82, align 1, !tbaa !16
  %shr87 = lshr i64 %conv75, 24
  %conv89 = trunc i64 %shr87 to i8
  %incdec.ptr90 = getelementptr inbounds i8, i8* %md, i64 12
  store i8 %conv89, i8* %incdec.ptr86, align 1, !tbaa !16
  %D = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 3
  %7 = load i32, i32* %D, align 4, !tbaa !14
  %conv91 = zext i32 %7 to i64
  %conv93 = trunc i32 %7 to i8
  %incdec.ptr94 = getelementptr inbounds i8, i8* %md, i64 13
  store i8 %conv93, i8* %incdec.ptr90, align 1, !tbaa !16
  %shr95 = lshr i64 %conv91, 8
  %conv97 = trunc i64 %shr95 to i8
  %incdec.ptr98 = getelementptr inbounds i8, i8* %md, i64 14
  store i8 %conv97, i8* %incdec.ptr94, align 1, !tbaa !16
  %shr99 = lshr i64 %conv91, 16
  %conv101 = trunc i64 %shr99 to i8
  %incdec.ptr102 = getelementptr inbounds i8, i8* %md, i64 15
  store i8 %conv101, i8* %incdec.ptr98, align 1, !tbaa !16
  %shr103 = lshr i64 %conv91, 24
  %conv105 = trunc i64 %shr103 to i8
  %incdec.ptr106 = getelementptr inbounds i8, i8* %md, i64 16
  store i8 %conv105, i8* %incdec.ptr102, align 1, !tbaa !16
  %E = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 4
  %8 = load i32, i32* %E, align 4, !tbaa !15
  %conv107 = zext i32 %8 to i64
  %conv109 = trunc i32 %8 to i8
  %incdec.ptr110 = getelementptr inbounds i8, i8* %md, i64 17
  store i8 %conv109, i8* %incdec.ptr106, align 1, !tbaa !16
  %shr111 = lshr i64 %conv107, 8
  %conv113 = trunc i64 %shr111 to i8
  %incdec.ptr114 = getelementptr inbounds i8, i8* %md, i64 18
  store i8 %conv113, i8* %incdec.ptr110, align 1, !tbaa !16
  %shr115 = lshr i64 %conv107, 16
  %conv117 = trunc i64 %shr115 to i8
  %incdec.ptr118 = getelementptr inbounds i8, i8* %md, i64 19
  store i8 %conv117, i8* %incdec.ptr114, align 1, !tbaa !16
  %shr119 = lshr i64 %conv107, 24
  %conv121 = trunc i64 %shr119 to i8
  store i8 %conv121, i8* %incdec.ptr118, align 1, !tbaa !16
  ret i32 1
}

declare void @OPENSSL_cleanse(i8* noundef, i64 noundef) local_unnamed_addr #3

; Function Attrs: noinline nounwind uwtable
define i32 @RIPEMD160_Init(%struct.RIPEMD160state_st* noundef %c) local_unnamed_addr #0 {
entry:
  %0 = bitcast %struct.RIPEMD160state_st* %c to i8*
  %call = tail call i8* @memset(i8* noundef %0, i32 noundef 0, i64 noundef 96) #5
  %1 = bitcast %struct.RIPEMD160state_st* %c to <4 x i32>*
  store <4 x i32> <i32 1732584193, i32 -271733879, i32 -1732584194, i32 271733878>, <4 x i32>* %1, align 4, !tbaa !19
  %E = getelementptr inbounds %struct.RIPEMD160state_st, %struct.RIPEMD160state_st* %c, i64 0, i32 4
  store i32 -1009589776, i32* %E, align 4, !tbaa !15
  ret i32 1
}

; Function Attrs: nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.fshl.i32(i32, i32, i32) #4

attributes #0 = { noinline nounwind uwtable "frame-pointer"="none" "min-legal-vector-width"="0" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #1 = { nounwind "frame-pointer"="none" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #2 = { nofree noinline nosync nounwind uwtable "frame-pointer"="none" "min-legal-vector-width"="0" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #3 = { "frame-pointer"="none" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #4 = { nofree nosync nounwind readnone speculatable willreturn }
attributes #5 = { nobuiltin nounwind "no-builtins" }
attributes #6 = { nobuiltin "no-builtins" }

!llvm.module.flags = !{!0, !1, !2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 7, !"uwtable", i32 1}
!3 = !{!"clang version 14.0.0"}
!4 = !{!5, !6, i64 20}
!5 = !{!"RIPEMD160state_st", !6, i64 0, !6, i64 4, !6, i64 8, !6, i64 12, !6, i64 16, !6, i64 20, !6, i64 24, !7, i64 28, !6, i64 92}
!6 = !{!"int", !7, i64 0}
!7 = !{!"omnipotent char", !8, i64 0}
!8 = !{!"Simple C/C++ TBAA"}
!9 = !{!5, !6, i64 24}
!10 = !{!5, !6, i64 92}
!11 = !{!5, !6, i64 0}
!12 = !{!5, !6, i64 4}
!13 = !{!5, !6, i64 8}
!14 = !{!5, !6, i64 12}
!15 = !{!5, !6, i64 16}
!16 = !{!7, !7, i64 0}
!17 = distinct !{!17, !18}
!18 = !{!"llvm.loop.mustprogress"}
!19 = !{!6, !6, i64 0}
