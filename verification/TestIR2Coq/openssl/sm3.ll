; ModuleID = 'crypto/sm3/sm3.c'
source_filename = "crypto/sm3/sm3.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.SM3state_st = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [16 x i32], i32 }

; Function Attrs: noinline nounwind uwtable
define i32 @ossl_sm3_update(%struct.SM3state_st* noundef %c, i8* noundef %data_, i64 noundef %len) local_unnamed_addr #0 {
entry:
  %cmp = icmp eq i64 %len, 0
  br i1 %cmp, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %Nl = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 8
  %0 = load i32, i32* %Nl, align 4, !tbaa !4
  %conv = trunc i64 %len to i32
  %shl = shl i32 %conv, 3
  %add = add i32 %0, %shl
  %cmp4 = icmp ult i32 %add, %0
  %Nh = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 9
  %1 = load i32, i32* %Nh, align 4, !tbaa !9
  %inc = zext i1 %cmp4 to i32
  %2 = add i32 %1, %inc
  %shr = lshr i64 %len, 29
  %conv8 = trunc i64 %shr to i32
  %Nh9 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 9
  %add10 = add i32 %2, %conv8
  store i32 %add10, i32* %Nh9, align 4, !tbaa !9
  store i32 %add, i32* %Nl, align 4, !tbaa !4
  %num = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 11
  %3 = load i32, i32* %num, align 4, !tbaa !10
  %conv12 = zext i32 %3 to i64
  %cmp13.not = icmp eq i32 %3, 0
  br i1 %cmp13.not, label %if.end34, label %if.then15

if.then15:                                        ; preds = %if.end
  %arraydecay = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 10, i64 0
  %4 = bitcast i32* %arraydecay to i8*
  %cmp17 = icmp ugt i64 %len, 63
  %add19 = add i64 %conv12, %len
  %cmp20 = icmp ugt i64 %add19, 63
  %or.cond = select i1 %cmp17, i1 true, i1 %cmp20
  %add.ptr = getelementptr inbounds i8, i8* %4, i64 %conv12
  br i1 %or.cond, label %if.then22, label %if.else

if.then22:                                        ; preds = %if.then15
  %sub = sub nsw i64 64, %conv12
  %call = tail call i8* @memcpy(i8* noundef nonnull %add.ptr, i8* noundef %data_, i64 noundef %sub) #5
  tail call void @ossl_sm3_block_data_order(%struct.SM3state_st* noundef nonnull %c, i8* noundef nonnull %4, i64 noundef 1) #6
  %add.ptr24 = getelementptr inbounds i8, i8* %data_, i64 %sub
  %sub25 = sub i64 %len, %sub
  store i32 0, i32* %num, align 4, !tbaa !10
  %call27 = tail call i8* @memset(i8* noundef nonnull %4, i32 noundef 0, i64 noundef 64) #5
  br label %if.end34

if.else:                                          ; preds = %if.then15
  %call29 = tail call i8* @memcpy(i8* noundef nonnull %add.ptr, i8* noundef %data_, i64 noundef %len) #5
  %5 = load i32, i32* %num, align 4, !tbaa !10
  %add32 = add i32 %5, %conv
  store i32 %add32, i32* %num, align 4, !tbaa !10
  br label %cleanup

if.end34:                                         ; preds = %if.then22, %if.end
  %len.addr.0 = phi i64 [ %sub25, %if.then22 ], [ %len, %if.end ]
  %data.0 = phi i8* [ %add.ptr24, %if.then22 ], [ %data_, %if.end ]
  %cmp35.not = icmp ult i64 %len.addr.0, 64
  br i1 %cmp35.not, label %if.end40, label %if.then37

if.then37:                                        ; preds = %if.end34
  %div = lshr i64 %len.addr.0, 6
  tail call void @ossl_sm3_block_data_order(%struct.SM3state_st* noundef nonnull %c, i8* noundef %data.0, i64 noundef %div) #6
  %mul = and i64 %len.addr.0, -64
  %add.ptr38 = getelementptr inbounds i8, i8* %data.0, i64 %mul
  %sub39 = and i64 %len.addr.0, 63
  br label %if.end40

if.end40:                                         ; preds = %if.then37, %if.end34
  %len.addr.1 = phi i64 [ %sub39, %if.then37 ], [ %len.addr.0, %if.end34 ]
  %data.1 = phi i8* [ %add.ptr38, %if.then37 ], [ %data.0, %if.end34 ]
  %cmp41.not = icmp eq i64 %len.addr.1, 0
  br i1 %cmp41.not, label %cleanup, label %if.then43

if.then43:                                        ; preds = %if.end40
  %arraydecay45 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 10, i64 0
  %6 = bitcast i32* %arraydecay45 to i8*
  %conv46 = trunc i64 %len.addr.1 to i32
  store i32 %conv46, i32* %num, align 4, !tbaa !10
  %call48 = tail call i8* @memcpy(i8* noundef nonnull %6, i8* noundef %data.1, i64 noundef %len.addr.1) #5
  br label %cleanup

cleanup:                                          ; preds = %if.end40, %if.then43, %entry, %if.else
  ret i32 1
}

; Function Attrs: nounwind
declare i8* @memcpy(i8* noundef, i8* noundef, i64 noundef) local_unnamed_addr #1

; Function Attrs: nofree noinline nosync nounwind uwtable
define void @ossl_sm3_block_data_order(%struct.SM3state_st* nocapture noundef %ctx, i8* noundef readonly %p, i64 noundef %num) local_unnamed_addr #2 {
entry:
  %tobool.not9348 = icmp eq i64 %num, 0
  br i1 %tobool.not9348, label %for.end, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %entry
  %A1 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %ctx, i64 0, i32 0
  %B2 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %ctx, i64 0, i32 1
  %C3 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %ctx, i64 0, i32 2
  %D4 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %ctx, i64 0, i32 3
  %E5 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %ctx, i64 0, i32 4
  %F6 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %ctx, i64 0, i32 5
  %G7 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %ctx, i64 0, i32 6
  %H8 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %ctx, i64 0, i32 7
  %.pre = load i32, i32* %A1, align 4, !tbaa !11
  %.pre9351 = load i32, i32* %B2, align 4, !tbaa !12
  %.pre9352 = load i32, i32* %C3, align 4, !tbaa !13
  %.pre9353 = load i32, i32* %D4, align 4, !tbaa !14
  %.pre9354 = load i32, i32* %E5, align 4, !tbaa !15
  %.pre9355 = load i32, i32* %F6, align 4, !tbaa !16
  %.pre9356 = load i32, i32* %G7, align 4, !tbaa !17
  %.pre9357 = load i32, i32* %H8, align 4, !tbaa !18
  br label %for.body

for.body:                                         ; preds = %for.body.lr.ph, %for.body
  %0 = phi i32 [ %.pre9357, %for.body.lr.ph ], [ %xor5952, %for.body ]
  %1 = phi i32 [ %.pre9356, %for.body.lr.ph ], [ %xor5950, %for.body ]
  %2 = phi i32 [ %.pre9355, %for.body.lr.ph ], [ %xor5948, %for.body ]
  %3 = phi i32 [ %.pre9354, %for.body.lr.ph ], [ %xor5946, %for.body ]
  %4 = phi i32 [ %.pre9353, %for.body.lr.ph ], [ %xor5944, %for.body ]
  %5 = phi i32 [ %.pre9352, %for.body.lr.ph ], [ %xor5942, %for.body ]
  %6 = phi i32 [ %.pre9351, %for.body.lr.ph ], [ %xor5940, %for.body ]
  %7 = phi i32 [ %.pre, %for.body.lr.ph ], [ %xor5938, %for.body ]
  %num.addr.09350 = phi i64 [ %num, %for.body.lr.ph ], [ %dec, %for.body ]
  %data.09349 = phi i8* [ %p, %for.body.lr.ph ], [ %incdec.ptr336, %for.body ]
  %dec = add i64 %num.addr.09350, -1
  %incdec.ptr = getelementptr inbounds i8, i8* %data.09349, i64 1
  %8 = load i8, i8* %data.09349, align 1, !tbaa !19
  %conv = zext i8 %8 to i32
  %shl = shl nuw i32 %conv, 24
  %incdec.ptr10 = getelementptr inbounds i8, i8* %data.09349, i64 2
  %9 = load i8, i8* %incdec.ptr, align 1, !tbaa !19
  %conv11 = zext i8 %9 to i32
  %shl12 = shl nuw nsw i32 %conv11, 16
  %or = or i32 %shl12, %shl
  %incdec.ptr15 = getelementptr inbounds i8, i8* %data.09349, i64 3
  %10 = load i8, i8* %incdec.ptr10, align 1, !tbaa !19
  %conv16 = zext i8 %10 to i32
  %shl17 = shl nuw nsw i32 %conv16, 8
  %or19 = or i32 %or, %shl17
  %incdec.ptr21 = getelementptr inbounds i8, i8* %data.09349, i64 4
  %11 = load i8, i8* %incdec.ptr15, align 1, !tbaa !19
  %conv22 = zext i8 %11 to i32
  %or24 = or i32 %or19, %conv22
  %incdec.ptr26 = getelementptr inbounds i8, i8* %data.09349, i64 5
  %12 = load i8, i8* %incdec.ptr21, align 1, !tbaa !19
  %conv27 = zext i8 %12 to i32
  %shl28 = shl nuw i32 %conv27, 24
  %incdec.ptr30 = getelementptr inbounds i8, i8* %data.09349, i64 6
  %13 = load i8, i8* %incdec.ptr26, align 1, !tbaa !19
  %conv31 = zext i8 %13 to i32
  %shl32 = shl nuw nsw i32 %conv31, 16
  %or34 = or i32 %shl32, %shl28
  %incdec.ptr36 = getelementptr inbounds i8, i8* %data.09349, i64 7
  %14 = load i8, i8* %incdec.ptr30, align 1, !tbaa !19
  %conv37 = zext i8 %14 to i32
  %shl38 = shl nuw nsw i32 %conv37, 8
  %or40 = or i32 %or34, %shl38
  %incdec.ptr42 = getelementptr inbounds i8, i8* %data.09349, i64 8
  %15 = load i8, i8* %incdec.ptr36, align 1, !tbaa !19
  %conv43 = zext i8 %15 to i32
  %or45 = or i32 %or40, %conv43
  %incdec.ptr47 = getelementptr inbounds i8, i8* %data.09349, i64 9
  %16 = load i8, i8* %incdec.ptr42, align 1, !tbaa !19
  %conv48 = zext i8 %16 to i32
  %shl49 = shl nuw i32 %conv48, 24
  %incdec.ptr51 = getelementptr inbounds i8, i8* %data.09349, i64 10
  %17 = load i8, i8* %incdec.ptr47, align 1, !tbaa !19
  %conv52 = zext i8 %17 to i32
  %shl53 = shl nuw nsw i32 %conv52, 16
  %or55 = or i32 %shl53, %shl49
  %incdec.ptr57 = getelementptr inbounds i8, i8* %data.09349, i64 11
  %18 = load i8, i8* %incdec.ptr51, align 1, !tbaa !19
  %conv58 = zext i8 %18 to i32
  %shl59 = shl nuw nsw i32 %conv58, 8
  %or61 = or i32 %or55, %shl59
  %incdec.ptr63 = getelementptr inbounds i8, i8* %data.09349, i64 12
  %19 = load i8, i8* %incdec.ptr57, align 1, !tbaa !19
  %conv64 = zext i8 %19 to i32
  %or66 = or i32 %or61, %conv64
  %incdec.ptr68 = getelementptr inbounds i8, i8* %data.09349, i64 13
  %20 = load i8, i8* %incdec.ptr63, align 1, !tbaa !19
  %conv69 = zext i8 %20 to i32
  %shl70 = shl nuw i32 %conv69, 24
  %incdec.ptr72 = getelementptr inbounds i8, i8* %data.09349, i64 14
  %21 = load i8, i8* %incdec.ptr68, align 1, !tbaa !19
  %conv73 = zext i8 %21 to i32
  %shl74 = shl nuw nsw i32 %conv73, 16
  %or76 = or i32 %shl74, %shl70
  %incdec.ptr78 = getelementptr inbounds i8, i8* %data.09349, i64 15
  %22 = load i8, i8* %incdec.ptr72, align 1, !tbaa !19
  %conv79 = zext i8 %22 to i32
  %shl80 = shl nuw nsw i32 %conv79, 8
  %or82 = or i32 %or76, %shl80
  %incdec.ptr84 = getelementptr inbounds i8, i8* %data.09349, i64 16
  %23 = load i8, i8* %incdec.ptr78, align 1, !tbaa !19
  %conv85 = zext i8 %23 to i32
  %or87 = or i32 %or82, %conv85
  %incdec.ptr89 = getelementptr inbounds i8, i8* %data.09349, i64 17
  %24 = load i8, i8* %incdec.ptr84, align 1, !tbaa !19
  %conv90 = zext i8 %24 to i32
  %shl91 = shl nuw i32 %conv90, 24
  %incdec.ptr93 = getelementptr inbounds i8, i8* %data.09349, i64 18
  %25 = load i8, i8* %incdec.ptr89, align 1, !tbaa !19
  %conv94 = zext i8 %25 to i32
  %shl95 = shl nuw nsw i32 %conv94, 16
  %or97 = or i32 %shl95, %shl91
  %incdec.ptr99 = getelementptr inbounds i8, i8* %data.09349, i64 19
  %26 = load i8, i8* %incdec.ptr93, align 1, !tbaa !19
  %conv100 = zext i8 %26 to i32
  %shl101 = shl nuw nsw i32 %conv100, 8
  %or103 = or i32 %or97, %shl101
  %incdec.ptr105 = getelementptr inbounds i8, i8* %data.09349, i64 20
  %27 = load i8, i8* %incdec.ptr99, align 1, !tbaa !19
  %conv106 = zext i8 %27 to i32
  %or108 = or i32 %or103, %conv106
  %incdec.ptr110 = getelementptr inbounds i8, i8* %data.09349, i64 21
  %28 = load i8, i8* %incdec.ptr105, align 1, !tbaa !19
  %conv111 = zext i8 %28 to i32
  %shl112 = shl nuw i32 %conv111, 24
  %incdec.ptr114 = getelementptr inbounds i8, i8* %data.09349, i64 22
  %29 = load i8, i8* %incdec.ptr110, align 1, !tbaa !19
  %conv115 = zext i8 %29 to i32
  %shl116 = shl nuw nsw i32 %conv115, 16
  %or118 = or i32 %shl116, %shl112
  %incdec.ptr120 = getelementptr inbounds i8, i8* %data.09349, i64 23
  %30 = load i8, i8* %incdec.ptr114, align 1, !tbaa !19
  %conv121 = zext i8 %30 to i32
  %shl122 = shl nuw nsw i32 %conv121, 8
  %or124 = or i32 %or118, %shl122
  %incdec.ptr126 = getelementptr inbounds i8, i8* %data.09349, i64 24
  %31 = load i8, i8* %incdec.ptr120, align 1, !tbaa !19
  %conv127 = zext i8 %31 to i32
  %or129 = or i32 %or124, %conv127
  %incdec.ptr131 = getelementptr inbounds i8, i8* %data.09349, i64 25
  %32 = load i8, i8* %incdec.ptr126, align 1, !tbaa !19
  %conv132 = zext i8 %32 to i32
  %shl133 = shl nuw i32 %conv132, 24
  %incdec.ptr135 = getelementptr inbounds i8, i8* %data.09349, i64 26
  %33 = load i8, i8* %incdec.ptr131, align 1, !tbaa !19
  %conv136 = zext i8 %33 to i32
  %shl137 = shl nuw nsw i32 %conv136, 16
  %or139 = or i32 %shl137, %shl133
  %incdec.ptr141 = getelementptr inbounds i8, i8* %data.09349, i64 27
  %34 = load i8, i8* %incdec.ptr135, align 1, !tbaa !19
  %conv142 = zext i8 %34 to i32
  %shl143 = shl nuw nsw i32 %conv142, 8
  %or145 = or i32 %or139, %shl143
  %incdec.ptr147 = getelementptr inbounds i8, i8* %data.09349, i64 28
  %35 = load i8, i8* %incdec.ptr141, align 1, !tbaa !19
  %conv148 = zext i8 %35 to i32
  %or150 = or i32 %or145, %conv148
  %incdec.ptr152 = getelementptr inbounds i8, i8* %data.09349, i64 29
  %36 = load i8, i8* %incdec.ptr147, align 1, !tbaa !19
  %conv153 = zext i8 %36 to i32
  %shl154 = shl nuw i32 %conv153, 24
  %incdec.ptr156 = getelementptr inbounds i8, i8* %data.09349, i64 30
  %37 = load i8, i8* %incdec.ptr152, align 1, !tbaa !19
  %conv157 = zext i8 %37 to i32
  %shl158 = shl nuw nsw i32 %conv157, 16
  %or160 = or i32 %shl158, %shl154
  %incdec.ptr162 = getelementptr inbounds i8, i8* %data.09349, i64 31
  %38 = load i8, i8* %incdec.ptr156, align 1, !tbaa !19
  %conv163 = zext i8 %38 to i32
  %shl164 = shl nuw nsw i32 %conv163, 8
  %or166 = or i32 %or160, %shl164
  %incdec.ptr168 = getelementptr inbounds i8, i8* %data.09349, i64 32
  %39 = load i8, i8* %incdec.ptr162, align 1, !tbaa !19
  %conv169 = zext i8 %39 to i32
  %or171 = or i32 %or166, %conv169
  %incdec.ptr173 = getelementptr inbounds i8, i8* %data.09349, i64 33
  %40 = load i8, i8* %incdec.ptr168, align 1, !tbaa !19
  %conv174 = zext i8 %40 to i32
  %shl175 = shl nuw i32 %conv174, 24
  %incdec.ptr177 = getelementptr inbounds i8, i8* %data.09349, i64 34
  %41 = load i8, i8* %incdec.ptr173, align 1, !tbaa !19
  %conv178 = zext i8 %41 to i32
  %shl179 = shl nuw nsw i32 %conv178, 16
  %or181 = or i32 %shl179, %shl175
  %incdec.ptr183 = getelementptr inbounds i8, i8* %data.09349, i64 35
  %42 = load i8, i8* %incdec.ptr177, align 1, !tbaa !19
  %conv184 = zext i8 %42 to i32
  %shl185 = shl nuw nsw i32 %conv184, 8
  %or187 = or i32 %or181, %shl185
  %incdec.ptr189 = getelementptr inbounds i8, i8* %data.09349, i64 36
  %43 = load i8, i8* %incdec.ptr183, align 1, !tbaa !19
  %conv190 = zext i8 %43 to i32
  %or192 = or i32 %or187, %conv190
  %incdec.ptr194 = getelementptr inbounds i8, i8* %data.09349, i64 37
  %44 = load i8, i8* %incdec.ptr189, align 1, !tbaa !19
  %conv195 = zext i8 %44 to i32
  %shl196 = shl nuw i32 %conv195, 24
  %incdec.ptr198 = getelementptr inbounds i8, i8* %data.09349, i64 38
  %45 = load i8, i8* %incdec.ptr194, align 1, !tbaa !19
  %conv199 = zext i8 %45 to i32
  %shl200 = shl nuw nsw i32 %conv199, 16
  %or202 = or i32 %shl200, %shl196
  %incdec.ptr204 = getelementptr inbounds i8, i8* %data.09349, i64 39
  %46 = load i8, i8* %incdec.ptr198, align 1, !tbaa !19
  %conv205 = zext i8 %46 to i32
  %shl206 = shl nuw nsw i32 %conv205, 8
  %or208 = or i32 %or202, %shl206
  %incdec.ptr210 = getelementptr inbounds i8, i8* %data.09349, i64 40
  %47 = load i8, i8* %incdec.ptr204, align 1, !tbaa !19
  %conv211 = zext i8 %47 to i32
  %or213 = or i32 %or208, %conv211
  %incdec.ptr215 = getelementptr inbounds i8, i8* %data.09349, i64 41
  %48 = load i8, i8* %incdec.ptr210, align 1, !tbaa !19
  %conv216 = zext i8 %48 to i32
  %shl217 = shl nuw i32 %conv216, 24
  %incdec.ptr219 = getelementptr inbounds i8, i8* %data.09349, i64 42
  %49 = load i8, i8* %incdec.ptr215, align 1, !tbaa !19
  %conv220 = zext i8 %49 to i32
  %shl221 = shl nuw nsw i32 %conv220, 16
  %or223 = or i32 %shl221, %shl217
  %incdec.ptr225 = getelementptr inbounds i8, i8* %data.09349, i64 43
  %50 = load i8, i8* %incdec.ptr219, align 1, !tbaa !19
  %conv226 = zext i8 %50 to i32
  %shl227 = shl nuw nsw i32 %conv226, 8
  %or229 = or i32 %or223, %shl227
  %incdec.ptr231 = getelementptr inbounds i8, i8* %data.09349, i64 44
  %51 = load i8, i8* %incdec.ptr225, align 1, !tbaa !19
  %conv232 = zext i8 %51 to i32
  %or234 = or i32 %or229, %conv232
  %incdec.ptr236 = getelementptr inbounds i8, i8* %data.09349, i64 45
  %52 = load i8, i8* %incdec.ptr231, align 1, !tbaa !19
  %conv237 = zext i8 %52 to i32
  %shl238 = shl nuw i32 %conv237, 24
  %incdec.ptr240 = getelementptr inbounds i8, i8* %data.09349, i64 46
  %53 = load i8, i8* %incdec.ptr236, align 1, !tbaa !19
  %conv241 = zext i8 %53 to i32
  %shl242 = shl nuw nsw i32 %conv241, 16
  %or244 = or i32 %shl242, %shl238
  %incdec.ptr246 = getelementptr inbounds i8, i8* %data.09349, i64 47
  %54 = load i8, i8* %incdec.ptr240, align 1, !tbaa !19
  %conv247 = zext i8 %54 to i32
  %shl248 = shl nuw nsw i32 %conv247, 8
  %or250 = or i32 %or244, %shl248
  %incdec.ptr252 = getelementptr inbounds i8, i8* %data.09349, i64 48
  %55 = load i8, i8* %incdec.ptr246, align 1, !tbaa !19
  %conv253 = zext i8 %55 to i32
  %or255 = or i32 %or250, %conv253
  %incdec.ptr257 = getelementptr inbounds i8, i8* %data.09349, i64 49
  %56 = load i8, i8* %incdec.ptr252, align 1, !tbaa !19
  %conv258 = zext i8 %56 to i32
  %shl259 = shl nuw i32 %conv258, 24
  %incdec.ptr261 = getelementptr inbounds i8, i8* %data.09349, i64 50
  %57 = load i8, i8* %incdec.ptr257, align 1, !tbaa !19
  %conv262 = zext i8 %57 to i32
  %shl263 = shl nuw nsw i32 %conv262, 16
  %or265 = or i32 %shl263, %shl259
  %incdec.ptr267 = getelementptr inbounds i8, i8* %data.09349, i64 51
  %58 = load i8, i8* %incdec.ptr261, align 1, !tbaa !19
  %conv268 = zext i8 %58 to i32
  %shl269 = shl nuw nsw i32 %conv268, 8
  %or271 = or i32 %or265, %shl269
  %incdec.ptr273 = getelementptr inbounds i8, i8* %data.09349, i64 52
  %59 = load i8, i8* %incdec.ptr267, align 1, !tbaa !19
  %conv274 = zext i8 %59 to i32
  %or276 = or i32 %or271, %conv274
  %incdec.ptr278 = getelementptr inbounds i8, i8* %data.09349, i64 53
  %60 = load i8, i8* %incdec.ptr273, align 1, !tbaa !19
  %conv279 = zext i8 %60 to i32
  %shl280 = shl nuw i32 %conv279, 24
  %incdec.ptr282 = getelementptr inbounds i8, i8* %data.09349, i64 54
  %61 = load i8, i8* %incdec.ptr278, align 1, !tbaa !19
  %conv283 = zext i8 %61 to i32
  %shl284 = shl nuw nsw i32 %conv283, 16
  %or286 = or i32 %shl284, %shl280
  %incdec.ptr288 = getelementptr inbounds i8, i8* %data.09349, i64 55
  %62 = load i8, i8* %incdec.ptr282, align 1, !tbaa !19
  %conv289 = zext i8 %62 to i32
  %shl290 = shl nuw nsw i32 %conv289, 8
  %or292 = or i32 %or286, %shl290
  %incdec.ptr294 = getelementptr inbounds i8, i8* %data.09349, i64 56
  %63 = load i8, i8* %incdec.ptr288, align 1, !tbaa !19
  %conv295 = zext i8 %63 to i32
  %or297 = or i32 %or292, %conv295
  %incdec.ptr299 = getelementptr inbounds i8, i8* %data.09349, i64 57
  %64 = load i8, i8* %incdec.ptr294, align 1, !tbaa !19
  %conv300 = zext i8 %64 to i32
  %shl301 = shl nuw i32 %conv300, 24
  %incdec.ptr303 = getelementptr inbounds i8, i8* %data.09349, i64 58
  %65 = load i8, i8* %incdec.ptr299, align 1, !tbaa !19
  %conv304 = zext i8 %65 to i32
  %shl305 = shl nuw nsw i32 %conv304, 16
  %or307 = or i32 %shl305, %shl301
  %incdec.ptr309 = getelementptr inbounds i8, i8* %data.09349, i64 59
  %66 = load i8, i8* %incdec.ptr303, align 1, !tbaa !19
  %conv310 = zext i8 %66 to i32
  %shl311 = shl nuw nsw i32 %conv310, 8
  %or313 = or i32 %or307, %shl311
  %incdec.ptr315 = getelementptr inbounds i8, i8* %data.09349, i64 60
  %67 = load i8, i8* %incdec.ptr309, align 1, !tbaa !19
  %conv316 = zext i8 %67 to i32
  %or318 = or i32 %or313, %conv316
  %incdec.ptr320 = getelementptr inbounds i8, i8* %data.09349, i64 61
  %68 = load i8, i8* %incdec.ptr315, align 1, !tbaa !19
  %conv321 = zext i8 %68 to i32
  %shl322 = shl nuw i32 %conv321, 24
  %incdec.ptr324 = getelementptr inbounds i8, i8* %data.09349, i64 62
  %69 = load i8, i8* %incdec.ptr320, align 1, !tbaa !19
  %conv325 = zext i8 %69 to i32
  %shl326 = shl nuw nsw i32 %conv325, 16
  %or328 = or i32 %shl326, %shl322
  %incdec.ptr330 = getelementptr inbounds i8, i8* %data.09349, i64 63
  %70 = load i8, i8* %incdec.ptr324, align 1, !tbaa !19
  %conv331 = zext i8 %70 to i32
  %shl332 = shl nuw nsw i32 %conv331, 8
  %or334 = or i32 %or328, %shl332
  %incdec.ptr336 = getelementptr inbounds i8, i8* %data.09349, i64 64
  %71 = load i8, i8* %incdec.ptr330, align 1, !tbaa !19
  %conv337 = zext i8 %71 to i32
  %or339 = or i32 %or334, %conv337
  %or342 = tail call i32 @llvm.fshl.i32(i32 %7, i32 %7, i32 12)
  %add = add i32 %or342, 2043430169
  %add343 = add i32 %add, %3
  %or347 = tail call i32 @llvm.fshl.i32(i32 %add343, i32 %add343, i32 7)
  %xor = xor i32 %6, %7
  %xor348 = xor i32 %xor, %5
  %add349 = add i32 %xor348, %4
  %xor350 = xor i32 %or347, %or342
  %add351 = add i32 %add349, %xor350
  %xor352 = xor i32 %or108, %or24
  %add353 = add i32 %add351, %xor352
  %xor354 = xor i32 %2, %3
  %xor355 = xor i32 %xor354, %1
  %add356 = add i32 %0, %or347
  %add357 = add i32 %add356, %xor355
  %add358 = add i32 %add357, %or24
  %or362 = tail call i32 @llvm.fshl.i32(i32 %6, i32 %6, i32 9)
  %or366 = tail call i32 @llvm.fshl.i32(i32 %2, i32 %2, i32 19)
  %or370 = tail call i32 @llvm.fshl.i32(i32 %add358, i32 %add358, i32 9)
  %xor371 = xor i32 %or370, %add358
  %or375 = tail call i32 @llvm.fshl.i32(i32 %add358, i32 %add358, i32 17)
  %xor376 = xor i32 %xor371, %or375
  %xor377 = xor i32 %or171, %or24
  %or381 = tail call i32 @llvm.fshl.i32(i32 %or297, i32 %or286, i32 15)
  %xor382 = xor i32 %xor377, %or381
  %or398 = tail call i32 @llvm.fshl.i32(i32 %xor382, i32 %xor382, i32 15)
  %or415 = tail call i32 @llvm.fshl.i32(i32 %xor382, i32 %xor382, i32 23)
  %shl417 = shl i32 %or87, 7
  %shr419 = lshr i32 %conv69, 1
  %or420 = or i32 %shl417, %shr419
  %xor399 = xor i32 %or234, %or420
  %xor416 = xor i32 %xor399, %xor382
  %xor421 = xor i32 %xor416, %or398
  %xor422 = xor i32 %xor421, %or415
  %or428 = tail call i32 @llvm.fshl.i32(i32 %add353, i32 %add353, i32 12)
  %add430 = add i32 %xor376, -208106958
  %add431 = add i32 %add430, %or428
  %or436 = tail call i32 @llvm.fshl.i32(i32 %add431, i32 %add431, i32 7)
  %xor438 = xor i32 %or362, %7
  %xor439 = xor i32 %xor438, %add353
  %add440 = add i32 %xor439, %5
  %xor441 = xor i32 %or436, %or428
  %xor443 = xor i32 %or129, %or45
  %add442 = add i32 %add440, %xor443
  %add444 = add i32 %add442, %xor441
  %xor446 = xor i32 %or366, %3
  %xor447 = xor i32 %xor446, %xor376
  %add448 = add i32 %or45, %1
  %add449 = add i32 %add448, %xor447
  %add450 = add i32 %add449, %or436
  %or454 = tail call i32 @llvm.fshl.i32(i32 %7, i32 %7, i32 9)
  %or458 = tail call i32 @llvm.fshl.i32(i32 %3, i32 %3, i32 19)
  %or462 = tail call i32 @llvm.fshl.i32(i32 %add450, i32 %add450, i32 9)
  %xor463 = xor i32 %or462, %add450
  %or467 = tail call i32 @llvm.fshl.i32(i32 %add450, i32 %add450, i32 17)
  %xor468 = xor i32 %xor463, %or467
  %xor471 = xor i32 %or192, %or45
  %or475 = tail call i32 @llvm.fshl.i32(i32 %or318, i32 %or307, i32 15)
  %xor476 = xor i32 %xor471, %or475
  %or492 = tail call i32 @llvm.fshl.i32(i32 %xor476, i32 %xor476, i32 15)
  %or509 = tail call i32 @llvm.fshl.i32(i32 %xor476, i32 %xor476, i32 23)
  %shl511 = shl i32 %or108, 7
  %shr513 = lshr i32 %conv90, 1
  %or514 = or i32 %shl511, %shr513
  %xor493 = xor i32 %or255, %or514
  %xor510 = xor i32 %xor493, %xor476
  %xor515 = xor i32 %xor510, %or492
  %xor516 = xor i32 %xor515, %or509
  %or522 = tail call i32 @llvm.fshl.i32(i32 %add444, i32 %add444, i32 12)
  %add524 = add i32 %or522, -416213915
  %add525 = add i32 %add524, %xor468
  %or530 = tail call i32 @llvm.fshl.i32(i32 %add525, i32 %add525, i32 7)
  %xor532 = xor i32 %add353, %or454
  %xor533 = xor i32 %xor532, %add444
  %xor535 = xor i32 %or530, %or522
  %xor537 = xor i32 %or150, %or66
  %add534 = add i32 %xor537, %or362
  %add536 = add i32 %add534, %xor533
  %add538 = add i32 %add536, %xor535
  %xor540 = xor i32 %xor376, %or458
  %xor541 = xor i32 %xor540, %xor468
  %add542 = add i32 %or66, %or366
  %add543 = add i32 %add542, %xor541
  %add544 = add i32 %add543, %or530
  %or548 = tail call i32 @llvm.fshl.i32(i32 %add353, i32 %add353, i32 9)
  %or552 = tail call i32 @llvm.fshl.i32(i32 %xor376, i32 %xor376, i32 19)
  %or556 = tail call i32 @llvm.fshl.i32(i32 %add544, i32 %add544, i32 9)
  %xor557 = xor i32 %or556, %add544
  %or561 = tail call i32 @llvm.fshl.i32(i32 %add544, i32 %add544, i32 17)
  %xor562 = xor i32 %xor557, %or561
  %xor565 = xor i32 %or213, %or66
  %or569 = tail call i32 @llvm.fshl.i32(i32 %or339, i32 %or328, i32 15)
  %xor570 = xor i32 %xor565, %or569
  %or586 = tail call i32 @llvm.fshl.i32(i32 %xor570, i32 %xor570, i32 15)
  %or603 = tail call i32 @llvm.fshl.i32(i32 %xor570, i32 %xor570, i32 23)
  %shl605 = shl i32 %or129, 7
  %shr607 = lshr i32 %conv111, 1
  %or608 = or i32 %shl605, %shr607
  %xor587 = xor i32 %or276, %or608
  %xor604 = xor i32 %xor587, %xor570
  %xor609 = xor i32 %xor604, %or586
  %xor610 = xor i32 %xor609, %or603
  %or616 = tail call i32 @llvm.fshl.i32(i32 %add538, i32 %add538, i32 12)
  %add618 = add i32 %or616, -832427829
  %add619 = add i32 %add618, %xor562
  %or624 = tail call i32 @llvm.fshl.i32(i32 %add619, i32 %add619, i32 7)
  %xor626 = xor i32 %add444, %or548
  %xor627 = xor i32 %xor626, %add538
  %xor629 = xor i32 %or624, %or616
  %xor631 = xor i32 %or171, %or87
  %add628 = add i32 %xor631, %or454
  %add630 = add i32 %add628, %xor627
  %add632 = add i32 %add630, %xor629
  %xor634 = xor i32 %xor468, %or552
  %xor635 = xor i32 %xor634, %xor562
  %add636 = add i32 %or87, %or458
  %add637 = add i32 %add636, %xor635
  %add638 = add i32 %add637, %or624
  %or642 = tail call i32 @llvm.fshl.i32(i32 %add444, i32 %add444, i32 9)
  %or646 = tail call i32 @llvm.fshl.i32(i32 %xor468, i32 %xor468, i32 19)
  %or650 = tail call i32 @llvm.fshl.i32(i32 %add638, i32 %add638, i32 9)
  %xor651 = xor i32 %or650, %add638
  %or655 = tail call i32 @llvm.fshl.i32(i32 %add638, i32 %add638, i32 17)
  %xor656 = xor i32 %xor651, %or655
  %xor659 = xor i32 %or234, %or87
  %or663 = tail call i32 @llvm.fshl.i32(i32 %xor422, i32 %xor422, i32 15)
  %xor664 = xor i32 %xor659, %or663
  %or680 = tail call i32 @llvm.fshl.i32(i32 %xor664, i32 %xor664, i32 15)
  %or697 = tail call i32 @llvm.fshl.i32(i32 %xor664, i32 %xor664, i32 23)
  %shl699 = shl i32 %or150, 7
  %shr701 = lshr i32 %conv132, 1
  %or702 = or i32 %shl699, %shr701
  %xor681 = xor i32 %or297, %or702
  %xor698 = xor i32 %xor681, %xor664
  %xor703 = xor i32 %xor698, %or680
  %xor704 = xor i32 %xor703, %or697
  %or710 = tail call i32 @llvm.fshl.i32(i32 %add632, i32 %add632, i32 12)
  %add712 = add i32 %or710, -1664855657
  %add713 = add i32 %add712, %xor656
  %or718 = tail call i32 @llvm.fshl.i32(i32 %add713, i32 %add713, i32 7)
  %xor720 = xor i32 %add538, %or642
  %xor721 = xor i32 %xor720, %add632
  %xor723 = xor i32 %or718, %or710
  %xor725 = xor i32 %or192, %or108
  %add722 = add i32 %xor725, %or548
  %add724 = add i32 %add722, %xor721
  %add726 = add i32 %add724, %xor723
  %xor728 = xor i32 %xor562, %or646
  %xor729 = xor i32 %xor728, %xor656
  %add730 = add i32 %or108, %or552
  %add731 = add i32 %add730, %xor729
  %add732 = add i32 %add731, %or718
  %or736 = tail call i32 @llvm.fshl.i32(i32 %add538, i32 %add538, i32 9)
  %or740 = tail call i32 @llvm.fshl.i32(i32 %xor562, i32 %xor562, i32 19)
  %or744 = tail call i32 @llvm.fshl.i32(i32 %add732, i32 %add732, i32 9)
  %xor745 = xor i32 %or744, %add732
  %or749 = tail call i32 @llvm.fshl.i32(i32 %add732, i32 %add732, i32 17)
  %xor750 = xor i32 %xor745, %or749
  %xor753 = xor i32 %or255, %or108
  %or757 = tail call i32 @llvm.fshl.i32(i32 %xor516, i32 %xor516, i32 15)
  %xor758 = xor i32 %xor753, %or757
  %or774 = tail call i32 @llvm.fshl.i32(i32 %xor758, i32 %xor758, i32 15)
  %or791 = tail call i32 @llvm.fshl.i32(i32 %xor758, i32 %xor758, i32 23)
  %shl793 = shl i32 %or171, 7
  %shr795 = lshr i32 %conv153, 1
  %or796 = or i32 %shl793, %shr795
  %xor775 = xor i32 %or318, %or796
  %xor792 = xor i32 %xor775, %xor758
  %xor797 = xor i32 %xor792, %or774
  %xor798 = xor i32 %xor797, %or791
  %or804 = tail call i32 @llvm.fshl.i32(i32 %add726, i32 %add726, i32 12)
  %add806 = add i32 %or804, 965255983
  %add807 = add i32 %add806, %xor750
  %or812 = tail call i32 @llvm.fshl.i32(i32 %add807, i32 %add807, i32 7)
  %xor814 = xor i32 %add632, %or736
  %xor815 = xor i32 %xor814, %add726
  %xor817 = xor i32 %or812, %or804
  %xor819 = xor i32 %or213, %or129
  %add816 = add i32 %xor819, %or642
  %add818 = add i32 %add816, %xor815
  %add820 = add i32 %add818, %xor817
  %xor822 = xor i32 %xor656, %or740
  %xor823 = xor i32 %xor822, %xor750
  %add824 = add i32 %or646, %or129
  %add825 = add i32 %add824, %xor823
  %add826 = add i32 %add825, %or812
  %or830 = tail call i32 @llvm.fshl.i32(i32 %add632, i32 %add632, i32 9)
  %or834 = tail call i32 @llvm.fshl.i32(i32 %xor656, i32 %xor656, i32 19)
  %or838 = tail call i32 @llvm.fshl.i32(i32 %add826, i32 %add826, i32 9)
  %xor839 = xor i32 %or838, %add826
  %or843 = tail call i32 @llvm.fshl.i32(i32 %add826, i32 %add826, i32 17)
  %xor844 = xor i32 %xor839, %or843
  %xor847 = xor i32 %or276, %or129
  %or851 = tail call i32 @llvm.fshl.i32(i32 %xor610, i32 %xor610, i32 15)
  %xor852 = xor i32 %xor847, %or851
  %or868 = tail call i32 @llvm.fshl.i32(i32 %xor852, i32 %xor852, i32 15)
  %or885 = tail call i32 @llvm.fshl.i32(i32 %xor852, i32 %xor852, i32 23)
  %shl887 = shl i32 %or192, 7
  %shr889 = lshr i32 %conv174, 1
  %or890 = or i32 %shl887, %shr889
  %xor869 = xor i32 %or339, %or890
  %xor886 = xor i32 %xor869, %xor852
  %xor891 = xor i32 %xor886, %or868
  %xor892 = xor i32 %xor891, %or885
  %or898 = tail call i32 @llvm.fshl.i32(i32 %add820, i32 %add820, i32 12)
  %add900 = add i32 %or898, 1930511966
  %add901 = add i32 %add900, %xor844
  %or906 = tail call i32 @llvm.fshl.i32(i32 %add901, i32 %add901, i32 7)
  %xor908 = xor i32 %add726, %or830
  %xor909 = xor i32 %xor908, %add820
  %xor911 = xor i32 %or906, %or898
  %xor913 = xor i32 %or234, %or150
  %add910 = add i32 %xor913, %or736
  %add912 = add i32 %add910, %xor909
  %add914 = add i32 %add912, %xor911
  %xor916 = xor i32 %xor750, %or834
  %xor917 = xor i32 %xor916, %xor844
  %add918 = add i32 %or740, %or150
  %add919 = add i32 %add918, %xor917
  %add920 = add i32 %add919, %or906
  %or924 = tail call i32 @llvm.fshl.i32(i32 %add726, i32 %add726, i32 9)
  %or928 = tail call i32 @llvm.fshl.i32(i32 %xor750, i32 %xor750, i32 19)
  %or932 = tail call i32 @llvm.fshl.i32(i32 %add920, i32 %add920, i32 9)
  %xor933 = xor i32 %or932, %add920
  %or937 = tail call i32 @llvm.fshl.i32(i32 %add920, i32 %add920, i32 17)
  %xor938 = xor i32 %xor933, %or937
  %xor941 = xor i32 %or297, %or150
  %or945 = tail call i32 @llvm.fshl.i32(i32 %xor704, i32 %xor704, i32 15)
  %xor946 = xor i32 %xor941, %or945
  %or962 = tail call i32 @llvm.fshl.i32(i32 %xor946, i32 %xor946, i32 15)
  %or979 = tail call i32 @llvm.fshl.i32(i32 %xor946, i32 %xor946, i32 23)
  %shl981 = shl i32 %or213, 7
  %shr983 = lshr i32 %conv195, 1
  %or984 = or i32 %shl981, %shr983
  %xor963 = xor i32 %xor422, %or984
  %xor980 = xor i32 %xor963, %xor946
  %xor985 = xor i32 %xor980, %or962
  %xor986 = xor i32 %xor985, %or979
  %or992 = tail call i32 @llvm.fshl.i32(i32 %add914, i32 %add914, i32 12)
  %add994 = add i32 %or992, -433943364
  %add995 = add i32 %add994, %xor938
  %or1000 = tail call i32 @llvm.fshl.i32(i32 %add995, i32 %add995, i32 7)
  %xor1002 = xor i32 %add820, %or924
  %xor1003 = xor i32 %xor1002, %add914
  %xor1005 = xor i32 %or1000, %or992
  %xor1007 = xor i32 %or255, %or171
  %add1004 = add i32 %xor1007, %or830
  %add1006 = add i32 %add1004, %xor1003
  %add1008 = add i32 %add1006, %xor1005
  %xor1010 = xor i32 %xor844, %or928
  %xor1011 = xor i32 %xor1010, %xor938
  %add1012 = add i32 %or834, %or171
  %add1013 = add i32 %add1012, %xor1011
  %add1014 = add i32 %add1013, %or1000
  %or1018 = tail call i32 @llvm.fshl.i32(i32 %add820, i32 %add820, i32 9)
  %or1022 = tail call i32 @llvm.fshl.i32(i32 %xor844, i32 %xor844, i32 19)
  %or1026 = tail call i32 @llvm.fshl.i32(i32 %add1014, i32 %add1014, i32 9)
  %xor1027 = xor i32 %or1026, %add1014
  %or1031 = tail call i32 @llvm.fshl.i32(i32 %add1014, i32 %add1014, i32 17)
  %xor1032 = xor i32 %xor1027, %or1031
  %xor1035 = xor i32 %or318, %or171
  %or1039 = tail call i32 @llvm.fshl.i32(i32 %xor798, i32 %xor798, i32 15)
  %xor1040 = xor i32 %xor1035, %or1039
  %or1056 = tail call i32 @llvm.fshl.i32(i32 %xor1040, i32 %xor1040, i32 15)
  %or1073 = tail call i32 @llvm.fshl.i32(i32 %xor1040, i32 %xor1040, i32 23)
  %shl1075 = shl i32 %or234, 7
  %shr1077 = lshr i32 %conv216, 1
  %or1078 = or i32 %shl1075, %shr1077
  %xor1057 = xor i32 %xor516, %or1078
  %xor1074 = xor i32 %xor1057, %xor1040
  %xor1079 = xor i32 %xor1074, %or1056
  %xor1080 = xor i32 %xor1079, %or1073
  %or1086 = tail call i32 @llvm.fshl.i32(i32 %add1008, i32 %add1008, i32 12)
  %add1088 = add i32 %or1086, -867886727
  %add1089 = add i32 %add1088, %xor1032
  %or1094 = tail call i32 @llvm.fshl.i32(i32 %add1089, i32 %add1089, i32 7)
  %xor1096 = xor i32 %add914, %or1018
  %xor1097 = xor i32 %xor1096, %add1008
  %xor1099 = xor i32 %or1094, %or1086
  %xor1101 = xor i32 %or276, %or192
  %add1098 = add i32 %xor1101, %or924
  %add1100 = add i32 %add1098, %xor1097
  %add1102 = add i32 %add1100, %xor1099
  %xor1104 = xor i32 %xor938, %or1022
  %xor1105 = xor i32 %xor1104, %xor1032
  %add1106 = add i32 %or928, %or192
  %add1107 = add i32 %add1106, %xor1105
  %add1108 = add i32 %add1107, %or1094
  %or1112 = tail call i32 @llvm.fshl.i32(i32 %add914, i32 %add914, i32 9)
  %or1116 = tail call i32 @llvm.fshl.i32(i32 %xor938, i32 %xor938, i32 19)
  %or1120 = tail call i32 @llvm.fshl.i32(i32 %add1108, i32 %add1108, i32 9)
  %xor1121 = xor i32 %or1120, %add1108
  %or1125 = tail call i32 @llvm.fshl.i32(i32 %add1108, i32 %add1108, i32 17)
  %xor1126 = xor i32 %xor1121, %or1125
  %xor1129 = xor i32 %or339, %or192
  %or1133 = tail call i32 @llvm.fshl.i32(i32 %xor892, i32 %xor892, i32 15)
  %xor1134 = xor i32 %xor1129, %or1133
  %or1150 = tail call i32 @llvm.fshl.i32(i32 %xor1134, i32 %xor1134, i32 15)
  %or1167 = tail call i32 @llvm.fshl.i32(i32 %xor1134, i32 %xor1134, i32 23)
  %shl1169 = shl i32 %or255, 7
  %shr1171 = lshr i32 %conv237, 1
  %or1172 = or i32 %shl1169, %shr1171
  %xor1151 = xor i32 %xor610, %or1172
  %xor1168 = xor i32 %xor1151, %xor1134
  %xor1173 = xor i32 %xor1168, %or1150
  %xor1174 = xor i32 %xor1173, %or1167
  %or1180 = tail call i32 @llvm.fshl.i32(i32 %add1102, i32 %add1102, i32 12)
  %add1182 = add i32 %or1180, -1735773453
  %add1183 = add i32 %add1182, %xor1126
  %or1188 = tail call i32 @llvm.fshl.i32(i32 %add1183, i32 %add1183, i32 7)
  %xor1190 = xor i32 %add1008, %or1112
  %xor1191 = xor i32 %xor1190, %add1102
  %xor1193 = xor i32 %or1188, %or1180
  %xor1195 = xor i32 %or297, %or213
  %add1192 = add i32 %or1018, %xor1195
  %add1194 = add i32 %add1192, %xor1191
  %add1196 = add i32 %add1194, %xor1193
  %xor1198 = xor i32 %xor1032, %or1116
  %xor1199 = xor i32 %xor1198, %xor1126
  %add1200 = add i32 %or1022, %or213
  %add1201 = add i32 %add1200, %xor1199
  %add1202 = add i32 %add1201, %or1188
  %or1206 = tail call i32 @llvm.fshl.i32(i32 %add1008, i32 %add1008, i32 9)
  %or1210 = tail call i32 @llvm.fshl.i32(i32 %xor1032, i32 %xor1032, i32 19)
  %or1214 = tail call i32 @llvm.fshl.i32(i32 %add1202, i32 %add1202, i32 9)
  %xor1215 = xor i32 %or1214, %add1202
  %or1219 = tail call i32 @llvm.fshl.i32(i32 %add1202, i32 %add1202, i32 17)
  %xor1220 = xor i32 %xor1215, %or1219
  %xor1223 = xor i32 %xor422, %or213
  %or1227 = tail call i32 @llvm.fshl.i32(i32 %xor986, i32 %xor986, i32 15)
  %xor1228 = xor i32 %xor1223, %or1227
  %or1244 = tail call i32 @llvm.fshl.i32(i32 %xor1228, i32 %xor1228, i32 15)
  %or1261 = tail call i32 @llvm.fshl.i32(i32 %xor1228, i32 %xor1228, i32 23)
  %shl1263 = shl i32 %or276, 7
  %shr1265 = lshr i32 %conv258, 1
  %or1266 = or i32 %shl1263, %shr1265
  %xor1245 = xor i32 %xor704, %or1266
  %xor1262 = xor i32 %xor1245, %xor1228
  %xor1267 = xor i32 %xor1262, %or1244
  %xor1268 = xor i32 %xor1267, %or1261
  %or1274 = tail call i32 @llvm.fshl.i32(i32 %add1196, i32 %add1196, i32 12)
  %add1276 = add i32 %or1274, 823420391
  %add1277 = add i32 %add1276, %xor1220
  %or1282 = tail call i32 @llvm.fshl.i32(i32 %add1277, i32 %add1277, i32 7)
  %xor1284 = xor i32 %add1102, %or1206
  %xor1285 = xor i32 %xor1284, %add1196
  %xor1287 = xor i32 %or1282, %or1274
  %xor1289 = xor i32 %or318, %or234
  %add1286 = add i32 %or1112, %xor1289
  %add1288 = add i32 %add1286, %xor1285
  %add1290 = add i32 %add1288, %xor1287
  %xor1292 = xor i32 %xor1126, %or1210
  %xor1293 = xor i32 %xor1292, %xor1220
  %add1294 = add i32 %or1116, %or234
  %add1295 = add i32 %add1294, %xor1293
  %add1296 = add i32 %add1295, %or1282
  %or1300 = tail call i32 @llvm.fshl.i32(i32 %add1102, i32 %add1102, i32 9)
  %or1304 = tail call i32 @llvm.fshl.i32(i32 %xor1126, i32 %xor1126, i32 19)
  %or1308 = tail call i32 @llvm.fshl.i32(i32 %add1296, i32 %add1296, i32 9)
  %xor1309 = xor i32 %or1308, %add1296
  %or1313 = tail call i32 @llvm.fshl.i32(i32 %add1296, i32 %add1296, i32 17)
  %xor1314 = xor i32 %xor1309, %or1313
  %xor1317 = xor i32 %xor516, %or234
  %or1321 = tail call i32 @llvm.fshl.i32(i32 %xor1080, i32 %xor1080, i32 15)
  %xor1322 = xor i32 %xor1317, %or1321
  %or1338 = tail call i32 @llvm.fshl.i32(i32 %xor1322, i32 %xor1322, i32 15)
  %or1355 = tail call i32 @llvm.fshl.i32(i32 %xor1322, i32 %xor1322, i32 23)
  %shl1357 = shl i32 %or297, 7
  %shr1359 = lshr i32 %conv279, 1
  %or1360 = or i32 %shl1357, %shr1359
  %xor1339 = xor i32 %xor798, %or1360
  %xor1356 = xor i32 %xor1339, %xor1322
  %xor1361 = xor i32 %xor1356, %or1338
  %xor1362 = xor i32 %xor1361, %or1355
  %or1368 = tail call i32 @llvm.fshl.i32(i32 %add1290, i32 %add1290, i32 12)
  %add1370 = add i32 %or1368, 1646840782
  %add1371 = add i32 %add1370, %xor1314
  %or1376 = tail call i32 @llvm.fshl.i32(i32 %add1371, i32 %add1371, i32 7)
  %xor1378 = xor i32 %add1196, %or1300
  %xor1379 = xor i32 %xor1378, %add1290
  %xor1381 = xor i32 %or1376, %or1368
  %xor1383 = xor i32 %or339, %or255
  %add1380 = add i32 %or1206, %xor1383
  %add1382 = add i32 %add1380, %xor1379
  %add1384 = add i32 %add1382, %xor1381
  %xor1386 = xor i32 %xor1220, %or1304
  %xor1387 = xor i32 %xor1386, %xor1314
  %add1388 = add i32 %or1210, %or255
  %add1389 = add i32 %add1388, %xor1387
  %add1390 = add i32 %add1389, %or1376
  %or1394 = tail call i32 @llvm.fshl.i32(i32 %add1196, i32 %add1196, i32 9)
  %or1398 = tail call i32 @llvm.fshl.i32(i32 %xor1220, i32 %xor1220, i32 19)
  %or1402 = tail call i32 @llvm.fshl.i32(i32 %add1390, i32 %add1390, i32 9)
  %xor1403 = xor i32 %or1402, %add1390
  %or1407 = tail call i32 @llvm.fshl.i32(i32 %add1390, i32 %add1390, i32 17)
  %xor1408 = xor i32 %xor1403, %or1407
  %xor1411 = xor i32 %xor610, %or255
  %or1415 = tail call i32 @llvm.fshl.i32(i32 %xor1174, i32 %xor1174, i32 15)
  %xor1416 = xor i32 %xor1411, %or1415
  %or1432 = tail call i32 @llvm.fshl.i32(i32 %xor1416, i32 %xor1416, i32 15)
  %or1449 = tail call i32 @llvm.fshl.i32(i32 %xor1416, i32 %xor1416, i32 23)
  %shl1451 = shl i32 %or318, 7
  %shr1453 = lshr i32 %conv300, 1
  %or1454 = or i32 %shl1451, %shr1453
  %xor1433 = xor i32 %xor892, %or1454
  %xor1450 = xor i32 %xor1433, %xor1416
  %xor1455 = xor i32 %xor1450, %or1432
  %xor1456 = xor i32 %xor1455, %or1449
  %or1462 = tail call i32 @llvm.fshl.i32(i32 %add1384, i32 %add1384, i32 12)
  %add1464 = add i32 %or1462, -1001285732
  %add1465 = add i32 %add1464, %xor1408
  %or1470 = tail call i32 @llvm.fshl.i32(i32 %add1465, i32 %add1465, i32 7)
  %xor1472 = xor i32 %add1290, %or1394
  %xor1473 = xor i32 %xor1472, %add1384
  %xor1475 = xor i32 %or1470, %or1462
  %xor1477 = xor i32 %xor422, %or276
  %add1474 = add i32 %or1300, %xor1477
  %add1476 = add i32 %add1474, %xor1473
  %add1478 = add i32 %add1476, %xor1475
  %xor1480 = xor i32 %xor1314, %or1398
  %xor1481 = xor i32 %xor1480, %xor1408
  %add1482 = add i32 %or1304, %or276
  %add1483 = add i32 %add1482, %xor1481
  %add1484 = add i32 %add1483, %or1470
  %or1488 = tail call i32 @llvm.fshl.i32(i32 %add1290, i32 %add1290, i32 9)
  %or1492 = tail call i32 @llvm.fshl.i32(i32 %xor1314, i32 %xor1314, i32 19)
  %or1496 = tail call i32 @llvm.fshl.i32(i32 %add1484, i32 %add1484, i32 9)
  %xor1497 = xor i32 %or1496, %add1484
  %or1501 = tail call i32 @llvm.fshl.i32(i32 %add1484, i32 %add1484, i32 17)
  %xor1502 = xor i32 %xor1497, %or1501
  %xor1505 = xor i32 %xor704, %or276
  %or1509 = tail call i32 @llvm.fshl.i32(i32 %xor1268, i32 %xor1268, i32 15)
  %xor1510 = xor i32 %xor1505, %or1509
  %or1526 = tail call i32 @llvm.fshl.i32(i32 %xor1510, i32 %xor1510, i32 15)
  %or1543 = tail call i32 @llvm.fshl.i32(i32 %xor1510, i32 %xor1510, i32 23)
  %shl1545 = shl i32 %or339, 7
  %shr1547 = lshr i32 %conv321, 1
  %or1548 = or i32 %shl1545, %shr1547
  %xor1527 = xor i32 %xor986, %or1548
  %xor1544 = xor i32 %xor1527, %xor1510
  %xor1549 = xor i32 %xor1544, %or1526
  %xor1550 = xor i32 %xor1549, %or1543
  %or1556 = tail call i32 @llvm.fshl.i32(i32 %add1478, i32 %add1478, i32 12)
  %add1558 = add i32 %or1556, -2002571463
  %add1559 = add i32 %add1558, %xor1502
  %or1564 = tail call i32 @llvm.fshl.i32(i32 %add1559, i32 %add1559, i32 7)
  %xor1566 = xor i32 %add1384, %or1488
  %xor1567 = xor i32 %xor1566, %add1478
  %xor1569 = xor i32 %or1564, %or1556
  %xor1571 = xor i32 %xor516, %or297
  %add1568 = add i32 %or1394, %xor1571
  %add1570 = add i32 %add1568, %xor1567
  %add1572 = add i32 %add1570, %xor1569
  %xor1574 = xor i32 %xor1408, %or1492
  %xor1575 = xor i32 %xor1574, %xor1502
  %add1576 = add i32 %or1398, %or297
  %add1577 = add i32 %add1576, %xor1575
  %add1578 = add i32 %add1577, %or1564
  %or1582 = tail call i32 @llvm.fshl.i32(i32 %add1384, i32 %add1384, i32 9)
  %or1586 = tail call i32 @llvm.fshl.i32(i32 %xor1408, i32 %xor1408, i32 19)
  %or1590 = tail call i32 @llvm.fshl.i32(i32 %add1578, i32 %add1578, i32 9)
  %xor1591 = xor i32 %or1590, %add1578
  %or1595 = tail call i32 @llvm.fshl.i32(i32 %add1578, i32 %add1578, i32 17)
  %xor1596 = xor i32 %xor1591, %or1595
  %xor1599 = xor i32 %xor798, %or297
  %or1603 = tail call i32 @llvm.fshl.i32(i32 %xor1362, i32 %xor1362, i32 15)
  %xor1604 = xor i32 %xor1599, %or1603
  %or1620 = tail call i32 @llvm.fshl.i32(i32 %xor1604, i32 %xor1604, i32 15)
  %or1637 = tail call i32 @llvm.fshl.i32(i32 %xor1604, i32 %xor1604, i32 23)
  %or1642 = tail call i32 @llvm.fshl.i32(i32 %xor422, i32 %xor422, i32 7)
  %xor1621 = xor i32 %xor1080, %or1642
  %xor1638 = xor i32 %xor1621, %xor1604
  %xor1643 = xor i32 %xor1638, %or1620
  %xor1644 = xor i32 %xor1643, %or1637
  %or1650 = tail call i32 @llvm.fshl.i32(i32 %add1572, i32 %add1572, i32 12)
  %add1652 = add i32 %or1650, 289824371
  %add1653 = add i32 %add1652, %xor1596
  %or1658 = tail call i32 @llvm.fshl.i32(i32 %add1653, i32 %add1653, i32 7)
  %xor1660 = xor i32 %add1478, %or1582
  %xor1661 = xor i32 %xor1660, %add1572
  %xor1663 = xor i32 %or1658, %or1650
  %xor1665 = xor i32 %xor610, %or318
  %add1662 = add i32 %or1488, %xor1665
  %add1664 = add i32 %add1662, %xor1661
  %add1666 = add i32 %add1664, %xor1663
  %xor1668 = xor i32 %xor1502, %or1586
  %xor1669 = xor i32 %xor1668, %xor1596
  %add1670 = add i32 %or1492, %or318
  %add1671 = add i32 %add1670, %xor1669
  %add1672 = add i32 %add1671, %or1658
  %or1676 = tail call i32 @llvm.fshl.i32(i32 %add1478, i32 %add1478, i32 9)
  %or1680 = tail call i32 @llvm.fshl.i32(i32 %xor1502, i32 %xor1502, i32 19)
  %or1684 = tail call i32 @llvm.fshl.i32(i32 %add1672, i32 %add1672, i32 9)
  %xor1685 = xor i32 %or1684, %add1672
  %or1689 = tail call i32 @llvm.fshl.i32(i32 %add1672, i32 %add1672, i32 17)
  %xor1690 = xor i32 %xor1685, %or1689
  %xor1693 = xor i32 %xor892, %or318
  %or1697 = tail call i32 @llvm.fshl.i32(i32 %xor1456, i32 %xor1456, i32 15)
  %xor1698 = xor i32 %xor1693, %or1697
  %or1714 = tail call i32 @llvm.fshl.i32(i32 %xor1698, i32 %xor1698, i32 15)
  %or1731 = tail call i32 @llvm.fshl.i32(i32 %xor1698, i32 %xor1698, i32 23)
  %or1736 = tail call i32 @llvm.fshl.i32(i32 %xor516, i32 %xor516, i32 7)
  %xor1715 = xor i32 %xor1174, %or1736
  %xor1732 = xor i32 %xor1715, %xor1698
  %xor1737 = xor i32 %xor1732, %or1714
  %xor1738 = xor i32 %xor1737, %or1731
  %or1744 = tail call i32 @llvm.fshl.i32(i32 %add1666, i32 %add1666, i32 12)
  %add1746 = add i32 %or1744, 579648742
  %add1747 = add i32 %add1746, %xor1690
  %or1752 = tail call i32 @llvm.fshl.i32(i32 %add1747, i32 %add1747, i32 7)
  %xor1754 = xor i32 %add1572, %or1676
  %xor1755 = xor i32 %xor1754, %add1666
  %xor1757 = xor i32 %or1752, %or1744
  %xor1759 = xor i32 %xor704, %or339
  %add1756 = add i32 %or1582, %xor1759
  %add1758 = add i32 %add1756, %xor1755
  %add1760 = add i32 %add1758, %xor1757
  %xor1762 = xor i32 %xor1596, %or1680
  %xor1763 = xor i32 %xor1762, %xor1690
  %add1764 = add i32 %or1586, %or339
  %add1765 = add i32 %add1764, %xor1763
  %add1766 = add i32 %add1765, %or1752
  %or1770 = tail call i32 @llvm.fshl.i32(i32 %add1572, i32 %add1572, i32 9)
  %or1774 = tail call i32 @llvm.fshl.i32(i32 %xor1596, i32 %xor1596, i32 19)
  %or1778 = tail call i32 @llvm.fshl.i32(i32 %add1766, i32 %add1766, i32 9)
  %xor1779 = xor i32 %or1778, %add1766
  %or1783 = tail call i32 @llvm.fshl.i32(i32 %add1766, i32 %add1766, i32 17)
  %xor1784 = xor i32 %xor1779, %or1783
  %xor1787 = xor i32 %xor986, %or339
  %or1791 = tail call i32 @llvm.fshl.i32(i32 %xor1550, i32 %xor1550, i32 15)
  %xor1792 = xor i32 %xor1787, %or1791
  %or1808 = tail call i32 @llvm.fshl.i32(i32 %xor1792, i32 %xor1792, i32 15)
  %or1825 = tail call i32 @llvm.fshl.i32(i32 %xor1792, i32 %xor1792, i32 23)
  %or1830 = tail call i32 @llvm.fshl.i32(i32 %xor610, i32 %xor610, i32 7)
  %xor1809 = xor i32 %xor1268, %or1830
  %xor1826 = xor i32 %xor1809, %xor1792
  %xor1831 = xor i32 %xor1826, %or1808
  %xor1832 = xor i32 %xor1831, %or1825
  %or1838 = tail call i32 @llvm.fshl.i32(i32 %add1760, i32 %add1760, i32 12)
  %add1840 = add i32 %or1838, -1651869049
  %add1841 = add i32 %add1840, %xor1784
  %or1846 = tail call i32 @llvm.fshl.i32(i32 %add1841, i32 %add1841, i32 7)
  %and1848 = and i32 %add1760, %add1666
  %or1849 = or i32 %add1760, %add1666
  %and1850 = and i32 %or1849, %or1770
  %or1851 = or i32 %and1850, %and1848
  %xor1853 = xor i32 %or1846, %or1838
  %xor1855 = xor i32 %xor798, %xor422
  %add1852 = add i32 %or1676, %xor1855
  %add1854 = add i32 %add1852, %or1851
  %add1856 = add i32 %add1854, %xor1853
  %xor1858 = xor i32 %xor1690, %or1774
  %and1859 = and i32 %xor1784, %xor1858
  %xor1860 = xor i32 %and1859, %or1774
  %add1861 = add i32 %or1680, %xor422
  %add1862 = add i32 %add1861, %xor1860
  %add1863 = add i32 %add1862, %or1846
  %or1867 = tail call i32 @llvm.fshl.i32(i32 %add1666, i32 %add1666, i32 9)
  %or1871 = tail call i32 @llvm.fshl.i32(i32 %xor1690, i32 %xor1690, i32 19)
  %or1875 = tail call i32 @llvm.fshl.i32(i32 %add1863, i32 %add1863, i32 9)
  %xor1876 = xor i32 %or1875, %add1863
  %or1880 = tail call i32 @llvm.fshl.i32(i32 %add1863, i32 %add1863, i32 17)
  %xor1881 = xor i32 %xor1876, %or1880
  %xor1884 = xor i32 %xor1080, %xor422
  %or1888 = tail call i32 @llvm.fshl.i32(i32 %xor1644, i32 %xor1644, i32 15)
  %xor1889 = xor i32 %xor1884, %or1888
  %or1905 = tail call i32 @llvm.fshl.i32(i32 %xor1889, i32 %xor1889, i32 15)
  %or1922 = tail call i32 @llvm.fshl.i32(i32 %xor1889, i32 %xor1889, i32 23)
  %or1927 = tail call i32 @llvm.fshl.i32(i32 %xor704, i32 %xor704, i32 7)
  %xor1906 = xor i32 %xor1362, %or1927
  %xor1923 = xor i32 %xor1906, %xor1889
  %xor1928 = xor i32 %xor1923, %or1905
  %xor1929 = xor i32 %xor1928, %or1922
  %or1935 = tail call i32 @llvm.fshl.i32(i32 %add1856, i32 %add1856, i32 12)
  %add1937 = add i32 %or1935, 991229199
  %add1938 = add i32 %add1937, %xor1881
  %or1943 = tail call i32 @llvm.fshl.i32(i32 %add1938, i32 %add1938, i32 7)
  %and1945 = and i32 %add1856, %add1760
  %or1946 = or i32 %add1856, %add1760
  %and1947 = and i32 %or1946, %or1867
  %or1948 = or i32 %and1947, %and1945
  %xor1950 = xor i32 %or1943, %or1935
  %xor1952 = xor i32 %xor892, %xor516
  %add1949 = add i32 %or1770, %xor1952
  %add1951 = add i32 %add1949, %or1948
  %add1953 = add i32 %add1951, %xor1950
  %xor1955 = xor i32 %xor1784, %or1871
  %and1956 = and i32 %xor1881, %xor1955
  %xor1957 = xor i32 %and1956, %or1871
  %add1958 = add i32 %or1774, %xor516
  %add1959 = add i32 %add1958, %xor1957
  %add1960 = add i32 %add1959, %or1943
  %or1964 = tail call i32 @llvm.fshl.i32(i32 %add1760, i32 %add1760, i32 9)
  %or1968 = tail call i32 @llvm.fshl.i32(i32 %xor1784, i32 %xor1784, i32 19)
  %or1972 = tail call i32 @llvm.fshl.i32(i32 %add1960, i32 %add1960, i32 9)
  %xor1973 = xor i32 %or1972, %add1960
  %or1977 = tail call i32 @llvm.fshl.i32(i32 %add1960, i32 %add1960, i32 17)
  %xor1978 = xor i32 %xor1973, %or1977
  %xor1981 = xor i32 %xor1174, %xor516
  %or1985 = tail call i32 @llvm.fshl.i32(i32 %xor1738, i32 %xor1738, i32 15)
  %xor1986 = xor i32 %xor1981, %or1985
  %or2002 = tail call i32 @llvm.fshl.i32(i32 %xor1986, i32 %xor1986, i32 15)
  %or2019 = tail call i32 @llvm.fshl.i32(i32 %xor1986, i32 %xor1986, i32 23)
  %or2024 = tail call i32 @llvm.fshl.i32(i32 %xor798, i32 %xor798, i32 7)
  %xor2003 = xor i32 %xor1456, %or2024
  %xor2020 = xor i32 %xor2003, %xor1986
  %xor2025 = xor i32 %xor2020, %or2002
  %xor2026 = xor i32 %xor2025, %or2019
  %or2032 = tail call i32 @llvm.fshl.i32(i32 %add1953, i32 %add1953, i32 12)
  %add2034 = add i32 %or2032, 1982458398
  %add2035 = add i32 %add2034, %xor1978
  %or2040 = tail call i32 @llvm.fshl.i32(i32 %add2035, i32 %add2035, i32 7)
  %and2042 = and i32 %add1953, %add1856
  %or2043 = or i32 %add1953, %add1856
  %and2044 = and i32 %or2043, %or1964
  %or2045 = or i32 %and2044, %and2042
  %xor2047 = xor i32 %or2040, %or2032
  %xor2049 = xor i32 %xor986, %xor610
  %add2046 = add i32 %or1867, %xor2049
  %add2048 = add i32 %add2046, %or2045
  %add2050 = add i32 %add2048, %xor2047
  %xor2052 = xor i32 %xor1881, %or1968
  %and2053 = and i32 %xor1978, %xor2052
  %xor2054 = xor i32 %and2053, %or1968
  %add2055 = add i32 %or1871, %xor610
  %add2056 = add i32 %add2055, %xor2054
  %add2057 = add i32 %add2056, %or2040
  %or2061 = tail call i32 @llvm.fshl.i32(i32 %add1856, i32 %add1856, i32 9)
  %or2065 = tail call i32 @llvm.fshl.i32(i32 %xor1881, i32 %xor1881, i32 19)
  %or2069 = tail call i32 @llvm.fshl.i32(i32 %add2057, i32 %add2057, i32 9)
  %xor2070 = xor i32 %or2069, %add2057
  %or2074 = tail call i32 @llvm.fshl.i32(i32 %add2057, i32 %add2057, i32 17)
  %xor2075 = xor i32 %xor2070, %or2074
  %xor2078 = xor i32 %xor1268, %xor610
  %or2082 = tail call i32 @llvm.fshl.i32(i32 %xor1832, i32 %xor1832, i32 15)
  %xor2083 = xor i32 %xor2078, %or2082
  %or2099 = tail call i32 @llvm.fshl.i32(i32 %xor2083, i32 %xor2083, i32 15)
  %or2116 = tail call i32 @llvm.fshl.i32(i32 %xor2083, i32 %xor2083, i32 23)
  %or2121 = tail call i32 @llvm.fshl.i32(i32 %xor892, i32 %xor892, i32 7)
  %xor2100 = xor i32 %xor1550, %or2121
  %xor2117 = xor i32 %xor2100, %xor2083
  %xor2122 = xor i32 %xor2117, %or2099
  %xor2123 = xor i32 %xor2122, %or2116
  %or2129 = tail call i32 @llvm.fshl.i32(i32 %add2050, i32 %add2050, i32 12)
  %add2131 = add i32 %or2129, -330050500
  %add2132 = add i32 %add2131, %xor2075
  %or2137 = tail call i32 @llvm.fshl.i32(i32 %add2132, i32 %add2132, i32 7)
  %and2139 = and i32 %add2050, %add1953
  %or2140 = or i32 %add2050, %add1953
  %and2141 = and i32 %or2140, %or2061
  %or2142 = or i32 %and2141, %and2139
  %xor2144 = xor i32 %or2137, %or2129
  %xor2146 = xor i32 %xor1080, %xor704
  %add2143 = add i32 %or1964, %xor2146
  %add2145 = add i32 %add2143, %or2142
  %add2147 = add i32 %add2145, %xor2144
  %xor2149 = xor i32 %xor1978, %or2065
  %and2150 = and i32 %xor2075, %xor2149
  %xor2151 = xor i32 %and2150, %or2065
  %add2152 = add i32 %or1968, %xor704
  %add2153 = add i32 %add2152, %xor2151
  %add2154 = add i32 %add2153, %or2137
  %or2158 = tail call i32 @llvm.fshl.i32(i32 %add1953, i32 %add1953, i32 9)
  %or2162 = tail call i32 @llvm.fshl.i32(i32 %xor1978, i32 %xor1978, i32 19)
  %or2166 = tail call i32 @llvm.fshl.i32(i32 %add2154, i32 %add2154, i32 9)
  %xor2167 = xor i32 %or2166, %add2154
  %or2171 = tail call i32 @llvm.fshl.i32(i32 %add2154, i32 %add2154, i32 17)
  %xor2172 = xor i32 %xor2167, %or2171
  %xor2175 = xor i32 %xor1362, %xor704
  %or2179 = tail call i32 @llvm.fshl.i32(i32 %xor1929, i32 %xor1929, i32 15)
  %xor2180 = xor i32 %xor2175, %or2179
  %or2196 = tail call i32 @llvm.fshl.i32(i32 %xor2180, i32 %xor2180, i32 15)
  %or2213 = tail call i32 @llvm.fshl.i32(i32 %xor2180, i32 %xor2180, i32 23)
  %or2218 = tail call i32 @llvm.fshl.i32(i32 %xor986, i32 %xor986, i32 7)
  %xor2197 = xor i32 %xor1644, %or2218
  %xor2214 = xor i32 %xor2197, %xor2180
  %xor2219 = xor i32 %xor2214, %or2196
  %xor2220 = xor i32 %xor2219, %or2213
  %or2226 = tail call i32 @llvm.fshl.i32(i32 %add2147, i32 %add2147, i32 12)
  %add2228 = add i32 %or2226, -660100999
  %add2229 = add i32 %add2228, %xor2172
  %or2234 = tail call i32 @llvm.fshl.i32(i32 %add2229, i32 %add2229, i32 7)
  %and2236 = and i32 %add2147, %add2050
  %or2237 = or i32 %add2147, %add2050
  %and2238 = and i32 %or2237, %or2158
  %or2239 = or i32 %and2238, %and2236
  %xor2241 = xor i32 %or2234, %or2226
  %xor2243 = xor i32 %xor1174, %xor798
  %add2240 = add i32 %or2061, %xor2243
  %add2242 = add i32 %add2240, %or2239
  %add2244 = add i32 %add2242, %xor2241
  %xor2246 = xor i32 %xor2075, %or2162
  %and2247 = and i32 %xor2172, %xor2246
  %xor2248 = xor i32 %and2247, %or2162
  %add2249 = add i32 %or2065, %xor798
  %add2250 = add i32 %add2249, %xor2248
  %add2251 = add i32 %add2250, %or2234
  %or2255 = tail call i32 @llvm.fshl.i32(i32 %add2050, i32 %add2050, i32 9)
  %or2259 = tail call i32 @llvm.fshl.i32(i32 %xor2075, i32 %xor2075, i32 19)
  %or2263 = tail call i32 @llvm.fshl.i32(i32 %add2251, i32 %add2251, i32 9)
  %xor2264 = xor i32 %or2263, %add2251
  %or2268 = tail call i32 @llvm.fshl.i32(i32 %add2251, i32 %add2251, i32 17)
  %xor2269 = xor i32 %xor2264, %or2268
  %xor2272 = xor i32 %xor1456, %xor798
  %or2276 = tail call i32 @llvm.fshl.i32(i32 %xor2026, i32 %xor2026, i32 15)
  %xor2277 = xor i32 %xor2272, %or2276
  %or2293 = tail call i32 @llvm.fshl.i32(i32 %xor2277, i32 %xor2277, i32 15)
  %or2310 = tail call i32 @llvm.fshl.i32(i32 %xor2277, i32 %xor2277, i32 23)
  %or2315 = tail call i32 @llvm.fshl.i32(i32 %xor1080, i32 %xor1080, i32 7)
  %xor2294 = xor i32 %xor1738, %or2315
  %xor2311 = xor i32 %xor2294, %xor2277
  %xor2316 = xor i32 %xor2311, %or2293
  %xor2317 = xor i32 %xor2316, %or2310
  %or2323 = tail call i32 @llvm.fshl.i32(i32 %add2244, i32 %add2244, i32 12)
  %add2325 = add i32 %or2323, -1320201997
  %add2326 = add i32 %add2325, %xor2269
  %or2331 = tail call i32 @llvm.fshl.i32(i32 %add2326, i32 %add2326, i32 7)
  %and2333 = and i32 %add2244, %add2147
  %or2334 = or i32 %add2244, %add2147
  %and2335 = and i32 %or2334, %or2255
  %or2336 = or i32 %and2335, %and2333
  %xor2338 = xor i32 %or2331, %or2323
  %xor2340 = xor i32 %xor1268, %xor892
  %add2337 = add i32 %or2158, %xor2340
  %add2339 = add i32 %add2337, %or2336
  %add2341 = add i32 %add2339, %xor2338
  %xor2343 = xor i32 %xor2172, %or2259
  %and2344 = and i32 %xor2269, %xor2343
  %xor2345 = xor i32 %and2344, %or2259
  %add2346 = add i32 %or2162, %xor892
  %add2347 = add i32 %add2346, %xor2345
  %add2348 = add i32 %add2347, %or2331
  %or2352 = tail call i32 @llvm.fshl.i32(i32 %add2147, i32 %add2147, i32 9)
  %or2356 = tail call i32 @llvm.fshl.i32(i32 %xor2172, i32 %xor2172, i32 19)
  %or2360 = tail call i32 @llvm.fshl.i32(i32 %add2348, i32 %add2348, i32 9)
  %xor2361 = xor i32 %or2360, %add2348
  %or2365 = tail call i32 @llvm.fshl.i32(i32 %add2348, i32 %add2348, i32 17)
  %xor2366 = xor i32 %xor2361, %or2365
  %xor2369 = xor i32 %xor1550, %xor892
  %or2373 = tail call i32 @llvm.fshl.i32(i32 %xor2123, i32 %xor2123, i32 15)
  %xor2374 = xor i32 %xor2369, %or2373
  %or2390 = tail call i32 @llvm.fshl.i32(i32 %xor2374, i32 %xor2374, i32 15)
  %or2407 = tail call i32 @llvm.fshl.i32(i32 %xor2374, i32 %xor2374, i32 23)
  %or2412 = tail call i32 @llvm.fshl.i32(i32 %xor1174, i32 %xor1174, i32 7)
  %xor2391 = xor i32 %xor1832, %or2412
  %xor2408 = xor i32 %xor2391, %xor2374
  %xor2413 = xor i32 %xor2408, %or2390
  %xor2414 = xor i32 %xor2413, %or2407
  %or2420 = tail call i32 @llvm.fshl.i32(i32 %add2341, i32 %add2341, i32 12)
  %add2422 = add i32 %or2420, 1654563303
  %add2423 = add i32 %add2422, %xor2366
  %or2428 = tail call i32 @llvm.fshl.i32(i32 %add2423, i32 %add2423, i32 7)
  %and2430 = and i32 %add2341, %add2244
  %or2431 = or i32 %add2341, %add2244
  %and2432 = and i32 %or2431, %or2352
  %or2433 = or i32 %and2432, %and2430
  %xor2435 = xor i32 %or2428, %or2420
  %xor2437 = xor i32 %xor1362, %xor986
  %add2434 = add i32 %or2255, %xor2437
  %add2436 = add i32 %add2434, %or2433
  %add2438 = add i32 %add2436, %xor2435
  %xor2440 = xor i32 %xor2269, %or2356
  %and2441 = and i32 %xor2366, %xor2440
  %xor2442 = xor i32 %and2441, %or2356
  %add2443 = add i32 %or2259, %xor986
  %add2444 = add i32 %add2443, %xor2442
  %add2445 = add i32 %add2444, %or2428
  %or2449 = tail call i32 @llvm.fshl.i32(i32 %add2244, i32 %add2244, i32 9)
  %or2453 = tail call i32 @llvm.fshl.i32(i32 %xor2269, i32 %xor2269, i32 19)
  %or2457 = tail call i32 @llvm.fshl.i32(i32 %add2445, i32 %add2445, i32 9)
  %xor2458 = xor i32 %or2457, %add2445
  %or2462 = tail call i32 @llvm.fshl.i32(i32 %add2445, i32 %add2445, i32 17)
  %xor2463 = xor i32 %xor2458, %or2462
  %xor2466 = xor i32 %xor1644, %xor986
  %or2470 = tail call i32 @llvm.fshl.i32(i32 %xor2220, i32 %xor2220, i32 15)
  %xor2471 = xor i32 %xor2466, %or2470
  %or2487 = tail call i32 @llvm.fshl.i32(i32 %xor2471, i32 %xor2471, i32 15)
  %or2504 = tail call i32 @llvm.fshl.i32(i32 %xor2471, i32 %xor2471, i32 23)
  %or2509 = tail call i32 @llvm.fshl.i32(i32 %xor1268, i32 %xor1268, i32 7)
  %xor2488 = xor i32 %xor1929, %or2509
  %xor2505 = xor i32 %xor2488, %xor2471
  %xor2510 = xor i32 %xor2505, %or2487
  %xor2511 = xor i32 %xor2510, %or2504
  %or2517 = tail call i32 @llvm.fshl.i32(i32 %add2438, i32 %add2438, i32 12)
  %add2519 = add i32 %or2517, -985840690
  %add2520 = add i32 %add2519, %xor2463
  %or2525 = tail call i32 @llvm.fshl.i32(i32 %add2520, i32 %add2520, i32 7)
  %and2527 = and i32 %add2438, %add2341
  %or2528 = or i32 %add2438, %add2341
  %and2529 = and i32 %or2528, %or2449
  %or2530 = or i32 %and2529, %and2527
  %xor2532 = xor i32 %or2525, %or2517
  %xor2534 = xor i32 %xor1456, %xor1080
  %add2531 = add i32 %or2352, %xor2534
  %add2533 = add i32 %add2531, %or2530
  %add2535 = add i32 %add2533, %xor2532
  %xor2537 = xor i32 %xor2366, %or2453
  %and2538 = and i32 %xor2463, %xor2537
  %xor2539 = xor i32 %and2538, %or2453
  %add2540 = add i32 %or2356, %xor1080
  %add2541 = add i32 %add2540, %xor2539
  %add2542 = add i32 %add2541, %or2525
  %or2546 = tail call i32 @llvm.fshl.i32(i32 %add2341, i32 %add2341, i32 9)
  %or2550 = tail call i32 @llvm.fshl.i32(i32 %xor2366, i32 %xor2366, i32 19)
  %or2554 = tail call i32 @llvm.fshl.i32(i32 %add2542, i32 %add2542, i32 9)
  %xor2555 = xor i32 %or2554, %add2542
  %or2559 = tail call i32 @llvm.fshl.i32(i32 %add2542, i32 %add2542, i32 17)
  %xor2560 = xor i32 %xor2555, %or2559
  %xor2563 = xor i32 %xor1738, %xor1080
  %or2567 = tail call i32 @llvm.fshl.i32(i32 %xor2317, i32 %xor2317, i32 15)
  %xor2568 = xor i32 %xor2563, %or2567
  %or2584 = tail call i32 @llvm.fshl.i32(i32 %xor2568, i32 %xor2568, i32 15)
  %or2601 = tail call i32 @llvm.fshl.i32(i32 %xor2568, i32 %xor2568, i32 23)
  %or2606 = tail call i32 @llvm.fshl.i32(i32 %xor1362, i32 %xor1362, i32 7)
  %xor2585 = xor i32 %xor2026, %or2606
  %xor2602 = xor i32 %xor2585, %xor2568
  %xor2607 = xor i32 %xor2602, %or2584
  %xor2608 = xor i32 %xor2607, %or2601
  %or2614 = tail call i32 @llvm.fshl.i32(i32 %add2535, i32 %add2535, i32 12)
  %add2616 = add i32 %or2614, -1971681379
  %add2617 = add i32 %add2616, %xor2560
  %or2622 = tail call i32 @llvm.fshl.i32(i32 %add2617, i32 %add2617, i32 7)
  %and2624 = and i32 %add2535, %add2438
  %or2625 = or i32 %add2535, %add2438
  %and2626 = and i32 %or2625, %or2546
  %or2627 = or i32 %and2626, %and2624
  %xor2629 = xor i32 %or2622, %or2614
  %xor2631 = xor i32 %xor1550, %xor1174
  %add2628 = add i32 %or2449, %xor2631
  %add2630 = add i32 %add2628, %or2627
  %add2632 = add i32 %add2630, %xor2629
  %xor2634 = xor i32 %xor2463, %or2550
  %and2635 = and i32 %xor2560, %xor2634
  %xor2636 = xor i32 %and2635, %or2550
  %add2637 = add i32 %or2453, %xor1174
  %add2638 = add i32 %add2637, %xor2636
  %add2639 = add i32 %add2638, %or2622
  %or2643 = tail call i32 @llvm.fshl.i32(i32 %add2438, i32 %add2438, i32 9)
  %or2647 = tail call i32 @llvm.fshl.i32(i32 %xor2463, i32 %xor2463, i32 19)
  %or2651 = tail call i32 @llvm.fshl.i32(i32 %add2639, i32 %add2639, i32 9)
  %xor2652 = xor i32 %or2651, %add2639
  %or2656 = tail call i32 @llvm.fshl.i32(i32 %add2639, i32 %add2639, i32 17)
  %xor2657 = xor i32 %xor2652, %or2656
  %xor2660 = xor i32 %xor1832, %xor1174
  %or2664 = tail call i32 @llvm.fshl.i32(i32 %xor2414, i32 %xor2414, i32 15)
  %xor2665 = xor i32 %xor2660, %or2664
  %or2681 = tail call i32 @llvm.fshl.i32(i32 %xor2665, i32 %xor2665, i32 15)
  %or2698 = tail call i32 @llvm.fshl.i32(i32 %xor2665, i32 %xor2665, i32 23)
  %or2703 = tail call i32 @llvm.fshl.i32(i32 %xor1456, i32 %xor1456, i32 7)
  %xor2682 = xor i32 %xor2123, %or2703
  %xor2699 = xor i32 %xor2682, %xor2665
  %xor2704 = xor i32 %xor2699, %or2681
  %xor2705 = xor i32 %xor2704, %or2698
  %or2711 = tail call i32 @llvm.fshl.i32(i32 %add2632, i32 %add2632, i32 12)
  %add2713 = add i32 %or2711, 351604539
  %add2714 = add i32 %add2713, %xor2657
  %or2719 = tail call i32 @llvm.fshl.i32(i32 %add2714, i32 %add2714, i32 7)
  %and2721 = and i32 %add2632, %add2535
  %or2722 = or i32 %add2632, %add2535
  %and2723 = and i32 %or2722, %or2643
  %or2724 = or i32 %and2723, %and2721
  %xor2726 = xor i32 %or2719, %or2711
  %xor2728 = xor i32 %xor1644, %xor1268
  %add2725 = add i32 %or2546, %xor2728
  %add2727 = add i32 %add2725, %or2724
  %add2729 = add i32 %add2727, %xor2726
  %xor2731 = xor i32 %xor2560, %or2647
  %and2732 = and i32 %xor2657, %xor2731
  %xor2733 = xor i32 %and2732, %or2647
  %add2734 = add i32 %or2550, %xor1268
  %add2735 = add i32 %add2734, %xor2733
  %add2736 = add i32 %add2735, %or2719
  %or2740 = tail call i32 @llvm.fshl.i32(i32 %add2535, i32 %add2535, i32 9)
  %or2744 = tail call i32 @llvm.fshl.i32(i32 %xor2560, i32 %xor2560, i32 19)
  %or2748 = tail call i32 @llvm.fshl.i32(i32 %add2736, i32 %add2736, i32 9)
  %xor2749 = xor i32 %or2748, %add2736
  %or2753 = tail call i32 @llvm.fshl.i32(i32 %add2736, i32 %add2736, i32 17)
  %xor2754 = xor i32 %xor2749, %or2753
  %xor2757 = xor i32 %xor1929, %xor1268
  %or2761 = tail call i32 @llvm.fshl.i32(i32 %xor2511, i32 %xor2511, i32 15)
  %xor2762 = xor i32 %xor2757, %or2761
  %or2778 = tail call i32 @llvm.fshl.i32(i32 %xor2762, i32 %xor2762, i32 15)
  %or2795 = tail call i32 @llvm.fshl.i32(i32 %xor2762, i32 %xor2762, i32 23)
  %or2800 = tail call i32 @llvm.fshl.i32(i32 %xor1550, i32 %xor1550, i32 7)
  %xor2779 = xor i32 %xor2220, %or2800
  %xor2796 = xor i32 %xor2779, %xor2762
  %xor2801 = xor i32 %xor2796, %or2778
  %xor2802 = xor i32 %xor2801, %or2795
  %or2808 = tail call i32 @llvm.fshl.i32(i32 %add2729, i32 %add2729, i32 12)
  %add2810 = add i32 %or2808, 703209078
  %add2811 = add i32 %add2810, %xor2754
  %or2816 = tail call i32 @llvm.fshl.i32(i32 %add2811, i32 %add2811, i32 7)
  %and2818 = and i32 %add2729, %add2632
  %or2819 = or i32 %add2729, %add2632
  %and2820 = and i32 %or2819, %or2740
  %or2821 = or i32 %and2820, %and2818
  %xor2823 = xor i32 %or2816, %or2808
  %xor2825 = xor i32 %xor1738, %xor1362
  %add2822 = add i32 %or2643, %xor2825
  %add2824 = add i32 %add2822, %or2821
  %add2826 = add i32 %add2824, %xor2823
  %xor2828 = xor i32 %xor2657, %or2744
  %and2829 = and i32 %xor2754, %xor2828
  %xor2830 = xor i32 %and2829, %or2744
  %add2831 = add i32 %or2647, %xor1362
  %add2832 = add i32 %add2831, %xor2830
  %add2833 = add i32 %add2832, %or2816
  %or2837 = tail call i32 @llvm.fshl.i32(i32 %add2632, i32 %add2632, i32 9)
  %or2841 = tail call i32 @llvm.fshl.i32(i32 %xor2657, i32 %xor2657, i32 19)
  %or2845 = tail call i32 @llvm.fshl.i32(i32 %add2833, i32 %add2833, i32 9)
  %xor2846 = xor i32 %or2845, %add2833
  %or2850 = tail call i32 @llvm.fshl.i32(i32 %add2833, i32 %add2833, i32 17)
  %xor2851 = xor i32 %xor2846, %or2850
  %xor2854 = xor i32 %xor2026, %xor1362
  %or2858 = tail call i32 @llvm.fshl.i32(i32 %xor2608, i32 %xor2608, i32 15)
  %xor2859 = xor i32 %xor2854, %or2858
  %or2875 = tail call i32 @llvm.fshl.i32(i32 %xor2859, i32 %xor2859, i32 15)
  %or2892 = tail call i32 @llvm.fshl.i32(i32 %xor2859, i32 %xor2859, i32 23)
  %or2897 = tail call i32 @llvm.fshl.i32(i32 %xor1644, i32 %xor1644, i32 7)
  %xor2876 = xor i32 %xor2317, %or2897
  %xor2893 = xor i32 %xor2876, %xor2859
  %xor2898 = xor i32 %xor2893, %or2875
  %xor2899 = xor i32 %xor2898, %or2892
  %or2905 = tail call i32 @llvm.fshl.i32(i32 %add2826, i32 %add2826, i32 12)
  %add2907 = add i32 %or2905, 1406418156
  %add2908 = add i32 %add2907, %xor2851
  %or2913 = tail call i32 @llvm.fshl.i32(i32 %add2908, i32 %add2908, i32 7)
  %and2915 = and i32 %add2826, %add2729
  %or2916 = or i32 %add2826, %add2729
  %and2917 = and i32 %or2916, %or2837
  %or2918 = or i32 %and2917, %and2915
  %xor2920 = xor i32 %or2913, %or2905
  %xor2922 = xor i32 %xor1832, %xor1456
  %add2919 = add i32 %or2740, %xor2922
  %add2921 = add i32 %add2919, %or2918
  %add2923 = add i32 %add2921, %xor2920
  %xor2925 = xor i32 %xor2754, %or2841
  %and2926 = and i32 %xor2851, %xor2925
  %xor2927 = xor i32 %and2926, %or2841
  %add2928 = add i32 %or2744, %xor1456
  %add2929 = add i32 %add2928, %xor2927
  %add2930 = add i32 %add2929, %or2913
  %or2934 = tail call i32 @llvm.fshl.i32(i32 %add2729, i32 %add2729, i32 9)
  %or2938 = tail call i32 @llvm.fshl.i32(i32 %xor2754, i32 %xor2754, i32 19)
  %or2942 = tail call i32 @llvm.fshl.i32(i32 %add2930, i32 %add2930, i32 9)
  %xor2943 = xor i32 %or2942, %add2930
  %or2947 = tail call i32 @llvm.fshl.i32(i32 %add2930, i32 %add2930, i32 17)
  %xor2948 = xor i32 %xor2943, %or2947
  %xor2951 = xor i32 %xor2123, %xor1456
  %or2955 = tail call i32 @llvm.fshl.i32(i32 %xor2705, i32 %xor2705, i32 15)
  %xor2956 = xor i32 %xor2951, %or2955
  %or2972 = tail call i32 @llvm.fshl.i32(i32 %xor2956, i32 %xor2956, i32 15)
  %or2989 = tail call i32 @llvm.fshl.i32(i32 %xor2956, i32 %xor2956, i32 23)
  %or2994 = tail call i32 @llvm.fshl.i32(i32 %xor1738, i32 %xor1738, i32 7)
  %xor2973 = xor i32 %xor2414, %or2994
  %xor2990 = xor i32 %xor2973, %xor2956
  %xor2995 = xor i32 %xor2990, %or2972
  %xor2996 = xor i32 %xor2995, %or2989
  %or3002 = tail call i32 @llvm.fshl.i32(i32 %add2923, i32 %add2923, i32 12)
  %add3004 = add i32 %or3002, -1482130984
  %add3005 = add i32 %add3004, %xor2948
  %or3010 = tail call i32 @llvm.fshl.i32(i32 %add3005, i32 %add3005, i32 7)
  %and3012 = and i32 %add2923, %add2826
  %or3013 = or i32 %add2923, %add2826
  %and3014 = and i32 %or3013, %or2934
  %or3015 = or i32 %and3014, %and3012
  %xor3017 = xor i32 %or3010, %or3002
  %xor3019 = xor i32 %xor1929, %xor1550
  %add3016 = add i32 %or2837, %xor3019
  %add3018 = add i32 %add3016, %or3015
  %add3020 = add i32 %add3018, %xor3017
  %xor3022 = xor i32 %xor2851, %or2938
  %and3023 = and i32 %xor2948, %xor3022
  %xor3024 = xor i32 %and3023, %or2938
  %add3025 = add i32 %or2841, %xor1550
  %add3026 = add i32 %add3025, %xor3024
  %add3027 = add i32 %add3026, %or3010
  %or3031 = tail call i32 @llvm.fshl.i32(i32 %add2826, i32 %add2826, i32 9)
  %or3035 = tail call i32 @llvm.fshl.i32(i32 %xor2851, i32 %xor2851, i32 19)
  %or3039 = tail call i32 @llvm.fshl.i32(i32 %add3027, i32 %add3027, i32 9)
  %xor3040 = xor i32 %or3039, %add3027
  %or3044 = tail call i32 @llvm.fshl.i32(i32 %add3027, i32 %add3027, i32 17)
  %xor3045 = xor i32 %xor3040, %or3044
  %xor3048 = xor i32 %xor2220, %xor1550
  %or3052 = tail call i32 @llvm.fshl.i32(i32 %xor2802, i32 %xor2802, i32 15)
  %xor3053 = xor i32 %xor3048, %or3052
  %or3069 = tail call i32 @llvm.fshl.i32(i32 %xor3053, i32 %xor3053, i32 15)
  %or3086 = tail call i32 @llvm.fshl.i32(i32 %xor3053, i32 %xor3053, i32 23)
  %or3091 = tail call i32 @llvm.fshl.i32(i32 %xor1832, i32 %xor1832, i32 7)
  %xor3070 = xor i32 %xor2511, %or3091
  %xor3087 = xor i32 %xor3070, %xor3053
  %xor3092 = xor i32 %xor3087, %or3069
  %xor3093 = xor i32 %xor3092, %or3086
  %or3099 = tail call i32 @llvm.fshl.i32(i32 %add3020, i32 %add3020, i32 12)
  %add3101 = add i32 %or3099, 1330705329
  %add3102 = add i32 %add3101, %xor3045
  %or3107 = tail call i32 @llvm.fshl.i32(i32 %add3102, i32 %add3102, i32 7)
  %and3109 = and i32 %add3020, %add2923
  %or3110 = or i32 %add3020, %add2923
  %and3111 = and i32 %or3110, %or3031
  %or3112 = or i32 %and3111, %and3109
  %xor3114 = xor i32 %or3107, %or3099
  %xor3116 = xor i32 %xor2026, %xor1644
  %add3113 = add i32 %or2934, %xor3116
  %add3115 = add i32 %add3113, %or3112
  %add3117 = add i32 %add3115, %xor3114
  %xor3119 = xor i32 %xor2948, %or3035
  %and3120 = and i32 %xor3045, %xor3119
  %xor3121 = xor i32 %and3120, %or3035
  %add3122 = add i32 %or2938, %xor1644
  %add3123 = add i32 %add3122, %xor3121
  %add3124 = add i32 %add3123, %or3107
  %or3128 = tail call i32 @llvm.fshl.i32(i32 %add2923, i32 %add2923, i32 9)
  %or3132 = tail call i32 @llvm.fshl.i32(i32 %xor2948, i32 %xor2948, i32 19)
  %or3136 = tail call i32 @llvm.fshl.i32(i32 %add3124, i32 %add3124, i32 9)
  %xor3137 = xor i32 %or3136, %add3124
  %or3141 = tail call i32 @llvm.fshl.i32(i32 %add3124, i32 %add3124, i32 17)
  %xor3142 = xor i32 %xor3137, %or3141
  %xor3145 = xor i32 %xor2317, %xor1644
  %or3149 = tail call i32 @llvm.fshl.i32(i32 %xor2899, i32 %xor2899, i32 15)
  %xor3150 = xor i32 %xor3145, %or3149
  %or3166 = tail call i32 @llvm.fshl.i32(i32 %xor3150, i32 %xor3150, i32 15)
  %or3183 = tail call i32 @llvm.fshl.i32(i32 %xor3150, i32 %xor3150, i32 23)
  %or3188 = tail call i32 @llvm.fshl.i32(i32 %xor1929, i32 %xor1929, i32 7)
  %xor3167 = xor i32 %xor2608, %or3188
  %xor3184 = xor i32 %xor3167, %xor3150
  %xor3189 = xor i32 %xor3184, %or3166
  %xor3190 = xor i32 %xor3189, %or3183
  %or3196 = tail call i32 @llvm.fshl.i32(i32 %add3117, i32 %add3117, i32 12)
  %add3198 = add i32 %or3196, -1633556638
  %add3199 = add i32 %add3198, %xor3142
  %or3204 = tail call i32 @llvm.fshl.i32(i32 %add3199, i32 %add3199, i32 7)
  %and3206 = and i32 %add3117, %add3020
  %or3207 = or i32 %add3117, %add3020
  %and3208 = and i32 %or3207, %or3128
  %or3209 = or i32 %and3208, %and3206
  %xor3211 = xor i32 %or3204, %or3196
  %xor3213 = xor i32 %xor2123, %xor1738
  %add3210 = add i32 %or3031, %xor3213
  %add3212 = add i32 %add3210, %or3209
  %add3214 = add i32 %add3212, %xor3211
  %xor3216 = xor i32 %xor3045, %or3132
  %and3217 = and i32 %xor3142, %xor3216
  %xor3218 = xor i32 %and3217, %or3132
  %add3219 = add i32 %or3035, %xor1738
  %add3220 = add i32 %add3219, %xor3218
  %add3221 = add i32 %add3220, %or3204
  %or3225 = tail call i32 @llvm.fshl.i32(i32 %add3020, i32 %add3020, i32 9)
  %or3229 = tail call i32 @llvm.fshl.i32(i32 %xor3045, i32 %xor3045, i32 19)
  %or3233 = tail call i32 @llvm.fshl.i32(i32 %add3221, i32 %add3221, i32 9)
  %xor3234 = xor i32 %or3233, %add3221
  %or3238 = tail call i32 @llvm.fshl.i32(i32 %add3221, i32 %add3221, i32 17)
  %xor3239 = xor i32 %xor3234, %or3238
  %xor3242 = xor i32 %xor2414, %xor1738
  %or3246 = tail call i32 @llvm.fshl.i32(i32 %xor2996, i32 %xor2996, i32 15)
  %xor3247 = xor i32 %xor3242, %or3246
  %or3263 = tail call i32 @llvm.fshl.i32(i32 %xor3247, i32 %xor3247, i32 15)
  %or3280 = tail call i32 @llvm.fshl.i32(i32 %xor3247, i32 %xor3247, i32 23)
  %or3285 = tail call i32 @llvm.fshl.i32(i32 %xor2026, i32 %xor2026, i32 7)
  %xor3264 = xor i32 %xor2705, %or3285
  %xor3281 = xor i32 %xor3264, %xor3247
  %xor3286 = xor i32 %xor3281, %or3263
  %xor3287 = xor i32 %xor3286, %or3280
  %or3293 = tail call i32 @llvm.fshl.i32(i32 %add3214, i32 %add3214, i32 12)
  %add3295 = add i32 %or3293, 1027854021
  %add3296 = add i32 %add3295, %xor3239
  %or3301 = tail call i32 @llvm.fshl.i32(i32 %add3296, i32 %add3296, i32 7)
  %and3303 = and i32 %add3214, %add3117
  %or3304 = or i32 %add3214, %add3117
  %and3305 = and i32 %or3304, %or3225
  %or3306 = or i32 %and3305, %and3303
  %xor3308 = xor i32 %or3301, %or3293
  %xor3310 = xor i32 %xor2220, %xor1832
  %add3307 = add i32 %or3128, %xor3310
  %add3309 = add i32 %add3307, %or3306
  %add3311 = add i32 %add3309, %xor3308
  %xor3313 = xor i32 %xor3142, %or3229
  %and3314 = and i32 %xor3239, %xor3313
  %xor3315 = xor i32 %and3314, %or3229
  %add3316 = add i32 %or3132, %xor1832
  %add3317 = add i32 %add3316, %xor3315
  %add3318 = add i32 %add3317, %or3301
  %or3322 = tail call i32 @llvm.fshl.i32(i32 %add3117, i32 %add3117, i32 9)
  %or3326 = tail call i32 @llvm.fshl.i32(i32 %xor3142, i32 %xor3142, i32 19)
  %or3330 = tail call i32 @llvm.fshl.i32(i32 %add3318, i32 %add3318, i32 9)
  %xor3331 = xor i32 %or3330, %add3318
  %or3335 = tail call i32 @llvm.fshl.i32(i32 %add3318, i32 %add3318, i32 17)
  %xor3336 = xor i32 %xor3331, %or3335
  %xor3339 = xor i32 %xor2511, %xor1832
  %or3343 = tail call i32 @llvm.fshl.i32(i32 %xor3093, i32 %xor3093, i32 15)
  %xor3344 = xor i32 %xor3339, %or3343
  %or3360 = tail call i32 @llvm.fshl.i32(i32 %xor3344, i32 %xor3344, i32 15)
  %or3377 = tail call i32 @llvm.fshl.i32(i32 %xor3344, i32 %xor3344, i32 23)
  %or3382 = tail call i32 @llvm.fshl.i32(i32 %xor2123, i32 %xor2123, i32 7)
  %xor3361 = xor i32 %xor2802, %or3382
  %xor3378 = xor i32 %xor3361, %xor3344
  %xor3383 = xor i32 %xor3378, %or3360
  %xor3384 = xor i32 %xor3383, %or3377
  %or3390 = tail call i32 @llvm.fshl.i32(i32 %add3311, i32 %add3311, i32 12)
  %add3392 = add i32 %or3390, 2055708042
  %add3393 = add i32 %add3392, %xor3336
  %or3398 = tail call i32 @llvm.fshl.i32(i32 %add3393, i32 %add3393, i32 7)
  %and3400 = and i32 %add3311, %add3214
  %or3401 = or i32 %add3311, %add3214
  %and3402 = and i32 %or3401, %or3322
  %or3403 = or i32 %and3402, %and3400
  %xor3405 = xor i32 %or3398, %or3390
  %xor3407 = xor i32 %xor2317, %xor1929
  %add3404 = add i32 %or3225, %xor3407
  %add3406 = add i32 %add3404, %or3403
  %add3408 = add i32 %add3406, %xor3405
  %xor3410 = xor i32 %xor3239, %or3326
  %and3411 = and i32 %xor3336, %xor3410
  %xor3412 = xor i32 %and3411, %or3326
  %add3413 = add i32 %or3229, %xor1929
  %add3414 = add i32 %add3413, %xor3412
  %add3415 = add i32 %add3414, %or3398
  %or3419 = tail call i32 @llvm.fshl.i32(i32 %add3214, i32 %add3214, i32 9)
  %or3423 = tail call i32 @llvm.fshl.i32(i32 %xor3239, i32 %xor3239, i32 19)
  %or3427 = tail call i32 @llvm.fshl.i32(i32 %add3415, i32 %add3415, i32 9)
  %xor3428 = xor i32 %or3427, %add3415
  %or3432 = tail call i32 @llvm.fshl.i32(i32 %add3415, i32 %add3415, i32 17)
  %xor3433 = xor i32 %xor3428, %or3432
  %xor3436 = xor i32 %xor2608, %xor1929
  %or3440 = tail call i32 @llvm.fshl.i32(i32 %xor3190, i32 %xor3190, i32 15)
  %xor3441 = xor i32 %xor3436, %or3440
  %or3457 = tail call i32 @llvm.fshl.i32(i32 %xor3441, i32 %xor3441, i32 15)
  %or3474 = tail call i32 @llvm.fshl.i32(i32 %xor3441, i32 %xor3441, i32 23)
  %or3479 = tail call i32 @llvm.fshl.i32(i32 %xor2220, i32 %xor2220, i32 7)
  %xor3458 = xor i32 %xor2899, %or3479
  %xor3475 = xor i32 %xor3458, %xor3441
  %xor3480 = xor i32 %xor3475, %or3457
  %xor3481 = xor i32 %xor3480, %or3474
  %or3487 = tail call i32 @llvm.fshl.i32(i32 %add3408, i32 %add3408, i32 12)
  %add3489 = add i32 %or3487, -183551212
  %add3490 = add i32 %add3489, %xor3433
  %or3495 = tail call i32 @llvm.fshl.i32(i32 %add3490, i32 %add3490, i32 7)
  %and3497 = and i32 %add3408, %add3311
  %or3498 = or i32 %add3408, %add3311
  %and3499 = and i32 %or3498, %or3419
  %or3500 = or i32 %and3499, %and3497
  %xor3502 = xor i32 %or3495, %or3487
  %xor3504 = xor i32 %xor2414, %xor2026
  %add3501 = add i32 %or3322, %xor3504
  %add3503 = add i32 %add3501, %or3500
  %add3505 = add i32 %add3503, %xor3502
  %xor3507 = xor i32 %xor3336, %or3423
  %and3508 = and i32 %xor3433, %xor3507
  %xor3509 = xor i32 %and3508, %or3423
  %add3510 = add i32 %or3326, %xor2026
  %add3511 = add i32 %add3510, %xor3509
  %add3512 = add i32 %add3511, %or3495
  %or3516 = tail call i32 @llvm.fshl.i32(i32 %add3311, i32 %add3311, i32 9)
  %or3520 = tail call i32 @llvm.fshl.i32(i32 %xor3336, i32 %xor3336, i32 19)
  %or3524 = tail call i32 @llvm.fshl.i32(i32 %add3512, i32 %add3512, i32 9)
  %xor3525 = xor i32 %or3524, %add3512
  %or3529 = tail call i32 @llvm.fshl.i32(i32 %add3512, i32 %add3512, i32 17)
  %xor3530 = xor i32 %xor3525, %or3529
  %xor3533 = xor i32 %xor2705, %xor2026
  %or3537 = tail call i32 @llvm.fshl.i32(i32 %xor3287, i32 %xor3287, i32 15)
  %xor3538 = xor i32 %xor3533, %or3537
  %or3554 = tail call i32 @llvm.fshl.i32(i32 %xor3538, i32 %xor3538, i32 15)
  %or3571 = tail call i32 @llvm.fshl.i32(i32 %xor3538, i32 %xor3538, i32 23)
  %or3576 = tail call i32 @llvm.fshl.i32(i32 %xor2317, i32 %xor2317, i32 7)
  %xor3555 = xor i32 %xor2996, %or3576
  %xor3572 = xor i32 %xor3555, %xor3538
  %xor3577 = xor i32 %xor3572, %or3554
  %xor3578 = xor i32 %xor3577, %or3571
  %or3584 = tail call i32 @llvm.fshl.i32(i32 %add3505, i32 %add3505, i32 12)
  %add3586 = add i32 %or3584, -367102423
  %add3587 = add i32 %add3586, %xor3530
  %or3592 = tail call i32 @llvm.fshl.i32(i32 %add3587, i32 %add3587, i32 7)
  %and3594 = and i32 %add3505, %add3408
  %or3595 = or i32 %add3505, %add3408
  %and3596 = and i32 %or3595, %or3516
  %or3597 = or i32 %and3596, %and3594
  %xor3599 = xor i32 %or3592, %or3584
  %xor3601 = xor i32 %xor2511, %xor2123
  %add3598 = add i32 %or3419, %xor3601
  %add3600 = add i32 %add3598, %or3597
  %add3602 = add i32 %add3600, %xor3599
  %xor3604 = xor i32 %xor3433, %or3520
  %and3605 = and i32 %xor3530, %xor3604
  %xor3606 = xor i32 %and3605, %or3520
  %add3607 = add i32 %or3423, %xor2123
  %add3608 = add i32 %add3607, %xor3606
  %add3609 = add i32 %add3608, %or3592
  %or3613 = tail call i32 @llvm.fshl.i32(i32 %add3408, i32 %add3408, i32 9)
  %or3617 = tail call i32 @llvm.fshl.i32(i32 %xor3433, i32 %xor3433, i32 19)
  %or3621 = tail call i32 @llvm.fshl.i32(i32 %add3609, i32 %add3609, i32 9)
  %xor3622 = xor i32 %or3621, %add3609
  %or3626 = tail call i32 @llvm.fshl.i32(i32 %add3609, i32 %add3609, i32 17)
  %xor3627 = xor i32 %xor3622, %or3626
  %xor3630 = xor i32 %xor2802, %xor2123
  %or3634 = tail call i32 @llvm.fshl.i32(i32 %xor3384, i32 %xor3384, i32 15)
  %xor3635 = xor i32 %xor3630, %or3634
  %or3651 = tail call i32 @llvm.fshl.i32(i32 %xor3635, i32 %xor3635, i32 15)
  %or3668 = tail call i32 @llvm.fshl.i32(i32 %xor3635, i32 %xor3635, i32 23)
  %or3673 = tail call i32 @llvm.fshl.i32(i32 %xor2414, i32 %xor2414, i32 7)
  %xor3652 = xor i32 %xor3093, %or3673
  %xor3669 = xor i32 %xor3652, %xor3635
  %xor3674 = xor i32 %xor3669, %or3651
  %xor3675 = xor i32 %xor3674, %or3668
  %or3681 = tail call i32 @llvm.fshl.i32(i32 %add3602, i32 %add3602, i32 12)
  %add3683 = add i32 %or3681, -734204845
  %add3684 = add i32 %add3683, %xor3627
  %or3689 = tail call i32 @llvm.fshl.i32(i32 %add3684, i32 %add3684, i32 7)
  %and3691 = and i32 %add3602, %add3505
  %or3692 = or i32 %add3602, %add3505
  %and3693 = and i32 %or3692, %or3613
  %or3694 = or i32 %and3693, %and3691
  %xor3696 = xor i32 %or3689, %or3681
  %xor3698 = xor i32 %xor2608, %xor2220
  %add3695 = add i32 %or3516, %xor3698
  %add3697 = add i32 %add3695, %or3694
  %add3699 = add i32 %add3697, %xor3696
  %xor3701 = xor i32 %xor3530, %or3617
  %and3702 = and i32 %xor3627, %xor3701
  %xor3703 = xor i32 %and3702, %or3617
  %add3704 = add i32 %or3520, %xor2220
  %add3705 = add i32 %add3704, %xor3703
  %add3706 = add i32 %add3705, %or3689
  %or3710 = tail call i32 @llvm.fshl.i32(i32 %add3505, i32 %add3505, i32 9)
  %or3714 = tail call i32 @llvm.fshl.i32(i32 %xor3530, i32 %xor3530, i32 19)
  %or3718 = tail call i32 @llvm.fshl.i32(i32 %add3706, i32 %add3706, i32 9)
  %xor3719 = xor i32 %or3718, %add3706
  %or3723 = tail call i32 @llvm.fshl.i32(i32 %add3706, i32 %add3706, i32 17)
  %xor3724 = xor i32 %xor3719, %or3723
  %xor3727 = xor i32 %xor2899, %xor2220
  %or3731 = tail call i32 @llvm.fshl.i32(i32 %xor3481, i32 %xor3481, i32 15)
  %xor3732 = xor i32 %xor3727, %or3731
  %or3748 = tail call i32 @llvm.fshl.i32(i32 %xor3732, i32 %xor3732, i32 15)
  %or3765 = tail call i32 @llvm.fshl.i32(i32 %xor3732, i32 %xor3732, i32 23)
  %or3770 = tail call i32 @llvm.fshl.i32(i32 %xor2511, i32 %xor2511, i32 7)
  %xor3749 = xor i32 %xor3190, %or3770
  %xor3766 = xor i32 %xor3749, %xor3732
  %xor3771 = xor i32 %xor3766, %or3748
  %xor3772 = xor i32 %xor3771, %or3765
  %or3778 = tail call i32 @llvm.fshl.i32(i32 %add3699, i32 %add3699, i32 12)
  %add3780 = add i32 %or3778, -1468409689
  %add3781 = add i32 %add3780, %xor3724
  %or3786 = tail call i32 @llvm.fshl.i32(i32 %add3781, i32 %add3781, i32 7)
  %and3788 = and i32 %add3699, %add3602
  %or3789 = or i32 %add3699, %add3602
  %and3790 = and i32 %or3789, %or3710
  %or3791 = or i32 %and3790, %and3788
  %xor3793 = xor i32 %or3786, %or3778
  %xor3795 = xor i32 %xor2705, %xor2317
  %add3792 = add i32 %or3613, %xor3795
  %add3794 = add i32 %add3792, %or3791
  %add3796 = add i32 %add3794, %xor3793
  %xor3798 = xor i32 %xor3627, %or3714
  %and3799 = and i32 %xor3724, %xor3798
  %xor3800 = xor i32 %and3799, %or3714
  %add3801 = add i32 %or3617, %xor2317
  %add3802 = add i32 %add3801, %xor3800
  %add3803 = add i32 %add3802, %or3786
  %or3807 = tail call i32 @llvm.fshl.i32(i32 %add3602, i32 %add3602, i32 9)
  %or3811 = tail call i32 @llvm.fshl.i32(i32 %xor3627, i32 %xor3627, i32 19)
  %or3815 = tail call i32 @llvm.fshl.i32(i32 %add3803, i32 %add3803, i32 9)
  %xor3816 = xor i32 %or3815, %add3803
  %or3820 = tail call i32 @llvm.fshl.i32(i32 %add3803, i32 %add3803, i32 17)
  %xor3821 = xor i32 %xor3816, %or3820
  %xor3824 = xor i32 %xor2996, %xor2317
  %or3828 = tail call i32 @llvm.fshl.i32(i32 %xor3578, i32 %xor3578, i32 15)
  %xor3829 = xor i32 %xor3824, %or3828
  %or3845 = tail call i32 @llvm.fshl.i32(i32 %xor3829, i32 %xor3829, i32 15)
  %or3862 = tail call i32 @llvm.fshl.i32(i32 %xor3829, i32 %xor3829, i32 23)
  %or3867 = tail call i32 @llvm.fshl.i32(i32 %xor2608, i32 %xor2608, i32 7)
  %xor3846 = xor i32 %xor3287, %or3867
  %xor3863 = xor i32 %xor3846, %xor3829
  %xor3868 = xor i32 %xor3863, %or3845
  %xor3869 = xor i32 %xor3868, %or3862
  %or3875 = tail call i32 @llvm.fshl.i32(i32 %add3796, i32 %add3796, i32 12)
  %add3877 = add i32 %or3875, 1358147919
  %add3878 = add i32 %add3877, %xor3821
  %or3883 = tail call i32 @llvm.fshl.i32(i32 %add3878, i32 %add3878, i32 7)
  %and3885 = and i32 %add3796, %add3699
  %or3886 = or i32 %add3796, %add3699
  %and3887 = and i32 %or3886, %or3807
  %or3888 = or i32 %and3887, %and3885
  %xor3890 = xor i32 %or3883, %or3875
  %xor3892 = xor i32 %xor2802, %xor2414
  %add3889 = add i32 %or3710, %xor3892
  %add3891 = add i32 %add3889, %or3888
  %add3893 = add i32 %add3891, %xor3890
  %xor3895 = xor i32 %xor3724, %or3811
  %and3896 = and i32 %xor3821, %xor3895
  %xor3897 = xor i32 %and3896, %or3811
  %add3898 = add i32 %or3714, %xor2414
  %add3899 = add i32 %add3898, %xor3897
  %add3900 = add i32 %add3899, %or3883
  %or3904 = tail call i32 @llvm.fshl.i32(i32 %add3699, i32 %add3699, i32 9)
  %or3908 = tail call i32 @llvm.fshl.i32(i32 %xor3724, i32 %xor3724, i32 19)
  %or3912 = tail call i32 @llvm.fshl.i32(i32 %add3900, i32 %add3900, i32 9)
  %xor3913 = xor i32 %or3912, %add3900
  %or3917 = tail call i32 @llvm.fshl.i32(i32 %add3900, i32 %add3900, i32 17)
  %xor3918 = xor i32 %xor3913, %or3917
  %xor3921 = xor i32 %xor3093, %xor2414
  %or3925 = tail call i32 @llvm.fshl.i32(i32 %xor3675, i32 %xor3675, i32 15)
  %xor3926 = xor i32 %xor3921, %or3925
  %or3942 = tail call i32 @llvm.fshl.i32(i32 %xor3926, i32 %xor3926, i32 15)
  %or3959 = tail call i32 @llvm.fshl.i32(i32 %xor3926, i32 %xor3926, i32 23)
  %or3964 = tail call i32 @llvm.fshl.i32(i32 %xor2705, i32 %xor2705, i32 7)
  %xor3943 = xor i32 %xor3384, %or3964
  %xor3960 = xor i32 %xor3943, %xor3926
  %xor3965 = xor i32 %xor3960, %or3942
  %xor3966 = xor i32 %xor3965, %or3959
  %or3972 = tail call i32 @llvm.fshl.i32(i32 %add3893, i32 %add3893, i32 12)
  %add3974 = add i32 %or3972, -1578671458
  %add3975 = add i32 %add3974, %xor3918
  %or3980 = tail call i32 @llvm.fshl.i32(i32 %add3975, i32 %add3975, i32 7)
  %and3982 = and i32 %add3893, %add3796
  %or3983 = or i32 %add3893, %add3796
  %and3984 = and i32 %or3983, %or3904
  %or3985 = or i32 %and3984, %and3982
  %xor3987 = xor i32 %or3980, %or3972
  %xor3989 = xor i32 %xor2899, %xor2511
  %add3986 = add i32 %or3807, %xor3989
  %add3988 = add i32 %add3986, %or3985
  %add3990 = add i32 %add3988, %xor3987
  %xor3992 = xor i32 %xor3821, %or3908
  %and3993 = and i32 %xor3918, %xor3992
  %xor3994 = xor i32 %and3993, %or3908
  %add3995 = add i32 %or3811, %xor2511
  %add3996 = add i32 %add3995, %xor3994
  %add3997 = add i32 %add3996, %or3980
  %or4001 = tail call i32 @llvm.fshl.i32(i32 %add3796, i32 %add3796, i32 9)
  %or4005 = tail call i32 @llvm.fshl.i32(i32 %xor3821, i32 %xor3821, i32 19)
  %or4009 = tail call i32 @llvm.fshl.i32(i32 %add3997, i32 %add3997, i32 9)
  %xor4010 = xor i32 %or4009, %add3997
  %or4014 = tail call i32 @llvm.fshl.i32(i32 %add3997, i32 %add3997, i32 17)
  %xor4015 = xor i32 %xor4010, %or4014
  %xor4018 = xor i32 %xor3190, %xor2511
  %or4022 = tail call i32 @llvm.fshl.i32(i32 %xor3772, i32 %xor3772, i32 15)
  %xor4023 = xor i32 %xor4018, %or4022
  %or4039 = tail call i32 @llvm.fshl.i32(i32 %xor4023, i32 %xor4023, i32 15)
  %or4056 = tail call i32 @llvm.fshl.i32(i32 %xor4023, i32 %xor4023, i32 23)
  %or4061 = tail call i32 @llvm.fshl.i32(i32 %xor2802, i32 %xor2802, i32 7)
  %xor4040 = xor i32 %xor3481, %or4061
  %xor4057 = xor i32 %xor4040, %xor4023
  %xor4062 = xor i32 %xor4057, %or4039
  %xor4063 = xor i32 %xor4062, %or4056
  %or4069 = tail call i32 @llvm.fshl.i32(i32 %add3990, i32 %add3990, i32 12)
  %add4071 = add i32 %or4069, 1137624381
  %add4072 = add i32 %add4071, %xor4015
  %or4077 = tail call i32 @llvm.fshl.i32(i32 %add4072, i32 %add4072, i32 7)
  %and4079 = and i32 %add3990, %add3893
  %or4080 = or i32 %add3990, %add3893
  %and4081 = and i32 %or4080, %or4001
  %or4082 = or i32 %and4081, %and4079
  %xor4084 = xor i32 %or4077, %or4069
  %xor4086 = xor i32 %xor2996, %xor2608
  %add4083 = add i32 %or3904, %xor4086
  %add4085 = add i32 %add4083, %or4082
  %add4087 = add i32 %add4085, %xor4084
  %xor4089 = xor i32 %xor3918, %or4005
  %and4090 = and i32 %xor4015, %xor4089
  %xor4091 = xor i32 %and4090, %or4005
  %add4092 = add i32 %or3908, %xor2608
  %add4093 = add i32 %add4092, %xor4091
  %add4094 = add i32 %add4093, %or4077
  %or4098 = tail call i32 @llvm.fshl.i32(i32 %add3893, i32 %add3893, i32 9)
  %or4102 = tail call i32 @llvm.fshl.i32(i32 %xor3918, i32 %xor3918, i32 19)
  %or4106 = tail call i32 @llvm.fshl.i32(i32 %add4094, i32 %add4094, i32 9)
  %xor4107 = xor i32 %or4106, %add4094
  %or4111 = tail call i32 @llvm.fshl.i32(i32 %add4094, i32 %add4094, i32 17)
  %xor4112 = xor i32 %xor4107, %or4111
  %xor4115 = xor i32 %xor3287, %xor2608
  %or4119 = tail call i32 @llvm.fshl.i32(i32 %xor3869, i32 %xor3869, i32 15)
  %xor4120 = xor i32 %xor4115, %or4119
  %or4136 = tail call i32 @llvm.fshl.i32(i32 %xor4120, i32 %xor4120, i32 15)
  %or4153 = tail call i32 @llvm.fshl.i32(i32 %xor4120, i32 %xor4120, i32 23)
  %or4158 = tail call i32 @llvm.fshl.i32(i32 %xor2899, i32 %xor2899, i32 7)
  %xor4137 = xor i32 %xor3578, %or4158
  %xor4154 = xor i32 %xor4137, %xor4120
  %xor4159 = xor i32 %xor4154, %or4136
  %xor4160 = xor i32 %xor4159, %or4153
  %or4166 = tail call i32 @llvm.fshl.i32(i32 %add4087, i32 %add4087, i32 12)
  %add4168 = add i32 %or4166, -2019718534
  %add4169 = add i32 %add4168, %xor4112
  %or4174 = tail call i32 @llvm.fshl.i32(i32 %add4169, i32 %add4169, i32 7)
  %and4176 = and i32 %add4087, %add3990
  %or4177 = or i32 %add4087, %add3990
  %and4178 = and i32 %or4177, %or4098
  %or4179 = or i32 %and4178, %and4176
  %xor4181 = xor i32 %or4174, %or4166
  %xor4183 = xor i32 %xor3093, %xor2705
  %add4180 = add i32 %or4001, %xor4183
  %add4182 = add i32 %add4180, %or4179
  %add4184 = add i32 %add4182, %xor4181
  %xor4186 = xor i32 %xor4015, %or4102
  %and4187 = and i32 %xor4112, %xor4186
  %xor4188 = xor i32 %and4187, %or4102
  %add4189 = add i32 %or4005, %xor2705
  %add4190 = add i32 %add4189, %xor4188
  %add4191 = add i32 %add4190, %or4174
  %or4195 = tail call i32 @llvm.fshl.i32(i32 %add3990, i32 %add3990, i32 9)
  %or4199 = tail call i32 @llvm.fshl.i32(i32 %xor4015, i32 %xor4015, i32 19)
  %or4203 = tail call i32 @llvm.fshl.i32(i32 %add4191, i32 %add4191, i32 9)
  %xor4204 = xor i32 %or4203, %add4191
  %or4208 = tail call i32 @llvm.fshl.i32(i32 %add4191, i32 %add4191, i32 17)
  %xor4209 = xor i32 %xor4204, %or4208
  %xor4212 = xor i32 %xor3384, %xor2705
  %or4216 = tail call i32 @llvm.fshl.i32(i32 %xor3966, i32 %xor3966, i32 15)
  %xor4217 = xor i32 %xor4212, %or4216
  %or4233 = tail call i32 @llvm.fshl.i32(i32 %xor4217, i32 %xor4217, i32 15)
  %or4250 = tail call i32 @llvm.fshl.i32(i32 %xor4217, i32 %xor4217, i32 23)
  %or4255 = tail call i32 @llvm.fshl.i32(i32 %xor2996, i32 %xor2996, i32 7)
  %xor4234 = xor i32 %xor3675, %or4255
  %xor4251 = xor i32 %xor4234, %xor4217
  %xor4256 = xor i32 %xor4251, %or4233
  %xor4257 = xor i32 %xor4256, %or4250
  %or4263 = tail call i32 @llvm.fshl.i32(i32 %add4184, i32 %add4184, i32 12)
  %add4265 = add i32 %or4263, 255530229
  %add4266 = add i32 %add4265, %xor4209
  %or4271 = tail call i32 @llvm.fshl.i32(i32 %add4266, i32 %add4266, i32 7)
  %and4273 = and i32 %add4184, %add4087
  %or4274 = or i32 %add4184, %add4087
  %and4275 = and i32 %or4274, %or4195
  %or4276 = or i32 %and4275, %and4273
  %xor4278 = xor i32 %or4271, %or4263
  %xor4280 = xor i32 %xor3190, %xor2802
  %add4277 = add i32 %or4098, %xor4280
  %add4279 = add i32 %add4277, %or4276
  %add4281 = add i32 %add4279, %xor4278
  %xor4283 = xor i32 %xor4112, %or4199
  %and4284 = and i32 %xor4209, %xor4283
  %xor4285 = xor i32 %and4284, %or4199
  %add4286 = add i32 %or4102, %xor2802
  %add4287 = add i32 %add4286, %xor4285
  %add4288 = add i32 %add4287, %or4271
  %or4292 = tail call i32 @llvm.fshl.i32(i32 %add4087, i32 %add4087, i32 9)
  %or4296 = tail call i32 @llvm.fshl.i32(i32 %xor4112, i32 %xor4112, i32 19)
  %or4300 = tail call i32 @llvm.fshl.i32(i32 %add4288, i32 %add4288, i32 9)
  %xor4301 = xor i32 %or4300, %add4288
  %or4305 = tail call i32 @llvm.fshl.i32(i32 %add4288, i32 %add4288, i32 17)
  %xor4306 = xor i32 %xor4301, %or4305
  %xor4309 = xor i32 %xor3481, %xor2802
  %or4313 = tail call i32 @llvm.fshl.i32(i32 %xor4063, i32 %xor4063, i32 15)
  %xor4314 = xor i32 %xor4309, %or4313
  %or4330 = tail call i32 @llvm.fshl.i32(i32 %xor4314, i32 %xor4314, i32 15)
  %or4347 = tail call i32 @llvm.fshl.i32(i32 %xor4314, i32 %xor4314, i32 23)
  %or4352 = tail call i32 @llvm.fshl.i32(i32 %xor3093, i32 %xor3093, i32 7)
  %xor4331 = xor i32 %xor3772, %or4352
  %xor4348 = xor i32 %xor4331, %xor4314
  %xor4353 = xor i32 %xor4348, %or4330
  %xor4354 = xor i32 %xor4353, %or4347
  %or4360 = tail call i32 @llvm.fshl.i32(i32 %add4281, i32 %add4281, i32 12)
  %add4362 = add i32 %or4360, 511060458
  %add4363 = add i32 %add4362, %xor4306
  %or4368 = tail call i32 @llvm.fshl.i32(i32 %add4363, i32 %add4363, i32 7)
  %and4370 = and i32 %add4281, %add4184
  %or4371 = or i32 %add4281, %add4184
  %and4372 = and i32 %or4371, %or4292
  %or4373 = or i32 %and4372, %and4370
  %xor4375 = xor i32 %or4368, %or4360
  %xor4377 = xor i32 %xor3287, %xor2899
  %add4374 = add i32 %or4195, %xor4377
  %add4376 = add i32 %add4374, %or4373
  %add4378 = add i32 %add4376, %xor4375
  %xor4380 = xor i32 %xor4209, %or4296
  %and4381 = and i32 %xor4306, %xor4380
  %xor4382 = xor i32 %and4381, %or4296
  %add4383 = add i32 %or4199, %xor2899
  %add4384 = add i32 %add4383, %xor4382
  %add4385 = add i32 %add4384, %or4368
  %or4389 = tail call i32 @llvm.fshl.i32(i32 %add4184, i32 %add4184, i32 9)
  %or4393 = tail call i32 @llvm.fshl.i32(i32 %xor4209, i32 %xor4209, i32 19)
  %or4397 = tail call i32 @llvm.fshl.i32(i32 %add4385, i32 %add4385, i32 9)
  %xor4398 = xor i32 %or4397, %add4385
  %or4402 = tail call i32 @llvm.fshl.i32(i32 %add4385, i32 %add4385, i32 17)
  %xor4403 = xor i32 %xor4398, %or4402
  %xor4406 = xor i32 %xor3578, %xor2899
  %or4410 = tail call i32 @llvm.fshl.i32(i32 %xor4160, i32 %xor4160, i32 15)
  %xor4411 = xor i32 %xor4406, %or4410
  %or4427 = tail call i32 @llvm.fshl.i32(i32 %xor4411, i32 %xor4411, i32 15)
  %or4444 = tail call i32 @llvm.fshl.i32(i32 %xor4411, i32 %xor4411, i32 23)
  %or4449 = tail call i32 @llvm.fshl.i32(i32 %xor3190, i32 %xor3190, i32 7)
  %xor4428 = xor i32 %xor3869, %or4449
  %xor4445 = xor i32 %xor4428, %xor4411
  %xor4450 = xor i32 %xor4445, %or4427
  %xor4451 = xor i32 %xor4450, %or4444
  %or4457 = tail call i32 @llvm.fshl.i32(i32 %add4378, i32 %add4378, i32 12)
  %add4459 = add i32 %or4457, 1022120916
  %add4460 = add i32 %add4459, %xor4403
  %or4465 = tail call i32 @llvm.fshl.i32(i32 %add4460, i32 %add4460, i32 7)
  %and4467 = and i32 %add4378, %add4281
  %or4468 = or i32 %add4378, %add4281
  %and4469 = and i32 %or4468, %or4389
  %or4470 = or i32 %and4469, %and4467
  %xor4472 = xor i32 %or4465, %or4457
  %xor4474 = xor i32 %xor3384, %xor2996
  %add4471 = add i32 %or4292, %xor4474
  %add4473 = add i32 %add4471, %or4470
  %add4475 = add i32 %add4473, %xor4472
  %xor4477 = xor i32 %xor4306, %or4393
  %and4478 = and i32 %xor4403, %xor4477
  %xor4479 = xor i32 %and4478, %or4393
  %add4480 = add i32 %or4296, %xor2996
  %add4481 = add i32 %add4480, %xor4479
  %add4482 = add i32 %add4481, %or4465
  %or4486 = tail call i32 @llvm.fshl.i32(i32 %add4281, i32 %add4281, i32 9)
  %or4490 = tail call i32 @llvm.fshl.i32(i32 %xor4306, i32 %xor4306, i32 19)
  %or4494 = tail call i32 @llvm.fshl.i32(i32 %add4482, i32 %add4482, i32 9)
  %xor4495 = xor i32 %or4494, %add4482
  %or4499 = tail call i32 @llvm.fshl.i32(i32 %add4482, i32 %add4482, i32 17)
  %xor4500 = xor i32 %xor4495, %or4499
  %xor4503 = xor i32 %xor3675, %xor2996
  %or4507 = tail call i32 @llvm.fshl.i32(i32 %xor4257, i32 %xor4257, i32 15)
  %xor4508 = xor i32 %xor4503, %or4507
  %or4524 = tail call i32 @llvm.fshl.i32(i32 %xor4508, i32 %xor4508, i32 15)
  %or4541 = tail call i32 @llvm.fshl.i32(i32 %xor4508, i32 %xor4508, i32 23)
  %or4546 = tail call i32 @llvm.fshl.i32(i32 %xor3287, i32 %xor3287, i32 7)
  %xor4525 = xor i32 %xor3966, %or4546
  %xor4542 = xor i32 %xor4525, %xor4508
  %xor4547 = xor i32 %xor4542, %or4524
  %xor4548 = xor i32 %xor4547, %or4541
  %or4554 = tail call i32 @llvm.fshl.i32(i32 %add4475, i32 %add4475, i32 12)
  %add4556 = add i32 %or4554, 2044241832
  %add4557 = add i32 %add4556, %xor4500
  %or4562 = tail call i32 @llvm.fshl.i32(i32 %add4557, i32 %add4557, i32 7)
  %and4564 = and i32 %add4475, %add4378
  %or4565 = or i32 %add4475, %add4378
  %and4566 = and i32 %or4565, %or4486
  %or4567 = or i32 %and4566, %and4564
  %xor4569 = xor i32 %or4562, %or4554
  %xor4571 = xor i32 %xor3481, %xor3093
  %add4568 = add i32 %or4389, %xor4571
  %add4570 = add i32 %add4568, %or4567
  %add4572 = add i32 %add4570, %xor4569
  %xor4574 = xor i32 %xor4403, %or4490
  %and4575 = and i32 %xor4500, %xor4574
  %xor4576 = xor i32 %and4575, %or4490
  %add4577 = add i32 %or4393, %xor3093
  %add4578 = add i32 %add4577, %xor4576
  %add4579 = add i32 %add4578, %or4562
  %or4583 = tail call i32 @llvm.fshl.i32(i32 %add4378, i32 %add4378, i32 9)
  %or4587 = tail call i32 @llvm.fshl.i32(i32 %xor4403, i32 %xor4403, i32 19)
  %or4591 = tail call i32 @llvm.fshl.i32(i32 %add4579, i32 %add4579, i32 9)
  %xor4592 = xor i32 %or4591, %add4579
  %or4596 = tail call i32 @llvm.fshl.i32(i32 %add4579, i32 %add4579, i32 17)
  %xor4597 = xor i32 %xor4592, %or4596
  %xor4600 = xor i32 %xor3772, %xor3093
  %or4604 = tail call i32 @llvm.fshl.i32(i32 %xor4354, i32 %xor4354, i32 15)
  %xor4605 = xor i32 %xor4600, %or4604
  %or4621 = tail call i32 @llvm.fshl.i32(i32 %xor4605, i32 %xor4605, i32 15)
  %or4638 = tail call i32 @llvm.fshl.i32(i32 %xor4605, i32 %xor4605, i32 23)
  %or4643 = tail call i32 @llvm.fshl.i32(i32 %xor3384, i32 %xor3384, i32 7)
  %xor4622 = xor i32 %xor4063, %or4643
  %xor4639 = xor i32 %xor4622, %xor4605
  %xor4644 = xor i32 %xor4639, %or4621
  %xor4645 = xor i32 %xor4644, %or4638
  %or4651 = tail call i32 @llvm.fshl.i32(i32 %add4572, i32 %add4572, i32 12)
  %add4653 = add i32 %or4651, -206483632
  %add4654 = add i32 %add4653, %xor4597
  %or4659 = tail call i32 @llvm.fshl.i32(i32 %add4654, i32 %add4654, i32 7)
  %and4661 = and i32 %add4572, %add4475
  %or4662 = or i32 %add4572, %add4475
  %and4663 = and i32 %or4662, %or4583
  %or4664 = or i32 %and4663, %and4661
  %xor4666 = xor i32 %or4659, %or4651
  %xor4668 = xor i32 %xor3578, %xor3190
  %add4665 = add i32 %or4486, %xor4668
  %add4667 = add i32 %add4665, %or4664
  %add4669 = add i32 %add4667, %xor4666
  %xor4671 = xor i32 %xor4500, %or4587
  %and4672 = and i32 %xor4597, %xor4671
  %xor4673 = xor i32 %and4672, %or4587
  %add4674 = add i32 %or4490, %xor3190
  %add4675 = add i32 %add4674, %xor4673
  %add4676 = add i32 %add4675, %or4659
  %or4680 = tail call i32 @llvm.fshl.i32(i32 %add4475, i32 %add4475, i32 9)
  %or4684 = tail call i32 @llvm.fshl.i32(i32 %xor4500, i32 %xor4500, i32 19)
  %or4688 = tail call i32 @llvm.fshl.i32(i32 %add4676, i32 %add4676, i32 9)
  %xor4689 = xor i32 %or4688, %add4676
  %or4693 = tail call i32 @llvm.fshl.i32(i32 %add4676, i32 %add4676, i32 17)
  %xor4694 = xor i32 %xor4689, %or4693
  %xor4697 = xor i32 %xor3869, %xor3190
  %or4701 = tail call i32 @llvm.fshl.i32(i32 %xor4451, i32 %xor4451, i32 15)
  %xor4702 = xor i32 %xor4697, %or4701
  %or4718 = tail call i32 @llvm.fshl.i32(i32 %xor4702, i32 %xor4702, i32 15)
  %or4735 = tail call i32 @llvm.fshl.i32(i32 %xor4702, i32 %xor4702, i32 23)
  %or4740 = tail call i32 @llvm.fshl.i32(i32 %xor3481, i32 %xor3481, i32 7)
  %xor4719 = xor i32 %xor4160, %or4740
  %xor4736 = xor i32 %xor4719, %xor4702
  %xor4741 = xor i32 %xor4736, %or4718
  %xor4742 = xor i32 %xor4741, %or4735
  %or4748 = tail call i32 @llvm.fshl.i32(i32 %add4669, i32 %add4669, i32 12)
  %add4750 = add i32 %or4748, -412967263
  %add4751 = add i32 %add4750, %xor4694
  %or4756 = tail call i32 @llvm.fshl.i32(i32 %add4751, i32 %add4751, i32 7)
  %and4758 = and i32 %add4669, %add4572
  %or4759 = or i32 %add4669, %add4572
  %and4760 = and i32 %or4759, %or4680
  %or4761 = or i32 %and4760, %and4758
  %xor4763 = xor i32 %or4756, %or4748
  %xor4765 = xor i32 %xor3675, %xor3287
  %add4762 = add i32 %or4583, %xor4765
  %add4764 = add i32 %add4762, %or4761
  %add4766 = add i32 %add4764, %xor4763
  %xor4768 = xor i32 %xor4597, %or4684
  %and4769 = and i32 %xor4694, %xor4768
  %xor4770 = xor i32 %and4769, %or4684
  %add4771 = add i32 %or4587, %xor3287
  %add4772 = add i32 %add4771, %xor4770
  %add4773 = add i32 %add4772, %or4756
  %or4777 = tail call i32 @llvm.fshl.i32(i32 %add4572, i32 %add4572, i32 9)
  %or4781 = tail call i32 @llvm.fshl.i32(i32 %xor4597, i32 %xor4597, i32 19)
  %or4785 = tail call i32 @llvm.fshl.i32(i32 %add4773, i32 %add4773, i32 9)
  %xor4786 = xor i32 %or4785, %add4773
  %or4790 = tail call i32 @llvm.fshl.i32(i32 %add4773, i32 %add4773, i32 17)
  %xor4791 = xor i32 %xor4786, %or4790
  %xor4794 = xor i32 %xor3966, %xor3287
  %or4798 = tail call i32 @llvm.fshl.i32(i32 %xor4548, i32 %xor4548, i32 15)
  %xor4799 = xor i32 %xor4794, %or4798
  %or4815 = tail call i32 @llvm.fshl.i32(i32 %xor4799, i32 %xor4799, i32 15)
  %or4832 = tail call i32 @llvm.fshl.i32(i32 %xor4799, i32 %xor4799, i32 23)
  %or4837 = tail call i32 @llvm.fshl.i32(i32 %xor3578, i32 %xor3578, i32 7)
  %xor4816 = xor i32 %xor4257, %or4837
  %xor4833 = xor i32 %xor4816, %xor4799
  %xor4838 = xor i32 %xor4833, %or4815
  %xor4839 = xor i32 %xor4838, %or4832
  %or4845 = tail call i32 @llvm.fshl.i32(i32 %add4766, i32 %add4766, i32 12)
  %add4847 = add i32 %or4845, -825934525
  %add4848 = add i32 %add4847, %xor4791
  %or4853 = tail call i32 @llvm.fshl.i32(i32 %add4848, i32 %add4848, i32 7)
  %and4855 = and i32 %add4766, %add4669
  %or4856 = or i32 %add4766, %add4669
  %and4857 = and i32 %or4856, %or4777
  %or4858 = or i32 %and4857, %and4855
  %xor4860 = xor i32 %or4853, %or4845
  %xor4862 = xor i32 %xor3772, %xor3384
  %add4859 = add i32 %or4680, %xor4862
  %add4861 = add i32 %add4859, %or4858
  %add4863 = add i32 %add4861, %xor4860
  %xor4865 = xor i32 %xor4694, %or4781
  %and4866 = and i32 %xor4791, %xor4865
  %xor4867 = xor i32 %and4866, %or4781
  %add4868 = add i32 %or4684, %xor3384
  %add4869 = add i32 %add4868, %xor4867
  %add4870 = add i32 %add4869, %or4853
  %or4874 = tail call i32 @llvm.fshl.i32(i32 %add4669, i32 %add4669, i32 9)
  %or4878 = tail call i32 @llvm.fshl.i32(i32 %xor4694, i32 %xor4694, i32 19)
  %or4882 = tail call i32 @llvm.fshl.i32(i32 %add4870, i32 %add4870, i32 9)
  %xor4883 = xor i32 %or4882, %add4870
  %or4887 = tail call i32 @llvm.fshl.i32(i32 %add4870, i32 %add4870, i32 17)
  %xor4888 = xor i32 %xor4883, %or4887
  %xor4891 = xor i32 %xor4063, %xor3384
  %or4895 = tail call i32 @llvm.fshl.i32(i32 %xor4645, i32 %xor4645, i32 15)
  %xor4896 = xor i32 %xor4891, %or4895
  %or4912 = tail call i32 @llvm.fshl.i32(i32 %xor4896, i32 %xor4896, i32 15)
  %or4929 = tail call i32 @llvm.fshl.i32(i32 %xor4896, i32 %xor4896, i32 23)
  %or4934 = tail call i32 @llvm.fshl.i32(i32 %xor3675, i32 %xor3675, i32 7)
  %xor4913 = xor i32 %xor4354, %or4934
  %xor4930 = xor i32 %xor4913, %xor4896
  %xor4935 = xor i32 %xor4930, %or4912
  %xor4936 = xor i32 %xor4935, %or4929
  %or4942 = tail call i32 @llvm.fshl.i32(i32 %add4863, i32 %add4863, i32 12)
  %add4944 = add i32 %or4942, -1651869049
  %add4945 = add i32 %add4944, %xor4888
  %or4950 = tail call i32 @llvm.fshl.i32(i32 %add4945, i32 %add4945, i32 7)
  %and4952 = and i32 %add4863, %add4766
  %or4953 = or i32 %add4863, %add4766
  %and4954 = and i32 %or4953, %or4874
  %or4955 = or i32 %and4954, %and4952
  %xor4957 = xor i32 %or4950, %or4942
  %xor4959 = xor i32 %xor3869, %xor3481
  %add4956 = add i32 %or4777, %xor4959
  %add4958 = add i32 %add4956, %or4955
  %add4960 = add i32 %add4958, %xor4957
  %xor4962 = xor i32 %xor4791, %or4878
  %and4963 = and i32 %xor4888, %xor4962
  %xor4964 = xor i32 %and4963, %or4878
  %add4965 = add i32 %or4781, %xor3481
  %add4966 = add i32 %add4965, %xor4964
  %add4967 = add i32 %add4966, %or4950
  %or4971 = tail call i32 @llvm.fshl.i32(i32 %add4766, i32 %add4766, i32 9)
  %or4975 = tail call i32 @llvm.fshl.i32(i32 %xor4791, i32 %xor4791, i32 19)
  %or4979 = tail call i32 @llvm.fshl.i32(i32 %add4967, i32 %add4967, i32 9)
  %xor4980 = xor i32 %or4979, %add4967
  %or4984 = tail call i32 @llvm.fshl.i32(i32 %add4967, i32 %add4967, i32 17)
  %xor4985 = xor i32 %xor4980, %or4984
  %xor4988 = xor i32 %xor4160, %xor3481
  %or4992 = tail call i32 @llvm.fshl.i32(i32 %xor4742, i32 %xor4742, i32 15)
  %xor4993 = xor i32 %xor4988, %or4992
  %or5009 = tail call i32 @llvm.fshl.i32(i32 %xor4993, i32 %xor4993, i32 15)
  %or5026 = tail call i32 @llvm.fshl.i32(i32 %xor4993, i32 %xor4993, i32 23)
  %or5031 = tail call i32 @llvm.fshl.i32(i32 %xor3772, i32 %xor3772, i32 7)
  %xor5010 = xor i32 %xor4451, %or5031
  %xor5027 = xor i32 %xor5010, %xor4993
  %xor5032 = xor i32 %xor5027, %or5009
  %xor5033 = xor i32 %xor5032, %or5026
  %or5039 = tail call i32 @llvm.fshl.i32(i32 %add4960, i32 %add4960, i32 12)
  %add5041 = add i32 %or5039, 991229199
  %add5042 = add i32 %add5041, %xor4985
  %or5047 = tail call i32 @llvm.fshl.i32(i32 %add5042, i32 %add5042, i32 7)
  %and5049 = and i32 %add4960, %add4863
  %or5050 = or i32 %add4960, %add4863
  %and5051 = and i32 %or5050, %or4971
  %or5052 = or i32 %and5051, %and5049
  %xor5054 = xor i32 %or5047, %or5039
  %xor5056 = xor i32 %xor3966, %xor3578
  %add5053 = add i32 %or4874, %xor5056
  %add5055 = add i32 %add5053, %or5052
  %add5057 = add i32 %add5055, %xor5054
  %xor5059 = xor i32 %xor4888, %or4975
  %and5060 = and i32 %xor4985, %xor5059
  %xor5061 = xor i32 %and5060, %or4975
  %add5062 = add i32 %or4878, %xor3578
  %add5063 = add i32 %add5062, %xor5061
  %add5064 = add i32 %add5063, %or5047
  %or5068 = tail call i32 @llvm.fshl.i32(i32 %add4863, i32 %add4863, i32 9)
  %or5072 = tail call i32 @llvm.fshl.i32(i32 %xor4888, i32 %xor4888, i32 19)
  %or5076 = tail call i32 @llvm.fshl.i32(i32 %add5064, i32 %add5064, i32 9)
  %xor5077 = xor i32 %or5076, %add5064
  %or5081 = tail call i32 @llvm.fshl.i32(i32 %add5064, i32 %add5064, i32 17)
  %xor5082 = xor i32 %xor5077, %or5081
  %xor5085 = xor i32 %xor4257, %xor3578
  %or5089 = tail call i32 @llvm.fshl.i32(i32 %xor4839, i32 %xor4839, i32 15)
  %xor5090 = xor i32 %xor5085, %or5089
  %or5106 = tail call i32 @llvm.fshl.i32(i32 %xor5090, i32 %xor5090, i32 15)
  %or5123 = tail call i32 @llvm.fshl.i32(i32 %xor5090, i32 %xor5090, i32 23)
  %or5128 = tail call i32 @llvm.fshl.i32(i32 %xor3869, i32 %xor3869, i32 7)
  %or5136 = tail call i32 @llvm.fshl.i32(i32 %add5057, i32 %add5057, i32 12)
  %add5138 = add i32 %or5136, 1982458398
  %add5139 = add i32 %add5138, %xor5082
  %or5144 = tail call i32 @llvm.fshl.i32(i32 %add5139, i32 %add5139, i32 7)
  %and5146 = and i32 %add5057, %add4960
  %or5147 = or i32 %add5057, %add4960
  %and5148 = and i32 %or5147, %or5068
  %or5149 = or i32 %and5148, %and5146
  %xor5151 = xor i32 %or5144, %or5136
  %xor5153 = xor i32 %xor4063, %xor3675
  %add5150 = add i32 %or4971, %xor5153
  %add5152 = add i32 %add5150, %or5149
  %add5154 = add i32 %add5152, %xor5151
  %xor5156 = xor i32 %xor4985, %or5072
  %and5157 = and i32 %xor5082, %xor5156
  %xor5158 = xor i32 %and5157, %or5072
  %add5159 = add i32 %or4975, %xor3675
  %add5160 = add i32 %add5159, %xor5158
  %add5161 = add i32 %add5160, %or5144
  %or5165 = tail call i32 @llvm.fshl.i32(i32 %add4960, i32 %add4960, i32 9)
  %or5169 = tail call i32 @llvm.fshl.i32(i32 %xor4985, i32 %xor4985, i32 19)
  %or5173 = tail call i32 @llvm.fshl.i32(i32 %add5161, i32 %add5161, i32 9)
  %xor5174 = xor i32 %or5173, %add5161
  %or5178 = tail call i32 @llvm.fshl.i32(i32 %add5161, i32 %add5161, i32 17)
  %xor5179 = xor i32 %xor5174, %or5178
  %xor5182 = xor i32 %xor4354, %xor3675
  %or5186 = tail call i32 @llvm.fshl.i32(i32 %xor4936, i32 %xor4936, i32 15)
  %xor5187 = xor i32 %xor5182, %or5186
  %or5203 = tail call i32 @llvm.fshl.i32(i32 %xor5187, i32 %xor5187, i32 15)
  %or5220 = tail call i32 @llvm.fshl.i32(i32 %xor5187, i32 %xor5187, i32 23)
  %or5225 = tail call i32 @llvm.fshl.i32(i32 %xor3966, i32 %xor3966, i32 7)
  %or5233 = tail call i32 @llvm.fshl.i32(i32 %add5154, i32 %add5154, i32 12)
  %add5235 = add i32 %or5233, -330050500
  %add5236 = add i32 %add5235, %xor5179
  %or5241 = tail call i32 @llvm.fshl.i32(i32 %add5236, i32 %add5236, i32 7)
  %and5243 = and i32 %add5154, %add5057
  %or5244 = or i32 %add5154, %add5057
  %and5245 = and i32 %or5244, %or5165
  %or5246 = or i32 %and5245, %and5243
  %xor5248 = xor i32 %or5241, %or5233
  %xor5250 = xor i32 %xor4160, %xor3772
  %add5247 = add i32 %or5068, %xor5250
  %add5249 = add i32 %add5247, %or5246
  %add5251 = add i32 %add5249, %xor5248
  %xor5253 = xor i32 %xor5082, %or5169
  %and5254 = and i32 %xor5179, %xor5253
  %xor5255 = xor i32 %and5254, %or5169
  %add5256 = add i32 %or5072, %xor3772
  %add5257 = add i32 %add5256, %xor5255
  %add5258 = add i32 %add5257, %or5241
  %or5262 = tail call i32 @llvm.fshl.i32(i32 %add5057, i32 %add5057, i32 9)
  %or5266 = tail call i32 @llvm.fshl.i32(i32 %xor5082, i32 %xor5082, i32 19)
  %or5270 = tail call i32 @llvm.fshl.i32(i32 %add5258, i32 %add5258, i32 9)
  %xor5271 = xor i32 %or5270, %add5258
  %or5275 = tail call i32 @llvm.fshl.i32(i32 %add5258, i32 %add5258, i32 17)
  %xor5276 = xor i32 %xor5271, %or5275
  %xor5279 = xor i32 %xor4451, %xor3772
  %or5283 = tail call i32 @llvm.fshl.i32(i32 %xor5033, i32 %xor5033, i32 15)
  %xor5284 = xor i32 %xor5279, %or5283
  %or5300 = tail call i32 @llvm.fshl.i32(i32 %xor5284, i32 %xor5284, i32 15)
  %or5317 = tail call i32 @llvm.fshl.i32(i32 %xor5284, i32 %xor5284, i32 23)
  %or5322 = tail call i32 @llvm.fshl.i32(i32 %xor4063, i32 %xor4063, i32 7)
  %or5330 = tail call i32 @llvm.fshl.i32(i32 %add5251, i32 %add5251, i32 12)
  %add5332 = add i32 %or5330, -660100999
  %add5333 = add i32 %add5332, %xor5276
  %or5338 = tail call i32 @llvm.fshl.i32(i32 %add5333, i32 %add5333, i32 7)
  %and5340 = and i32 %add5251, %add5154
  %or5341 = or i32 %add5251, %add5154
  %and5342 = and i32 %or5341, %or5262
  %or5343 = or i32 %and5342, %and5340
  %xor5345 = xor i32 %or5338, %or5330
  %xor5347 = xor i32 %xor4257, %xor3869
  %add5344 = add i32 %or5165, %xor5347
  %add5346 = add i32 %add5344, %or5343
  %add5348 = add i32 %add5346, %xor5345
  %xor5350 = xor i32 %xor5179, %or5266
  %and5351 = and i32 %xor5276, %xor5350
  %xor5352 = xor i32 %and5351, %or5266
  %add5353 = add i32 %or5169, %xor3869
  %add5354 = add i32 %add5353, %xor5352
  %add5355 = add i32 %add5354, %or5338
  %or5359 = tail call i32 @llvm.fshl.i32(i32 %add5154, i32 %add5154, i32 9)
  %or5363 = tail call i32 @llvm.fshl.i32(i32 %xor5179, i32 %xor5179, i32 19)
  %or5367 = tail call i32 @llvm.fshl.i32(i32 %add5355, i32 %add5355, i32 9)
  %xor5368 = xor i32 %or5367, %add5355
  %or5372 = tail call i32 @llvm.fshl.i32(i32 %add5355, i32 %add5355, i32 17)
  %xor5373 = xor i32 %xor5368, %or5372
  %or5381 = tail call i32 @llvm.fshl.i32(i32 %add5348, i32 %add5348, i32 12)
  %add5383 = add i32 %or5381, -1320201997
  %add5384 = add i32 %add5383, %xor5373
  %or5389 = tail call i32 @llvm.fshl.i32(i32 %add5384, i32 %add5384, i32 7)
  %and5391 = and i32 %add5348, %add5251
  %or5392 = or i32 %add5348, %add5251
  %and5393 = and i32 %or5392, %or5359
  %or5394 = or i32 %and5393, %and5391
  %xor5396 = xor i32 %or5389, %or5381
  %xor5398 = xor i32 %xor4354, %xor3966
  %add5395 = add i32 %or5262, %xor5398
  %add5397 = add i32 %add5395, %or5394
  %add5399 = add i32 %add5397, %xor5396
  %xor5401 = xor i32 %xor5276, %or5363
  %and5402 = and i32 %xor5373, %xor5401
  %xor5403 = xor i32 %and5402, %or5363
  %add5404 = add i32 %or5266, %xor3966
  %add5405 = add i32 %add5404, %xor5403
  %add5406 = add i32 %add5405, %or5389
  %or5410 = tail call i32 @llvm.fshl.i32(i32 %add5251, i32 %add5251, i32 9)
  %or5414 = tail call i32 @llvm.fshl.i32(i32 %xor5276, i32 %xor5276, i32 19)
  %or5418 = tail call i32 @llvm.fshl.i32(i32 %add5406, i32 %add5406, i32 9)
  %xor5419 = xor i32 %or5418, %add5406
  %or5423 = tail call i32 @llvm.fshl.i32(i32 %add5406, i32 %add5406, i32 17)
  %xor5424 = xor i32 %xor5419, %or5423
  %or5432 = tail call i32 @llvm.fshl.i32(i32 %add5399, i32 %add5399, i32 12)
  %add5434 = add i32 %or5432, 1654563303
  %add5435 = add i32 %add5434, %xor5424
  %or5440 = tail call i32 @llvm.fshl.i32(i32 %add5435, i32 %add5435, i32 7)
  %and5442 = and i32 %add5399, %add5348
  %or5443 = or i32 %add5399, %add5348
  %and5444 = and i32 %or5443, %or5410
  %or5445 = or i32 %and5444, %and5442
  %xor5447 = xor i32 %or5440, %or5432
  %xor5449 = xor i32 %xor4451, %xor4063
  %add5446 = add i32 %or5359, %xor5449
  %add5448 = add i32 %add5446, %or5445
  %add5450 = add i32 %add5448, %xor5447
  %xor5452 = xor i32 %xor5373, %or5414
  %and5453 = and i32 %xor5424, %xor5452
  %xor5454 = xor i32 %and5453, %or5414
  %add5455 = add i32 %or5363, %xor4063
  %add5456 = add i32 %add5455, %xor5454
  %add5457 = add i32 %add5456, %or5440
  %or5461 = tail call i32 @llvm.fshl.i32(i32 %add5348, i32 %add5348, i32 9)
  %or5465 = tail call i32 @llvm.fshl.i32(i32 %xor5373, i32 %xor5373, i32 19)
  %or5469 = tail call i32 @llvm.fshl.i32(i32 %add5457, i32 %add5457, i32 9)
  %xor5470 = xor i32 %or5469, %add5457
  %or5474 = tail call i32 @llvm.fshl.i32(i32 %add5457, i32 %add5457, i32 17)
  %xor5475 = xor i32 %xor5470, %or5474
  %or5483 = tail call i32 @llvm.fshl.i32(i32 %add5450, i32 %add5450, i32 12)
  %add5485 = add i32 %or5483, -985840690
  %add5486 = add i32 %add5485, %xor5475
  %or5491 = tail call i32 @llvm.fshl.i32(i32 %add5486, i32 %add5486, i32 7)
  %and5493 = and i32 %add5450, %add5399
  %or5494 = or i32 %add5450, %add5399
  %and5495 = and i32 %or5494, %or5461
  %or5496 = or i32 %and5495, %and5493
  %xor5498 = xor i32 %or5491, %or5483
  %xor5500 = xor i32 %xor4548, %xor4160
  %add5497 = add i32 %or5410, %xor5500
  %add5499 = add i32 %add5497, %or5496
  %add5501 = add i32 %add5499, %xor5498
  %xor5503 = xor i32 %xor5424, %or5465
  %and5504 = and i32 %xor5475, %xor5503
  %xor5505 = xor i32 %and5504, %or5465
  %add5506 = add i32 %or5414, %xor4160
  %add5507 = add i32 %add5506, %xor5505
  %add5508 = add i32 %add5507, %or5491
  %or5512 = tail call i32 @llvm.fshl.i32(i32 %add5399, i32 %add5399, i32 9)
  %or5516 = tail call i32 @llvm.fshl.i32(i32 %xor5424, i32 %xor5424, i32 19)
  %or5520 = tail call i32 @llvm.fshl.i32(i32 %add5508, i32 %add5508, i32 9)
  %xor5521 = xor i32 %or5520, %add5508
  %or5525 = tail call i32 @llvm.fshl.i32(i32 %add5508, i32 %add5508, i32 17)
  %xor5526 = xor i32 %xor5521, %or5525
  %or5534 = tail call i32 @llvm.fshl.i32(i32 %add5501, i32 %add5501, i32 12)
  %add5536 = add i32 %or5534, -1971681379
  %add5537 = add i32 %add5536, %xor5526
  %or5542 = tail call i32 @llvm.fshl.i32(i32 %add5537, i32 %add5537, i32 7)
  %and5544 = and i32 %add5501, %add5450
  %or5545 = or i32 %add5501, %add5450
  %and5546 = and i32 %or5545, %or5512
  %or5547 = or i32 %and5546, %and5544
  %xor5549 = xor i32 %or5542, %or5534
  %xor5551 = xor i32 %xor4645, %xor4257
  %add5548 = add i32 %or5461, %xor5551
  %add5550 = add i32 %add5548, %or5547
  %add5552 = add i32 %add5550, %xor5549
  %xor5554 = xor i32 %xor5475, %or5516
  %and5555 = and i32 %xor5526, %xor5554
  %xor5556 = xor i32 %and5555, %or5516
  %add5557 = add i32 %or5465, %xor4257
  %add5558 = add i32 %add5557, %xor5556
  %add5559 = add i32 %add5558, %or5542
  %or5563 = tail call i32 @llvm.fshl.i32(i32 %add5450, i32 %add5450, i32 9)
  %or5567 = tail call i32 @llvm.fshl.i32(i32 %xor5475, i32 %xor5475, i32 19)
  %or5571 = tail call i32 @llvm.fshl.i32(i32 %add5559, i32 %add5559, i32 9)
  %xor5572 = xor i32 %or5571, %add5559
  %or5576 = tail call i32 @llvm.fshl.i32(i32 %add5559, i32 %add5559, i32 17)
  %xor5577 = xor i32 %xor5572, %or5576
  %or5585 = tail call i32 @llvm.fshl.i32(i32 %add5552, i32 %add5552, i32 12)
  %add5587 = add i32 %or5585, 351604539
  %add5588 = add i32 %add5587, %xor5577
  %or5593 = tail call i32 @llvm.fshl.i32(i32 %add5588, i32 %add5588, i32 7)
  %and5595 = and i32 %add5552, %add5501
  %or5596 = or i32 %add5552, %add5501
  %and5597 = and i32 %or5596, %or5563
  %or5598 = or i32 %and5597, %and5595
  %xor5600 = xor i32 %or5593, %or5585
  %xor5602 = xor i32 %xor4742, %xor4354
  %add5599 = add i32 %or5512, %xor5602
  %add5601 = add i32 %add5599, %or5598
  %add5603 = add i32 %add5601, %xor5600
  %xor5605 = xor i32 %xor5526, %or5567
  %and5606 = and i32 %xor5577, %xor5605
  %xor5607 = xor i32 %and5606, %or5567
  %add5608 = add i32 %or5516, %xor4354
  %add5609 = add i32 %add5608, %xor5607
  %add5610 = add i32 %add5609, %or5593
  %or5614 = tail call i32 @llvm.fshl.i32(i32 %add5501, i32 %add5501, i32 9)
  %or5618 = tail call i32 @llvm.fshl.i32(i32 %xor5526, i32 %xor5526, i32 19)
  %or5622 = tail call i32 @llvm.fshl.i32(i32 %add5610, i32 %add5610, i32 9)
  %xor5623 = xor i32 %or5622, %add5610
  %or5627 = tail call i32 @llvm.fshl.i32(i32 %add5610, i32 %add5610, i32 17)
  %xor5628 = xor i32 %xor5623, %or5627
  %or5636 = tail call i32 @llvm.fshl.i32(i32 %add5603, i32 %add5603, i32 12)
  %add5638 = add i32 %or5636, 703209078
  %add5639 = add i32 %add5638, %xor5628
  %or5644 = tail call i32 @llvm.fshl.i32(i32 %add5639, i32 %add5639, i32 7)
  %and5646 = and i32 %add5603, %add5552
  %or5647 = or i32 %add5603, %add5552
  %and5648 = and i32 %or5647, %or5614
  %or5649 = or i32 %and5648, %and5646
  %xor5651 = xor i32 %or5644, %or5636
  %xor5653 = xor i32 %xor4839, %xor4451
  %add5650 = add i32 %or5563, %xor5653
  %add5652 = add i32 %add5650, %or5649
  %add5654 = add i32 %add5652, %xor5651
  %xor5656 = xor i32 %xor5577, %or5618
  %and5657 = and i32 %xor5628, %xor5656
  %xor5658 = xor i32 %and5657, %or5618
  %add5659 = add i32 %or5567, %xor4451
  %add5660 = add i32 %add5659, %xor5658
  %add5661 = add i32 %add5660, %or5644
  %or5665 = tail call i32 @llvm.fshl.i32(i32 %add5552, i32 %add5552, i32 9)
  %or5669 = tail call i32 @llvm.fshl.i32(i32 %xor5577, i32 %xor5577, i32 19)
  %or5673 = tail call i32 @llvm.fshl.i32(i32 %add5661, i32 %add5661, i32 9)
  %xor5674 = xor i32 %or5673, %add5661
  %or5678 = tail call i32 @llvm.fshl.i32(i32 %add5661, i32 %add5661, i32 17)
  %xor5679 = xor i32 %xor5674, %or5678
  %or5687 = tail call i32 @llvm.fshl.i32(i32 %add5654, i32 %add5654, i32 12)
  %add5689 = add i32 %or5687, 1406418156
  %add5690 = add i32 %add5689, %xor5679
  %or5695 = tail call i32 @llvm.fshl.i32(i32 %add5690, i32 %add5690, i32 7)
  %and5697 = and i32 %add5654, %add5603
  %or5698 = or i32 %add5654, %add5603
  %and5699 = and i32 %or5698, %or5665
  %or5700 = or i32 %and5699, %and5697
  %xor5702 = xor i32 %or5695, %or5687
  %xor5704 = xor i32 %xor4936, %xor4548
  %add5701 = add i32 %or5614, %xor5704
  %add5703 = add i32 %add5701, %or5700
  %add5705 = add i32 %add5703, %xor5702
  %xor5707 = xor i32 %xor5628, %or5669
  %and5708 = and i32 %xor5679, %xor5707
  %xor5709 = xor i32 %and5708, %or5669
  %add5710 = add i32 %or5618, %xor4548
  %add5711 = add i32 %add5710, %xor5709
  %add5712 = add i32 %add5711, %or5695
  %or5716 = tail call i32 @llvm.fshl.i32(i32 %add5603, i32 %add5603, i32 9)
  %or5720 = tail call i32 @llvm.fshl.i32(i32 %xor5628, i32 %xor5628, i32 19)
  %or5724 = tail call i32 @llvm.fshl.i32(i32 %add5712, i32 %add5712, i32 9)
  %xor5725 = xor i32 %or5724, %add5712
  %or5729 = tail call i32 @llvm.fshl.i32(i32 %add5712, i32 %add5712, i32 17)
  %xor5730 = xor i32 %xor5725, %or5729
  %or5738 = tail call i32 @llvm.fshl.i32(i32 %add5705, i32 %add5705, i32 12)
  %add5740 = add i32 %or5738, -1482130984
  %add5741 = add i32 %add5740, %xor5730
  %or5746 = tail call i32 @llvm.fshl.i32(i32 %add5741, i32 %add5741, i32 7)
  %and5748 = and i32 %add5705, %add5654
  %or5749 = or i32 %add5705, %add5654
  %and5750 = and i32 %or5749, %or5716
  %or5751 = or i32 %and5750, %and5748
  %xor5753 = xor i32 %or5746, %or5738
  %xor5755 = xor i32 %xor5033, %xor4645
  %add5752 = add i32 %or5665, %xor5755
  %add5754 = add i32 %add5752, %or5751
  %add5756 = add i32 %add5754, %xor5753
  %xor5758 = xor i32 %xor5679, %or5720
  %and5759 = and i32 %xor5730, %xor5758
  %xor5760 = xor i32 %and5759, %or5720
  %add5761 = add i32 %or5669, %xor4645
  %add5762 = add i32 %add5761, %xor5760
  %add5763 = add i32 %add5762, %or5746
  %or5767 = tail call i32 @llvm.fshl.i32(i32 %add5654, i32 %add5654, i32 9)
  %or5771 = tail call i32 @llvm.fshl.i32(i32 %xor5679, i32 %xor5679, i32 19)
  %or5775 = tail call i32 @llvm.fshl.i32(i32 %add5763, i32 %add5763, i32 9)
  %xor5776 = xor i32 %or5775, %add5763
  %or5780 = tail call i32 @llvm.fshl.i32(i32 %add5763, i32 %add5763, i32 17)
  %xor5781 = xor i32 %xor5776, %or5780
  %or5789 = tail call i32 @llvm.fshl.i32(i32 %add5756, i32 %add5756, i32 12)
  %add5791 = add i32 %or5789, 1330705329
  %add5792 = add i32 %add5791, %xor5781
  %or5797 = tail call i32 @llvm.fshl.i32(i32 %add5792, i32 %add5792, i32 7)
  %and5799 = and i32 %add5756, %add5705
  %or5800 = or i32 %add5756, %add5705
  %and5801 = and i32 %or5800, %or5767
  %or5802 = or i32 %and5801, %and5799
  %xor5804 = xor i32 %or5797, %or5789
  %xor5107 = xor i32 %xor4548, %or5128
  %xor5124 = xor i32 %xor5107, %xor4742
  %xor5129 = xor i32 %xor5124, %xor5090
  %xor5130 = xor i32 %xor5129, %or5106
  %xor5806 = xor i32 %xor5130, %or5123
  %add5803 = add i32 %or5716, %xor5806
  %add5805 = add i32 %add5803, %or5802
  %add5807 = add i32 %add5805, %xor5804
  %xor5809 = xor i32 %xor5730, %or5771
  %and5810 = and i32 %xor5781, %xor5809
  %xor5811 = xor i32 %and5810, %or5771
  %add5812 = add i32 %or5720, %xor4742
  %add5813 = add i32 %add5812, %xor5811
  %add5814 = add i32 %add5813, %or5797
  %or5818 = tail call i32 @llvm.fshl.i32(i32 %add5705, i32 %add5705, i32 9)
  %or5822 = tail call i32 @llvm.fshl.i32(i32 %xor5730, i32 %xor5730, i32 19)
  %or5826 = tail call i32 @llvm.fshl.i32(i32 %add5814, i32 %add5814, i32 9)
  %xor5827 = xor i32 %or5826, %add5814
  %or5831 = tail call i32 @llvm.fshl.i32(i32 %add5814, i32 %add5814, i32 17)
  %xor5832 = xor i32 %xor5827, %or5831
  %or5840 = tail call i32 @llvm.fshl.i32(i32 %add5807, i32 %add5807, i32 12)
  %add5842 = add i32 %or5840, -1633556638
  %add5843 = add i32 %add5842, %xor5832
  %or5848 = tail call i32 @llvm.fshl.i32(i32 %add5843, i32 %add5843, i32 7)
  %and5850 = and i32 %add5807, %add5756
  %or5851 = or i32 %add5807, %add5756
  %and5852 = and i32 %or5851, %or5818
  %or5853 = or i32 %and5852, %and5850
  %xor5855 = xor i32 %or5848, %or5840
  %xor5204 = xor i32 %xor4645, %or5225
  %xor5221 = xor i32 %xor5204, %xor4839
  %xor5226 = xor i32 %xor5221, %xor5187
  %xor5227 = xor i32 %xor5226, %or5203
  %xor5857 = xor i32 %xor5227, %or5220
  %add5854 = add i32 %or5767, %xor5857
  %add5856 = add i32 %add5854, %or5853
  %add5858 = add i32 %add5856, %xor5855
  %xor5860 = xor i32 %xor5781, %or5822
  %and5861 = and i32 %xor5832, %xor5860
  %xor5862 = xor i32 %and5861, %or5822
  %add5863 = add i32 %or5771, %xor4839
  %add5864 = add i32 %add5863, %xor5862
  %add5865 = add i32 %add5864, %or5848
  %or5869 = tail call i32 @llvm.fshl.i32(i32 %add5756, i32 %add5756, i32 9)
  %or5873 = tail call i32 @llvm.fshl.i32(i32 %xor5781, i32 %xor5781, i32 19)
  %or5877 = tail call i32 @llvm.fshl.i32(i32 %add5865, i32 %add5865, i32 9)
  %xor5878 = xor i32 %or5877, %add5865
  %or5882 = tail call i32 @llvm.fshl.i32(i32 %add5865, i32 %add5865, i32 17)
  %xor5883 = xor i32 %xor5878, %or5882
  %or5891 = tail call i32 @llvm.fshl.i32(i32 %add5858, i32 %add5858, i32 12)
  %add5893 = add i32 %or5891, 1027854021
  %add5894 = add i32 %add5893, %xor5883
  %or5899 = tail call i32 @llvm.fshl.i32(i32 %add5894, i32 %add5894, i32 7)
  %and5901 = and i32 %add5858, %add5807
  %or5902 = or i32 %add5858, %add5807
  %and5903 = and i32 %or5902, %or5869
  %or5904 = or i32 %and5903, %and5901
  %xor5906 = xor i32 %or5899, %or5891
  %xor5301 = xor i32 %xor4742, %or5322
  %xor5318 = xor i32 %xor5301, %xor4936
  %xor5323 = xor i32 %xor5318, %xor5284
  %xor5324 = xor i32 %xor5323, %or5300
  %xor5908 = xor i32 %xor5324, %or5317
  %add5905 = add i32 %or5818, %xor5908
  %add5907 = add i32 %add5905, %or5904
  %add5909 = add i32 %add5907, %xor5906
  %xor5911 = xor i32 %xor5832, %or5873
  %and5912 = and i32 %xor5883, %xor5911
  %xor5913 = xor i32 %and5912, %or5873
  %add5914 = add i32 %or5822, %xor4936
  %add5915 = add i32 %add5914, %xor5913
  %add5916 = add i32 %add5915, %or5899
  %or5920 = tail call i32 @llvm.fshl.i32(i32 %add5807, i32 %add5807, i32 9)
  %or5924 = tail call i32 @llvm.fshl.i32(i32 %xor5832, i32 %xor5832, i32 19)
  %or5928 = tail call i32 @llvm.fshl.i32(i32 %add5916, i32 %add5916, i32 9)
  %or5933 = tail call i32 @llvm.fshl.i32(i32 %add5916, i32 %add5916, i32 17)
  %xor5938 = xor i32 %add5909, %7
  store i32 %xor5938, i32* %A1, align 4, !tbaa !11
  %xor5940 = xor i32 %add5858, %6
  store i32 %xor5940, i32* %B2, align 4, !tbaa !12
  %xor5942 = xor i32 %or5920, %5
  store i32 %xor5942, i32* %C3, align 4, !tbaa !13
  %xor5944 = xor i32 %or5869, %4
  store i32 %xor5944, i32* %D4, align 4, !tbaa !14
  %xor5929 = xor i32 %add5916, %3
  %xor5934 = xor i32 %xor5929, %or5928
  %xor5946 = xor i32 %xor5934, %or5933
  store i32 %xor5946, i32* %E5, align 4, !tbaa !15
  %xor5948 = xor i32 %xor5883, %2
  store i32 %xor5948, i32* %F6, align 4, !tbaa !16
  %xor5950 = xor i32 %or5924, %1
  store i32 %xor5950, i32* %G7, align 4, !tbaa !17
  %xor5952 = xor i32 %or5873, %0
  store i32 %xor5952, i32* %H8, align 4, !tbaa !18
  %tobool.not = icmp eq i64 %dec, 0
  br i1 %tobool.not, label %for.end, label %for.body, !llvm.loop !20

for.end:                                          ; preds = %for.body, %entry
  ret void
}

; Function Attrs: nounwind
declare i8* @memset(i8* noundef, i32 noundef, i64 noundef) local_unnamed_addr #1

; Function Attrs: nofree noinline nosync nounwind uwtable
define void @ossl_sm3_transform(%struct.SM3state_st* nocapture noundef %c, i8* noundef %data) local_unnamed_addr #2 {
entry:
  tail call void @ossl_sm3_block_data_order(%struct.SM3state_st* noundef %c, i8* noundef %data, i64 noundef 1) #6
  ret void
}

; Function Attrs: noinline nounwind uwtable
define i32 @ossl_sm3_final(i8* noundef writeonly %md, %struct.SM3state_st* noundef %c) local_unnamed_addr #0 {
entry:
  %arraydecay = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 10, i64 0
  %0 = bitcast i32* %arraydecay to i8*
  %num = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 11
  %1 = load i32, i32* %num, align 4, !tbaa !10
  %conv = zext i32 %1 to i64
  %arrayidx = getelementptr inbounds i8, i8* %0, i64 %conv
  store i8 -128, i8* %arrayidx, align 1, !tbaa !19
  %inc = add nuw nsw i64 %conv, 1
  %cmp = icmp ugt i32 %1, 55
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %add.ptr = getelementptr inbounds i8, i8* %0, i64 %inc
  %sub = sub nsw i64 63, %conv
  %call = tail call i8* @memset(i8* noundef nonnull %add.ptr, i32 noundef 0, i64 noundef %sub) #5
  tail call void @ossl_sm3_block_data_order(%struct.SM3state_st* noundef nonnull %c, i8* noundef nonnull %0, i64 noundef 1) #6
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %n.0 = phi i64 [ 0, %if.then ], [ %inc, %entry ]
  %add.ptr2 = getelementptr inbounds i8, i8* %0, i64 %n.0
  %sub3 = sub nsw i64 56, %n.0
  %call4 = tail call i8* @memset(i8* noundef nonnull %add.ptr2, i32 noundef 0, i64 noundef %sub3) #5
  %add.ptr5287 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 10, i64 14
  %add.ptr5 = bitcast i32* %add.ptr5287 to i8*
  %Nh = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 9
  %2 = load i32, i32* %Nh, align 4, !tbaa !9
  %shr = lshr i32 %2, 24
  %conv6 = trunc i32 %shr to i8
  %incdec.ptr = getelementptr inbounds i8, i8* %add.ptr5, i64 1
  store i8 %conv6, i8* %add.ptr5, align 1, !tbaa !19
  %shr8 = lshr i32 %2, 16
  %conv10 = trunc i32 %shr8 to i8
  %incdec.ptr11 = getelementptr inbounds i8, i8* %add.ptr5, i64 2
  store i8 %conv10, i8* %incdec.ptr, align 1, !tbaa !19
  %shr13 = lshr i32 %2, 8
  %conv15 = trunc i32 %shr13 to i8
  %incdec.ptr16 = getelementptr inbounds i8, i8* %add.ptr5, i64 3
  store i8 %conv15, i8* %incdec.ptr11, align 1, !tbaa !19
  %conv19 = trunc i32 %2 to i8
  %incdec.ptr20288 = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 10, i64 15
  %incdec.ptr20 = bitcast i32* %incdec.ptr20288 to i8*
  store i8 %conv19, i8* %incdec.ptr16, align 1, !tbaa !19
  %Nl = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 8
  %3 = load i32, i32* %Nl, align 4, !tbaa !4
  %shr22 = lshr i32 %3, 24
  %conv24 = trunc i32 %shr22 to i8
  %incdec.ptr25 = getelementptr inbounds i8, i8* %incdec.ptr20, i64 1
  store i8 %conv24, i8* %incdec.ptr20, align 1, !tbaa !19
  %shr27 = lshr i32 %3, 16
  %conv29 = trunc i32 %shr27 to i8
  %incdec.ptr30 = getelementptr inbounds i8, i8* %incdec.ptr20, i64 2
  store i8 %conv29, i8* %incdec.ptr25, align 1, !tbaa !19
  %shr32 = lshr i32 %3, 8
  %conv34 = trunc i32 %shr32 to i8
  %incdec.ptr35 = getelementptr inbounds i8, i8* %incdec.ptr20, i64 3
  store i8 %conv34, i8* %incdec.ptr30, align 1, !tbaa !19
  %conv38 = trunc i32 %3 to i8
  store i8 %conv38, i8* %incdec.ptr35, align 1, !tbaa !19
  tail call void @ossl_sm3_block_data_order(%struct.SM3state_st* noundef nonnull %c, i8* noundef nonnull %0, i64 noundef 1) #6
  store i32 0, i32* %num, align 4, !tbaa !10
  tail call void @OPENSSL_cleanse(i8* noundef nonnull %0, i64 noundef 64) #5
  %A = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 0
  %4 = load i32, i32* %A, align 4, !tbaa !11
  %conv43 = zext i32 %4 to i64
  %shr44 = lshr i64 %conv43, 24
  %conv46 = trunc i64 %shr44 to i8
  %incdec.ptr47 = getelementptr inbounds i8, i8* %md, i64 1
  store i8 %conv46, i8* %md, align 1, !tbaa !19
  %shr48 = lshr i64 %conv43, 16
  %conv50 = trunc i64 %shr48 to i8
  %incdec.ptr51 = getelementptr inbounds i8, i8* %md, i64 2
  store i8 %conv50, i8* %incdec.ptr47, align 1, !tbaa !19
  %shr52 = lshr i64 %conv43, 8
  %conv54 = trunc i64 %shr52 to i8
  %incdec.ptr55 = getelementptr inbounds i8, i8* %md, i64 3
  store i8 %conv54, i8* %incdec.ptr51, align 1, !tbaa !19
  %conv57 = trunc i32 %4 to i8
  %incdec.ptr58 = getelementptr inbounds i8, i8* %md, i64 4
  store i8 %conv57, i8* %incdec.ptr55, align 1, !tbaa !19
  %B = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 1
  %5 = load i32, i32* %B, align 4, !tbaa !12
  %conv59 = zext i32 %5 to i64
  %shr60 = lshr i64 %conv59, 24
  %conv62 = trunc i64 %shr60 to i8
  %incdec.ptr63 = getelementptr inbounds i8, i8* %md, i64 5
  store i8 %conv62, i8* %incdec.ptr58, align 1, !tbaa !19
  %shr64 = lshr i64 %conv59, 16
  %conv66 = trunc i64 %shr64 to i8
  %incdec.ptr67 = getelementptr inbounds i8, i8* %md, i64 6
  store i8 %conv66, i8* %incdec.ptr63, align 1, !tbaa !19
  %shr68 = lshr i64 %conv59, 8
  %conv70 = trunc i64 %shr68 to i8
  %incdec.ptr71 = getelementptr inbounds i8, i8* %md, i64 7
  store i8 %conv70, i8* %incdec.ptr67, align 1, !tbaa !19
  %conv73 = trunc i32 %5 to i8
  %incdec.ptr74 = getelementptr inbounds i8, i8* %md, i64 8
  store i8 %conv73, i8* %incdec.ptr71, align 1, !tbaa !19
  %C = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 2
  %6 = load i32, i32* %C, align 4, !tbaa !13
  %conv75 = zext i32 %6 to i64
  %shr76 = lshr i64 %conv75, 24
  %conv78 = trunc i64 %shr76 to i8
  %incdec.ptr79 = getelementptr inbounds i8, i8* %md, i64 9
  store i8 %conv78, i8* %incdec.ptr74, align 1, !tbaa !19
  %shr80 = lshr i64 %conv75, 16
  %conv82 = trunc i64 %shr80 to i8
  %incdec.ptr83 = getelementptr inbounds i8, i8* %md, i64 10
  store i8 %conv82, i8* %incdec.ptr79, align 1, !tbaa !19
  %shr84 = lshr i64 %conv75, 8
  %conv86 = trunc i64 %shr84 to i8
  %incdec.ptr87 = getelementptr inbounds i8, i8* %md, i64 11
  store i8 %conv86, i8* %incdec.ptr83, align 1, !tbaa !19
  %conv89 = trunc i32 %6 to i8
  %incdec.ptr90 = getelementptr inbounds i8, i8* %md, i64 12
  store i8 %conv89, i8* %incdec.ptr87, align 1, !tbaa !19
  %D = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 3
  %7 = load i32, i32* %D, align 4, !tbaa !14
  %conv91 = zext i32 %7 to i64
  %shr92 = lshr i64 %conv91, 24
  %conv94 = trunc i64 %shr92 to i8
  %incdec.ptr95 = getelementptr inbounds i8, i8* %md, i64 13
  store i8 %conv94, i8* %incdec.ptr90, align 1, !tbaa !19
  %shr96 = lshr i64 %conv91, 16
  %conv98 = trunc i64 %shr96 to i8
  %incdec.ptr99 = getelementptr inbounds i8, i8* %md, i64 14
  store i8 %conv98, i8* %incdec.ptr95, align 1, !tbaa !19
  %shr100 = lshr i64 %conv91, 8
  %conv102 = trunc i64 %shr100 to i8
  %incdec.ptr103 = getelementptr inbounds i8, i8* %md, i64 15
  store i8 %conv102, i8* %incdec.ptr99, align 1, !tbaa !19
  %conv105 = trunc i32 %7 to i8
  %incdec.ptr106 = getelementptr inbounds i8, i8* %md, i64 16
  store i8 %conv105, i8* %incdec.ptr103, align 1, !tbaa !19
  %E = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 4
  %8 = load i32, i32* %E, align 4, !tbaa !15
  %conv107 = zext i32 %8 to i64
  %shr108 = lshr i64 %conv107, 24
  %conv110 = trunc i64 %shr108 to i8
  %incdec.ptr111 = getelementptr inbounds i8, i8* %md, i64 17
  store i8 %conv110, i8* %incdec.ptr106, align 1, !tbaa !19
  %shr112 = lshr i64 %conv107, 16
  %conv114 = trunc i64 %shr112 to i8
  %incdec.ptr115 = getelementptr inbounds i8, i8* %md, i64 18
  store i8 %conv114, i8* %incdec.ptr111, align 1, !tbaa !19
  %shr116 = lshr i64 %conv107, 8
  %conv118 = trunc i64 %shr116 to i8
  %incdec.ptr119 = getelementptr inbounds i8, i8* %md, i64 19
  store i8 %conv118, i8* %incdec.ptr115, align 1, !tbaa !19
  %conv121 = trunc i32 %8 to i8
  %incdec.ptr122 = getelementptr inbounds i8, i8* %md, i64 20
  store i8 %conv121, i8* %incdec.ptr119, align 1, !tbaa !19
  %F = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 5
  %9 = load i32, i32* %F, align 4, !tbaa !16
  %conv123 = zext i32 %9 to i64
  %shr124 = lshr i64 %conv123, 24
  %conv126 = trunc i64 %shr124 to i8
  %incdec.ptr127 = getelementptr inbounds i8, i8* %md, i64 21
  store i8 %conv126, i8* %incdec.ptr122, align 1, !tbaa !19
  %shr128 = lshr i64 %conv123, 16
  %conv130 = trunc i64 %shr128 to i8
  %incdec.ptr131 = getelementptr inbounds i8, i8* %md, i64 22
  store i8 %conv130, i8* %incdec.ptr127, align 1, !tbaa !19
  %shr132 = lshr i64 %conv123, 8
  %conv134 = trunc i64 %shr132 to i8
  %incdec.ptr135 = getelementptr inbounds i8, i8* %md, i64 23
  store i8 %conv134, i8* %incdec.ptr131, align 1, !tbaa !19
  %conv137 = trunc i32 %9 to i8
  %incdec.ptr138 = getelementptr inbounds i8, i8* %md, i64 24
  store i8 %conv137, i8* %incdec.ptr135, align 1, !tbaa !19
  %G = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 6
  %10 = load i32, i32* %G, align 4, !tbaa !17
  %conv139 = zext i32 %10 to i64
  %shr140 = lshr i64 %conv139, 24
  %conv142 = trunc i64 %shr140 to i8
  %incdec.ptr143 = getelementptr inbounds i8, i8* %md, i64 25
  store i8 %conv142, i8* %incdec.ptr138, align 1, !tbaa !19
  %shr144 = lshr i64 %conv139, 16
  %conv146 = trunc i64 %shr144 to i8
  %incdec.ptr147 = getelementptr inbounds i8, i8* %md, i64 26
  store i8 %conv146, i8* %incdec.ptr143, align 1, !tbaa !19
  %shr148 = lshr i64 %conv139, 8
  %conv150 = trunc i64 %shr148 to i8
  %incdec.ptr151 = getelementptr inbounds i8, i8* %md, i64 27
  store i8 %conv150, i8* %incdec.ptr147, align 1, !tbaa !19
  %conv153 = trunc i32 %10 to i8
  %incdec.ptr154 = getelementptr inbounds i8, i8* %md, i64 28
  store i8 %conv153, i8* %incdec.ptr151, align 1, !tbaa !19
  %H = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 7
  %11 = load i32, i32* %H, align 4, !tbaa !18
  %conv155 = zext i32 %11 to i64
  %shr156 = lshr i64 %conv155, 24
  %conv158 = trunc i64 %shr156 to i8
  %incdec.ptr159 = getelementptr inbounds i8, i8* %md, i64 29
  store i8 %conv158, i8* %incdec.ptr154, align 1, !tbaa !19
  %shr160 = lshr i64 %conv155, 16
  %conv162 = trunc i64 %shr160 to i8
  %incdec.ptr163 = getelementptr inbounds i8, i8* %md, i64 30
  store i8 %conv162, i8* %incdec.ptr159, align 1, !tbaa !19
  %shr164 = lshr i64 %conv155, 8
  %conv166 = trunc i64 %shr164 to i8
  %incdec.ptr167 = getelementptr inbounds i8, i8* %md, i64 31
  store i8 %conv166, i8* %incdec.ptr163, align 1, !tbaa !19
  %conv169 = trunc i32 %11 to i8
  store i8 %conv169, i8* %incdec.ptr167, align 1, !tbaa !19
  ret i32 1
}

declare void @OPENSSL_cleanse(i8* noundef, i64 noundef) local_unnamed_addr #3

; Function Attrs: noinline nounwind uwtable
define i32 @ossl_sm3_init(%struct.SM3state_st* noundef %c) local_unnamed_addr #0 {
entry:
  %0 = bitcast %struct.SM3state_st* %c to i8*
  %call = tail call i8* @memset(i8* noundef %0, i32 noundef 0, i64 noundef 108) #5
  %1 = bitcast %struct.SM3state_st* %c to <4 x i32>*
  store <4 x i32> <i32 1937774191, i32 1226093241, i32 388252375, i32 -628488704>, <4 x i32>* %1, align 4, !tbaa !22
  %E = getelementptr inbounds %struct.SM3state_st, %struct.SM3state_st* %c, i64 0, i32 4
  %2 = bitcast i32* %E to <4 x i32>*
  store <4 x i32> <i32 -1452330820, i32 372324522, i32 -477237683, i32 -1325724082>, <4 x i32>* %2, align 4, !tbaa !22
  ret i32 1
}

; Function Attrs: nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.fshl.i32(i32, i32, i32) #4

attributes #0 = { noinline nounwind uwtable "frame-pointer"="none" "min-legal-vector-width"="0" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #1 = { nounwind "frame-pointer"="none" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #2 = { nofree noinline nosync nounwind uwtable "frame-pointer"="none" "min-legal-vector-width"="0" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #3 = { "frame-pointer"="none" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #4 = { nofree nosync nounwind readnone speculatable willreturn }
attributes #5 = { nobuiltin nounwind "no-builtins" }
attributes #6 = { nobuiltin "no-builtins" }

!llvm.module.flags = !{!0, !1, !2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 7, !"uwtable", i32 1}
!3 = !{!"clang version 14.0.0"}
!4 = !{!5, !6, i64 32}
!5 = !{!"SM3state_st", !6, i64 0, !6, i64 4, !6, i64 8, !6, i64 12, !6, i64 16, !6, i64 20, !6, i64 24, !6, i64 28, !6, i64 32, !6, i64 36, !7, i64 40, !6, i64 104}
!6 = !{!"int", !7, i64 0}
!7 = !{!"omnipotent char", !8, i64 0}
!8 = !{!"Simple C/C++ TBAA"}
!9 = !{!5, !6, i64 36}
!10 = !{!5, !6, i64 104}
!11 = !{!5, !6, i64 0}
!12 = !{!5, !6, i64 4}
!13 = !{!5, !6, i64 8}
!14 = !{!5, !6, i64 12}
!15 = !{!5, !6, i64 16}
!16 = !{!5, !6, i64 20}
!17 = !{!5, !6, i64 24}
!18 = !{!5, !6, i64 28}
!19 = !{!7, !7, i64 0}
!20 = distinct !{!20, !21}
!21 = !{!"llvm.loop.mustprogress"}
!22 = !{!6, !6, i64 0}
